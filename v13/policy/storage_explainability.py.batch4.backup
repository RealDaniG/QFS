"""
storage_explainability.py - Policy for verifying Storage Placement and Integrity

Implements verification logic for storage proofs, asserting that:
1. Shard placement satisfies the Replication Factor (RF=3).
2. Assigned nodes were AEGIS-verified active nodes at the time of placement.
3. Merkle proofs provided by the StorageEngine are mathematically valid.
"""
from typing import Dict, Any, List, Optional
import hashlib
import json

class StorageVerifier:
    """
    Verifies storage events against QFS invariants.
    """

    @staticmethod
    def verify_placement_policy(shard_info: Dict[str, Any], active_nodes: List[str], replication_factor: int=3) -> Dict[str, Any]:
        """
        Verify that a shard was placed on the correct number of eligible nodes.
        
        Args:
            shard_info: Dictionary containing 'shard_id' and 'assigned_nodes'
            active_nodes: List of valid node IDs for the relevant epoch
            replication_factor: Expected number of replicas
            
        Returns:
            Dict with 'is_compliant' (bool) and 'violations' (list[str])
        """
        assigned = shard_info.get('assigned_nodes', [])
        violations = []
        if len(assigned) < replication_factor:
            violations.append(f'Insufficient replication: {len(assigned)}/{replication_factor}')
        valid_node_set = set(active_nodes)
        for node in assigned:
            if node not in valid_node_set:
                violations.append(f'Node {node} was not AEGIS-verified/active in this epoch')
        return {'is_compliant': len(violations) == 0, 'violations': violations, 'policy_check': 'RF_AND_AEGIS_IDENTITY'}

    @staticmethod
    def verify_merkle_proof(content_chunk: bytes, proof_json: str) -> bool:
        """
        Verify that the content chunk matches the Merkle Proof.
        
        Args:
            content_chunk: Raw content bytes (if available for re-verification)
            proof_json: JSON string with 'merkle_root'
            
        Returns:
            True if the calculated root matches the proof's root
        """
        try:
            proof = json.loads(proof_json)
            provided_root = proof.get('merkle_root')
            BLOCK_SIZE = 4096
            leaves = []
            for i in range(0, len(content_chunk), BLOCK_SIZE):
                block = content_chunk[i:i + BLOCK_SIZE]
                leaves.append(hashlib.sha3_256(block).hexdigest())
            if not leaves:
                calc_root = hashlib.sha3_256(b'').hexdigest()
            else:
                tree_level = leaves
                while len(tree_level) > 1:
                    next_level = []
                    for i in range(0, len(tree_level), 2):
                        left = tree_level[i]
                        right = tree_level[i + 1] if i + 1 < len(tree_level) else left
                        combined = (left + right).encode()
                        next_level.append(hashlib.sha3_256(combined).hexdigest())
                    tree_level = next_level
                calc_root = tree_level[0]
            return calc_root == provided_root
        except Exception:
            return False

def explain_storage_placement(content_id: str, events: List[Dict[str, Any]]) -> Any:
    """
    Generate a storage explanation from history events.
    
    Args:
        content_id: Content ID
        events: List of event dictionaries from QFSReplaySource
        
    Returns:
        Explanation object (or dict)
    """

    class StorageExplanation:

        def __init__(self):
            self.content_id = content_id
            self.replica_count = 0
            self.storage_nodes = []
            self.shard_ids = []
            self.proof_outcomes = []
            self.epoch_assigned = 0
            self.integrity_hash = 'simulated_hash'
            self.explanation_hash = 'simulated_hash'
            self.policy_version = 'v13.8'
    explanation = StorageExplanation()
    for event in events:
        payload = event.get('payload', {})
        if event.get('type') in ['ContentStored', 'STORE']:
            explanation.epoch_assigned = payload.get('epoch', 0)
            explanation.shard_ids = payload.get('shard_ids', [])
            explanation.integrity_hash = payload.get('hash_commit', '')
            replica_sets = payload.get('replica_sets', {})
            nodes = set()
            for shard_id, node_list in sorted(replica_sets.items()):
                nodes.update(node_list)
            explanation.storage_nodes = sorted(list(nodes))
            explanation.replica_count = len(explanation.storage_nodes)
        if event.get('type') in ['StorageProofSubmitted', 'PROOF_GENERATED']:
            proof_data = payload.get('proof', None)
            is_valid = False
            if proof_data:
                is_valid = True
            explanation.proof_outcomes.append({'shard_id': payload.get('shard_ids', ['unknown'])[0] if payload.get('shard_ids') else 'unknown', 'status': 'Verified' if is_valid else 'Failed', 'timestamp': event.get('timestamp')})
    explanation_str = f'{content_id}:{explanation.epoch_assigned}:{len(explanation.storage_nodes)}'
    explanation.explanation_hash = hashlib.sha256(explanation_str.encode()).hexdigest()
    return explanation