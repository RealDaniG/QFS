{"timestamp": "2025-12-15T16:27:01.345534", "session_id": "2ca08fd6a082ae9b", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_coherence_referral_integration.py::TestCoherenceReferralIntegration::test_referral_reward_application", "context": {"env": "test"}, "details": {"duration": 0.00025740000273799524, "error": "self = <v13.tests.unit.test_coherence_referral_integration.TestCoherenceReferralIntegration object at 0x000001976D983B10>\n\n    def test_referral_reward_application(self):\n        \"\"\"Test that CoherenceEngine correctly applies ReferralRewarded events to token state.\"\"\"\n        cm = CertifiedMath()\n        engine = CoherenceEngine(cm)\n    \n        # Initial State\n        referrer_wallet = \"0xReferrerWallet\"\n        initial_balance = \"100.0\"\n    \n        # Create initial bundle\n>       initial_bundle = create_token_state_bundle(\n            chr_state={},\n            flx_state={referrer_wallet: BigNum128.from_string(initial_balance)},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128.from_int(1),\n            lambda2=BigNum128.from_int(1),\n            c_crit=BigNum128.from_int(1),\n            pqc_cid=\"test_cid\",\n            timestamp=1000\n        )\n\nv13\\tests\\unit\\test_coherence_referral_integration.py:20: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nv13\\core\\TokenStateBundle.py:463: in create_token_state_bundle\n    bundle_id = temp_bundle.get_deterministic_hash(include_signature=False)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = TokenStateBundle(chr_state={}, flx_state={'0xReferrerWallet': BigNum128(raw=100000000000000000000, fp='100.0')}, psi_s...=100000000000000000000000000, fp='100000000.0'), 'phi': BigNum128(raw=1618033988749894848, fp='1.618033988749894848')})\ninclude_signature = False\n\n    def get_deterministic_hash(self, include_signature: bool = True) -> str:\n        \"\"\"\n        Generate a deterministic SHA-256 hash of the TokenStateBundle.\n        This is used for bundle identification and integrity verification.\n    \n        Args:\n            include_signature: Whether to include the signature in the hash calculation\n    \n        Returns:\n            str: SHA-256 hash as hexadecimal string\n        \"\"\"\n>       serialized = json.dumps(self.to_dict(include_signature=include_signature), sort_keys=True, separators=(',', ':'))\n                     ^^^^\nE       NameError: name 'json' is not defined. Did you forget to import 'json'?\n\nv13\\core\\TokenStateBundle.py:381: NameError"}, "hash": "edd7d319d2c08bde4e1ee30c112bcd9d95c9bccca2315bea9aedbcc86e99f0997b835d1b19441e4971d538e9b88d60a629e4672e854440eed92140eb5841a9a7"}
{"timestamp": "2025-12-15T16:27:32.483309", "session_id": "ff13cb43b2234dda", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_coherence_referral_integration.py::TestCoherenceReferralIntegration::test_referral_reward_application", "context": {"env": "test"}, "details": {"duration": 0.00024019999909796752, "error": "self = <v13.tests.unit.test_coherence_referral_integration.TestCoherenceReferralIntegration object at 0x0000027F169BF890>\n\n    def test_referral_reward_application(self):\n        \"\"\"Test that CoherenceEngine correctly applies ReferralRewarded events to token state.\"\"\"\n        cm = CertifiedMath()\n        engine = CoherenceEngine(cm)\n    \n        # Initial State\n        referrer_wallet = \"0xReferrerWallet\"\n        initial_balance = \"100.0\"\n    \n        # Create initial bundle\n>       initial_bundle = create_token_state_bundle(\n            chr_state={},\n            flx_state={referrer_wallet: BigNum128.from_string(initial_balance)},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128.from_int(1),\n            lambda2=BigNum128.from_int(1),\n            c_crit=BigNum128.from_int(1),\n            pqc_cid=\"test_cid\",\n            timestamp=1000\n        )\n\nv13\\tests\\unit\\test_coherence_referral_integration.py:20: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nv13\\core\\TokenStateBundle.py:463: in create_token_state_bundle\n    bundle_id = temp_bundle.get_deterministic_hash(include_signature=False)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = TokenStateBundle(chr_state={}, flx_state={'0xReferrerWallet': BigNum128(raw=100000000000000000000, fp='100.0')}, psi_s...=100000000000000000000000000, fp='100000000.0'), 'phi': BigNum128(raw=1618033988749894848, fp='1.618033988749894848')})\ninclude_signature = False\n\n    def get_deterministic_hash(self, include_signature: bool = True) -> str:\n        \"\"\"\n        Generate a deterministic SHA-256 hash of the TokenStateBundle.\n        This is used for bundle identification and integrity verification.\n    \n        Args:\n            include_signature: Whether to include the signature in the hash calculation\n    \n        Returns:\n            str: SHA-256 hash as hexadecimal string\n        \"\"\"\n>       serialized = json.dumps(self.to_dict(include_signature=include_signature), sort_keys=True, separators=(',', ':'))\n                     ^^^^\nE       NameError: name 'json' is not defined. Did you forget to import 'json'?\n\nv13\\core\\TokenStateBundle.py:381: NameError"}, "hash": "65bf6c2dbf638a8556501f192fb60d807a05a2327e29e1e5c0ba43129d33a3371b88b4b1c9266303dfdede76a1dfb4007b0839a1f936cc4adf3f219f8a143cce"}
{"timestamp": "2025-12-15T16:28:06.830187", "session_id": "b8d156f20207f4bd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_coherence_referral_integration.py::TestCoherenceReferralIntegration::test_referral_reward_application", "context": {"env": "test"}, "details": {"duration": 0.0004907999973511323, "error": "self = <v13.tests.unit.test_coherence_referral_integration.TestCoherenceReferralIntegration object at 0x0000024993303890>\n\n    def test_referral_reward_application(self):\n        \"\"\"Test that CoherenceEngine correctly applies ReferralRewarded events to token state.\"\"\"\n        cm = CertifiedMath()\n        engine = CoherenceEngine(cm)\n    \n        # Initial State\n        referrer_wallet = \"0xReferrerWallet\"\n        initial_balance = \"100.0\"\n    \n        # Create initial bundle\n        initial_bundle = create_token_state_bundle(\n            chr_state={},\n            flx_state={referrer_wallet: BigNum128.from_string(initial_balance)},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128.from_int(1),\n            lambda2=BigNum128.from_int(1),\n            c_crit=BigNum128.from_int(1),\n            pqc_cid=\"test_cid\",\n            timestamp=1000\n        )\n    \n        # Create ReferralRewarded event\n        reward_amount_scaled = 10_000_000_000 # 100 FLX (1e8 scale)\n        # Note: BigNum128 from_string(\"100.0\") is 100 * 1e18? Or 1e8?\n        # CertifiedMath/BigNum128 typically uses 1e18 or 1e9 depending on impl.\n        # The event uses 'amount_scaled' which usually implies integer units.\n        # But BigNum128.from_int(x) creates a BigNum with internal value x.\n        # If TokenState uses fixed point 1e18, we need to match.\n        # Let's assume the event amount is already in the correct \"atomic units\" for BigNum128.\n        # If BigNum128 expects 18 decimals, 100 FLX = 100 * 10^18.\n        # If ReferralLedger uses 10_000_000_000 (10^10), that might be small if 18 decimals.\n        # Let's check CertifiedMath/BigNum128 implementation if possibly, but in test we can assert the addition.\n    \n        event = ReferralRewarded(\n            referrer_wallet=referrer_wallet,\n            referee_wallet=\"0xReferee\",\n            token_type=\"FLX\",\n            amount_scaled=reward_amount_scaled,\n            epoch=101,\n            reason=\"Test Reward\",\n            guard_cir_code=\"PASS\"\n        )\n    \n        log_list = []\n    \n        # Apply transition\n        new_bundle = engine.apply_hsmf_transition(\n            current_bundle=initial_bundle,\n            log_list=log_list,\n            pqc_cid=\"test_cid_2\",\n            deterministic_timestamp=1100,\n            processed_events=[event]\n        )\n    \n        # Verify result\n        # Initial: 100.0 (BigNum128 likely parses decimal string to fixed point)\n        # Added: 10_000_000_000 (raw int)\n    \n        # We need to know what \"100.0\" becomes.\n        # If BigNum128 uses 1e18 scale: 100.0 -> 100 * 10^18 = 10^20.\n        # 10_000_000_000 is 10^10. So it is negligible.\n    \n        # HOWEVER, the ReferralLedger used 10_000_000_000 for \"100 FLX\" which implies 1e8 scale.\n        # If BigNum128 uses 1e18, then the Ledger is emitting wrong units OR BigNum128 handles it.\n        # For this test, effectively we just want to see Balance_New = Balance_Old + Reward.\n    \n        old_balance = initial_bundle.flx_state[referrer_wallet]\n        new_balance = new_bundle.flx_state[referrer_wallet]\n    \n        expected_balance = cm.add(old_balance, BigNum128.from_int(reward_amount_scaled), [])\n    \n        assert new_balance.value == expected_balance.value\n        assert new_balance.value > old_balance.value\n    \n        # Check logs\n        found_log = False\n>       for log in cm._audit_log: # Or check log_list if passed\n                   ^^^^^^^^^^^^^\nE       AttributeError: 'CertifiedMath' object has no attribute '_audit_log'\n\nv13\\tests\\unit\\test_coherence_referral_integration.py:89: AttributeError"}, "hash": "b3b2e84175d0f57c40f53848a02934f3ece2ac954b0d7a6ab33baebaf02bfaa6a13f454173a08fd1d6c18af7d1faf857d26e2695fd2c971f9d14838ad4221f60"}
{"timestamp": "2025-12-15T16:28:43.138661", "session_id": "acf666461d820285", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_coherence_referral_integration.py::TestCoherenceReferralIntegration::test_referral_reward_application", "context": {"env": "test"}, "details": {"duration": 0.0005178000028536189, "error": "self = <v13.tests.unit.test_coherence_referral_integration.TestCoherenceReferralIntegration object at 0x000002DB5873F610>\n\n    def test_referral_reward_application(self):\n        \"\"\"Test that CoherenceEngine correctly applies ReferralRewarded events to token state.\"\"\"\n        cm = CertifiedMath()\n        engine = CoherenceEngine(cm)\n    \n        # Initial State\n        referrer_wallet = \"0xReferrerWallet\"\n        initial_balance = \"100.0\"\n    \n        # Create initial bundle\n        initial_bundle = create_token_state_bundle(\n            chr_state={},\n            flx_state={referrer_wallet: BigNum128.from_string(initial_balance)},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128.from_int(1),\n            lambda2=BigNum128.from_int(1),\n            c_crit=BigNum128.from_int(1),\n            pqc_cid=\"test_cid\",\n            timestamp=1000\n        )\n    \n        # Create ReferralRewarded event\n        reward_amount_scaled = 10_000_000_000 # 100 FLX (1e8 scale)\n        # Note: BigNum128 from_string(\"100.0\") is 100 * 1e18? Or 1e8?\n        # CertifiedMath/BigNum128 typically uses 1e18 or 1e9 depending on impl.\n        # The event uses 'amount_scaled' which usually implies integer units.\n        # But BigNum128.from_int(x) creates a BigNum with internal value x.\n        # If TokenState uses fixed point 1e18, we need to match.\n        # Let's assume the event amount is already in the correct \"atomic units\" for BigNum128.\n        # If BigNum128 expects 18 decimals, 100 FLX = 100 * 10^18.\n        # If ReferralLedger uses 10_000_000_000 (10^10), that might be small if 18 decimals.\n        # Let's check CertifiedMath/BigNum128 implementation if possibly, but in test we can assert the addition.\n    \n        event = ReferralRewarded(\n            referrer_wallet=referrer_wallet,\n            referee_wallet=\"0xReferee\",\n            token_type=\"FLX\",\n            amount_scaled=reward_amount_scaled,\n            epoch=101,\n            reason=\"Test Reward\",\n            guard_cir_code=\"PASS\"\n        )\n    \n        log_list = []\n    \n        # Apply transition\n        new_bundle = engine.apply_hsmf_transition(\n            current_bundle=initial_bundle,\n            log_list=log_list,\n            pqc_cid=\"test_cid_2\",\n            deterministic_timestamp=1100,\n            processed_events=[event]\n        )\n    \n        # Verify result\n        # Initial: 100.0 (BigNum128 likely parses decimal string to fixed point)\n        # Added: 10_000_000_000 (raw int)\n    \n        # We need to know what \"100.0\" becomes.\n        # If BigNum128 uses 1e18 scale: 100.0 -> 100 * 10^18 = 10^20.\n        # 10_000_000_000 is 10^10. So it is negligible.\n    \n        # HOWEVER, the ReferralLedger used 10_000_000_000 for \"100 FLX\" which implies 1e8 scale.\n        # If BigNum128 uses 1e18, then the Ledger is emitting wrong units OR BigNum128 handles it.\n        # For this test, effectively we just want to see Balance_New = Balance_Old + Reward.\n    \n        old_balance = initial_bundle.flx_state[referrer_wallet]\n        new_balance = new_bundle.flx_state[referrer_wallet]\n    \n        expected_balance = cm.add(old_balance, BigNum128.from_int(reward_amount_scaled), [])\n    \n        assert new_balance.value == expected_balance.value\n        assert new_balance.value > old_balance.value\n    \n        # Check logs\n        found_log = False\n        for log in log_list:\n             if log.get('operation') == 'apply_referral_reward':\n                 if log.get('input', {}).get('wallet') == referrer_wallet:\n                     found_log = True\n                     break\n    \n        # Verify that we found the log entry\n>       assert found_log, \"Referral reward application was not logged\"\nE       AssertionError: Referral reward application was not logged\nE       assert False\n\nv13\\tests\\unit\\test_coherence_referral_integration.py:96: AssertionError"}, "hash": "1ae430984d3621a973c196599be6bca61c804c6be085b7fdc7a021250941828167e86cf965e695f5b6bc4964f495fc6d100d94ff06948d5a00e9f3c4a137a260"}
{"timestamp": "2025-12-15T16:30:08.795673", "session_id": "e00392a364106388", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_coherence_referral_integration.py::TestCoherenceReferralIntegration::test_referral_reward_application", "context": {"env": "test"}, "details": {"duration": 0.000505299998621922, "error": "self = <v13.tests.unit.test_coherence_referral_integration.TestCoherenceReferralIntegration object at 0x0000019866DFF610>\n\n    def test_referral_reward_application(self):\n        \"\"\"Test that CoherenceEngine correctly applies ReferralRewarded events to token state.\"\"\"\n        cm = CertifiedMath()\n        engine = CoherenceEngine(cm)\n    \n        # Initial State\n        referrer_wallet = \"0xReferrerWallet\"\n        initial_balance = \"100.0\"\n    \n        # Create initial bundle\n        initial_bundle = create_token_state_bundle(\n            chr_state={},\n            flx_state={referrer_wallet: BigNum128.from_string(initial_balance)},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128.from_int(1),\n            lambda2=BigNum128.from_int(1),\n            c_crit=BigNum128.from_int(1),\n            pqc_cid=\"test_cid\",\n            timestamp=1000\n        )\n    \n        # Create ReferralRewarded event\n        reward_amount_scaled = 10_000_000_000 # 100 FLX (1e8 scale)\n        # Note: BigNum128 from_string(\"100.0\") is 100 * 1e18? Or 1e8?\n        # CertifiedMath/BigNum128 typically uses 1e18 or 1e9 depending on impl.\n        # The event uses 'amount_scaled' which usually implies integer units.\n        # But BigNum128.from_int(x) creates a BigNum with internal value x.\n        # If TokenState uses fixed point 1e18, we need to match.\n        # Let's assume the event amount is already in the correct \"atomic units\" for BigNum128.\n        # If BigNum128 expects 18 decimals, 100 FLX = 100 * 10^18.\n        # If ReferralLedger uses 10_000_000_000 (10^10), that might be small if 18 decimals.\n        # Let's check CertifiedMath/BigNum128 implementation if possibly, but in test we can assert the addition.\n    \n        event = ReferralRewarded(\n            referrer_wallet=referrer_wallet,\n            referee_wallet=\"0xReferee\",\n            token_type=\"FLX\",\n            amount_scaled=reward_amount_scaled,\n            epoch=101,\n            reason=\"Test Reward\",\n            guard_cir_code=\"PASS\"\n        )\n    \n        log_list = []\n    \n        # Apply transition\n        new_bundle = engine.apply_hsmf_transition(\n            current_bundle=initial_bundle,\n            log_list=log_list,\n            pqc_cid=\"test_cid_2\",\n            deterministic_timestamp=1100,\n            processed_events=[event]\n        )\n    \n        # Verify result\n        # Initial: 100.0 (BigNum128 likely parses decimal string to fixed point)\n        # Added: 10_000_000_000 (raw int)\n    \n        # We need to know what \"100.0\" becomes.\n        # If BigNum128 uses 1e18 scale: 100.0 -> 100 * 10^18 = 10^20.\n        # 10_000_000_000 is 10^10. So it is negligible.\n    \n        # HOWEVER, the ReferralLedger used 10_000_000_000 for \"100 FLX\" which implies 1e8 scale.\n        # If BigNum128 uses 1e18, then the Ledger is emitting wrong units OR BigNum128 handles it.\n        # For this test, effectively we just want to see Balance_New = Balance_Old + Reward.\n    \n        old_balance = initial_bundle.flx_state[referrer_wallet]\n        new_balance = new_bundle.flx_state[referrer_wallet]\n    \n        expected_balance = cm.add(old_balance, BigNum128.from_int(reward_amount_scaled), [])\n    \n        assert new_balance.value == expected_balance.value\n        assert new_balance.value > old_balance.value\n    \n        # Check logs\n        found_log = False\n        for log in log_list:\n             if log.get('operation') == 'apply_referral_reward':\n                 if log.get('input', {}).get('wallet') == referrer_wallet:\n                     found_log = True\n                     break\n    \n        # Verify that we found the log entry\n>       assert found_log, \"Referral reward application was not logged\"\nE       AssertionError: Referral reward application was not logged\nE       assert False\n\nv13\\tests\\unit\\test_coherence_referral_integration.py:96: AssertionError"}, "hash": "621defe49327f15d4854e733e3e9cf090f657f2b72de2d2c1486a7795993bf8ce108b3d966334177243407fd6c6b3bae1beb4d0035fb201d527a94f78a7a0642"}
{"timestamp": "2025-12-15T16:30:43.193071", "session_id": "2ef501c60d73c9f9", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_coherence_referral_integration.py::TestCoherenceReferralIntegration::test_referral_reward_application", "context": {"env": "test"}, "details": {"duration": 0.0009042999990924727, "error": "self = <v13.tests.unit.test_coherence_referral_integration.TestCoherenceReferralIntegration object at 0x000001807829F610>\n\n    def test_referral_reward_application(self):\n        \"\"\"Test that CoherenceEngine correctly applies ReferralRewarded events to token state.\"\"\"\n        cm = CertifiedMath()\n        engine = CoherenceEngine(cm)\n    \n        # Initial State\n        referrer_wallet = \"0xReferrerWallet\"\n        initial_balance = \"100.0\"\n    \n        # Create initial bundle\n        initial_bundle = create_token_state_bundle(\n            chr_state={},\n            flx_state={referrer_wallet: BigNum128.from_string(initial_balance)},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128.from_int(1),\n            lambda2=BigNum128.from_int(1),\n            c_crit=BigNum128.from_int(1),\n            pqc_cid=\"test_cid\",\n            timestamp=1000\n        )\n    \n        # Create ReferralRewarded event\n        reward_amount_scaled = 10_000_000_000 # 100 FLX (1e8 scale)\n        # Note: BigNum128 from_string(\"100.0\") is 100 * 1e18? Or 1e8?\n        # CertifiedMath/BigNum128 typically uses 1e18 or 1e9 depending on impl.\n        # The event uses 'amount_scaled' which usually implies integer units.\n        # But BigNum128.from_int(x) creates a BigNum with internal value x.\n        # If TokenState uses fixed point 1e18, we need to match.\n        # Let's assume the event amount is already in the correct \"atomic units\" for BigNum128.\n        # If BigNum128 expects 18 decimals, 100 FLX = 100 * 10^18.\n        # If ReferralLedger uses 10_000_000_000 (10^10), that might be small if 18 decimals.\n        # Let's check CertifiedMath/BigNum128 implementation if possibly, but in test we can assert the addition.\n    \n        event = ReferralRewarded(\n            referrer_wallet=referrer_wallet,\n            referee_wallet=\"0xReferee\",\n            token_type=\"FLX\",\n            amount_scaled=reward_amount_scaled,\n            epoch=101,\n            reason=\"Test Reward\",\n            guard_cir_code=\"PASS\"\n        )\n    \n        log_list = []\n    \n        # Apply transition\n        new_bundle = engine.apply_hsmf_transition(\n            current_bundle=initial_bundle,\n            log_list=log_list,\n            pqc_cid=\"test_cid_2\",\n            deterministic_timestamp=1100,\n            processed_events=[event]\n        )\n    \n        # Verify result\n        # Initial: 100.0 (BigNum128 likely parses decimal string to fixed point)\n        # Added: 10_000_000_000 (raw int)\n    \n        # We need to know what \"100.0\" becomes.\n        # If BigNum128 uses 1e18 scale: 100.0 -> 100 * 10^18 = 10^20.\n        # 10_000_000_000 is 10^10. So it is negligible.\n    \n        # HOWEVER, the ReferralLedger used 10_000_000_000 for \"100 FLX\" which implies 1e8 scale.\n        # If BigNum128 uses 1e18, then the Ledger is emitting wrong units OR BigNum128 handles it.\n        # For this test, effectively we just want to see Balance_New = Balance_Old + Reward.\n    \n        old_balance = initial_bundle.flx_state[referrer_wallet]\n        new_balance = new_bundle.flx_state[referrer_wallet]\n    \n        expected_balance = cm.add(old_balance, BigNum128.from_int(reward_amount_scaled), [])\n    \n        assert new_balance.value == expected_balance.value\n        assert new_balance.value > old_balance.value\n    \n        # Check logs\n        found_log = False\n        for log in log_list:\n             if log.get('operation') == 'apply_referral_reward':\n                 if log.get('input', {}).get('wallet') == referrer_wallet:\n                     found_log = True\n                     break\n    \n        # Verify that we found the log entry\n>       assert found_log, \"Referral reward application was not logged\"\nE       AssertionError: Referral reward application was not logged\nE       assert False\n\nv13\\tests\\unit\\test_coherence_referral_integration.py:96: AssertionError"}, "hash": "e4221501c1a9080cc15d183d7b292e3d46780e3fadf3e939ef94adc6ff6adb4c1f9b19540bc611a3ad4271367126db78962ed6e810c083f7a8ed3a5d42d30d91"}
{"timestamp": "2025-12-15T16:31:03.887555", "session_id": "511834d3e8061df4", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_coherence_referral_integration.py::TestCoherenceReferralIntegration::test_referral_reward_application", "context": {"env": "test"}, "details": {"duration": 0.0007608999985677656, "error": "self = <v13.tests.unit.test_coherence_referral_integration.TestCoherenceReferralIntegration object at 0x000002E54EB7EE90>\n\n    def test_referral_reward_application(self):\n        \"\"\"Test that CoherenceEngine correctly applies ReferralRewarded events to token state.\"\"\"\n        cm = CertifiedMath()\n        engine = CoherenceEngine(cm)\n    \n        # Initial State\n        referrer_wallet = \"0xReferrerWallet\"\n        initial_balance = \"100.0\"\n    \n        # Create initial bundle\n        initial_bundle = create_token_state_bundle(\n            chr_state={},\n            flx_state={referrer_wallet: BigNum128.from_string(initial_balance)},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128.from_int(1),\n            lambda2=BigNum128.from_int(1),\n            c_crit=BigNum128.from_int(1),\n            pqc_cid=\"test_cid\",\n            timestamp=1000\n        )\n    \n        # Create ReferralRewarded event\n        reward_amount_scaled = 10_000_000_000 # 100 FLX (1e8 scale)\n        # Note: BigNum128 from_string(\"100.0\") is 100 * 1e18? Or 1e8?\n        # CertifiedMath/BigNum128 typically uses 1e18 or 1e9 depending on impl.\n        # The event uses 'amount_scaled' which usually implies integer units.\n        # But BigNum128.from_int(x) creates a BigNum with internal value x.\n        # If TokenState uses fixed point 1e18, we need to match.\n        # Let's assume the event amount is already in the correct \"atomic units\" for BigNum128.\n        # If BigNum128 expects 18 decimals, 100 FLX = 100 * 10^18.\n        # If ReferralLedger uses 10_000_000_000 (10^10), that might be small if 18 decimals.\n        # Let's check CertifiedMath/BigNum128 implementation if possibly, but in test we can assert the addition.\n    \n        event = ReferralRewarded(\n            referrer_wallet=referrer_wallet,\n            referee_wallet=\"0xReferee\",\n            token_type=\"FLX\",\n            amount_scaled=reward_amount_scaled,\n            epoch=101,\n            reason=\"Test Reward\",\n            guard_cir_code=\"PASS\"\n        )\n    \n        log_list = []\n    \n        # Apply transition\n        new_bundle = engine.apply_hsmf_transition(\n            current_bundle=initial_bundle,\n            log_list=log_list,\n            pqc_cid=\"test_cid_2\",\n            deterministic_timestamp=1100,\n            processed_events=[event]\n        )\n    \n        # Verify result\n        # Initial: 100.0 (BigNum128 likely parses decimal string to fixed point)\n        # Added: 10_000_000_000 (raw int)\n    \n        # We need to know what \"100.0\" becomes.\n        # If BigNum128 uses 1e18 scale: 100.0 -> 100 * 10^18 = 10^20.\n        # 10_000_000_000 is 10^10. So it is negligible.\n    \n        # HOWEVER, the ReferralLedger used 10_000_000_000 for \"100 FLX\" which implies 1e8 scale.\n        # If BigNum128 uses 1e18, then the Ledger is emitting wrong units OR BigNum128 handles it.\n        # For this test, effectively we just want to see Balance_New = Balance_Old + Reward.\n    \n        old_balance = initial_bundle.flx_state[referrer_wallet]\n        new_balance = new_bundle.flx_state[referrer_wallet]\n    \n        expected_balance = cm.add(old_balance, BigNum128.from_int(reward_amount_scaled), [])\n    \n        assert new_balance.value == expected_balance.value\n        assert new_balance.value > old_balance.value\n    \n        # Check logs\n        found_log = False\n        for log in log_list:\n             if log.get('operation') == 'apply_referral_reward':\n                 if log.get('input', {}).get('wallet') == referrer_wallet:\n                     found_log = True\n                     break\n    \n        # Verify that we found the log entry\n>       assert found_log, \"Referral reward application was not logged\"\nE       AssertionError: Referral reward application was not logged\nE       assert False\n\nv13\\tests\\unit\\test_coherence_referral_integration.py:96: AssertionError"}, "hash": "373064e82c38d4d7754927dfd020a8a7444b87f0c8c67f3168d11458ba096cb24df7b17de9c0e708a5a6adc7572b1b5f8ed9e0e39d296652b0e9c33854e93cb1"}
{"timestamp": "2025-12-15T16:31:44.059721", "session_id": "be3f45186196f35c", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_coherence_referral_integration.py::TestCoherenceReferralIntegration::test_referral_reward_application", "context": {"env": "test"}, "details": {"duration": 0.0009006000000226777, "error": "self = <v13.tests.unit.test_coherence_referral_integration.TestCoherenceReferralIntegration object at 0x00000274C5362E90>\n\n    def test_referral_reward_application(self):\n        \"\"\"Test that CoherenceEngine correctly applies ReferralRewarded events to token state.\"\"\"\n        cm = CertifiedMath()\n        engine = CoherenceEngine(cm)\n    \n        # Initial State\n        referrer_wallet = \"0xReferrerWallet\"\n        initial_balance = \"100.0\"\n    \n        # Create initial bundle\n        initial_bundle = create_token_state_bundle(\n            chr_state={},\n            flx_state={referrer_wallet: BigNum128.from_string(initial_balance)},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128.from_int(1),\n            lambda2=BigNum128.from_int(1),\n            c_crit=BigNum128.from_int(1),\n            pqc_cid=\"test_cid\",\n            timestamp=1000\n        )\n    \n        # Create ReferralRewarded event\n        reward_amount_scaled = 10_000_000_000 # 100 FLX (1e8 scale)\n        # Note: BigNum128 from_string(\"100.0\") is 100 * 1e18? Or 1e8?\n        # CertifiedMath/BigNum128 typically uses 1e18 or 1e9 depending on impl.\n        # The event uses 'amount_scaled' which usually implies integer units.\n        # But BigNum128.from_int(x) creates a BigNum with internal value x.\n        # If TokenState uses fixed point 1e18, we need to match.\n        # Let's assume the event amount is already in the correct \"atomic units\" for BigNum128.\n        # If BigNum128 expects 18 decimals, 100 FLX = 100 * 10^18.\n        # If ReferralLedger uses 10_000_000_000 (10^10), that might be small if 18 decimals.\n        # Let's check CertifiedMath/BigNum128 implementation if possibly, but in test we can assert the addition.\n    \n        event = ReferralRewarded(\n            referrer_wallet=referrer_wallet,\n            referee_wallet=\"0xReferee\",\n            token_type=\"FLX\",\n            amount_scaled=reward_amount_scaled,\n            epoch=101,\n            reason=\"Test Reward\",\n            guard_cir_code=\"PASS\"\n        )\n    \n        log_list = []\n    \n        # Apply transition\n        new_bundle = engine.apply_hsmf_transition(\n            current_bundle=initial_bundle,\n            log_list=log_list,\n            pqc_cid=\"test_cid_2\",\n            deterministic_timestamp=1100,\n            processed_events=[event]\n        )\n    \n        # Verify result\n        # Initial: 100.0 (BigNum128 likely parses decimal string to fixed point)\n        # Added: 10_000_000_000 (raw int)\n    \n        # We need to know what \"100.0\" becomes.\n        # If BigNum128 uses 1e18 scale: 100.0 -> 100 * 10^18 = 10^20.\n        # 10_000_000_000 is 10^10. So it is negligible.\n    \n        # HOWEVER, the ReferralLedger used 10_000_000_000 for \"100 FLX\" which implies 1e8 scale.\n        # If BigNum128 uses 1e18, then the Ledger is emitting wrong units OR BigNum128 handles it.\n        # For this test, effectively we just want to see Balance_New = Balance_Old + Reward.\n    \n        old_balance = initial_bundle.flx_state[referrer_wallet]\n        new_balance = new_bundle.flx_state[referrer_wallet]\n    \n        expected_balance = cm.add(old_balance, BigNum128.from_int(reward_amount_scaled), [])\n    \n        assert new_balance.value == expected_balance.value\n        assert new_balance.value > old_balance.value\n    \n        # Check logs\n        found_log = False\n        for log in log_list:\n             if log.get('operation') == 'apply_referral_reward':\n                 if log.get('input', {}).get('wallet') == referrer_wallet:\n                     found_log = True\n                     break\n    \n        # Verify that we found the log entry\n>       assert found_log, \"Referral reward application was not logged\"\nE       AssertionError: Referral reward application was not logged\nE       assert False\n\nv13\\tests\\unit\\test_coherence_referral_integration.py:96: AssertionError"}, "hash": "43fe6c5578bfc7642608d3275a23fb61fe5c3a74f24d47cfea86d7d5922cdb8427c1c02d53a277f45b389a1536ef290be75bab60ad4ab8f18f704e2cb6e783c1"}
{"timestamp": "2025-12-15T16:32:23.415084", "session_id": "aefa306be4d8daf2", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_coherence_referral_integration.py::TestCoherenceReferralIntegration::test_referral_reward_application", "context": {"env": "test"}, "details": {"duration": 0.0015225000024656765, "error": "self = <v13.tests.unit.test_coherence_referral_integration.TestCoherenceReferralIntegration object at 0x0000020E5689F610>\n\n    def test_referral_reward_application(self):\n        \"\"\"Test that CoherenceEngine correctly applies ReferralRewarded events to token state.\"\"\"\n        cm = CertifiedMath()\n        engine = CoherenceEngine(cm)\n    \n        # Initial State\n        referrer_wallet = \"0xReferrerWallet\"\n        initial_balance = \"100.0\"\n    \n        # Create initial bundle\n        initial_bundle = create_token_state_bundle(\n            chr_state={},\n            flx_state={referrer_wallet: BigNum128.from_string(initial_balance)},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128.from_int(1),\n            lambda2=BigNum128.from_int(1),\n            c_crit=BigNum128.from_int(1),\n            pqc_cid=\"test_cid\",\n            timestamp=1000\n        )\n    \n        # Create ReferralRewarded event\n        reward_amount_scaled = 10_000_000_000 # 100 FLX (1e8 scale)\n        # Note: BigNum128 from_string(\"100.0\") is 100 * 1e18? Or 1e8?\n        # CertifiedMath/BigNum128 typically uses 1e18 or 1e9 depending on impl.\n        # The event uses 'amount_scaled' which usually implies integer units.\n        # But BigNum128.from_int(x) creates a BigNum with internal value x.\n        # If TokenState uses fixed point 1e18, we need to match.\n        # Let's assume the event amount is already in the correct \"atomic units\" for BigNum128.\n        # If BigNum128 expects 18 decimals, 100 FLX = 100 * 10^18.\n        # If ReferralLedger uses 10_000_000_000 (10^10), that might be small if 18 decimals.\n        # Let's check CertifiedMath/BigNum128 implementation if possibly, but in test we can assert the addition.\n    \n        event = ReferralRewarded(\n            referrer_wallet=referrer_wallet,\n            referee_wallet=\"0xReferee\",\n            token_type=\"FLX\",\n            amount_scaled=reward_amount_scaled,\n            epoch=101,\n            reason=\"Test Reward\",\n            guard_cir_code=\"PASS\"\n        )\n    \n        log_list = []\n    \n        # Apply transition\n        new_bundle = engine.apply_hsmf_transition(\n            current_bundle=initial_bundle,\n            log_list=log_list,\n            pqc_cid=\"test_cid_2\",\n            deterministic_timestamp=1100,\n            processed_events=[event]\n        )\n    \n        # Verify result\n        # Initial: 100.0 (BigNum128 likely parses decimal string to fixed point)\n        # Added: 10_000_000_000 (raw int)\n    \n        # We need to know what \"100.0\" becomes.\n        # If BigNum128 uses 1e18 scale: 100.0 -> 100 * 10^18 = 10^20.\n        # 10_000_000_000 is 10^10. So it is negligible.\n    \n        # HOWEVER, the ReferralLedger used 10_000_000_000 for \"100 FLX\" which implies 1e8 scale.\n        # If BigNum128 uses 1e18, then the Ledger is emitting wrong units OR BigNum128 handles it.\n        # For this test, effectively we just want to see Balance_New = Balance_Old + Reward.\n    \n        old_balance = initial_bundle.flx_state[referrer_wallet]\n        new_balance = new_bundle.flx_state[referrer_wallet]\n    \n        expected_balance = cm.add(old_balance, BigNum128.from_int(reward_amount_scaled), [])\n    \n        assert new_balance.value == expected_balance.value\n        assert new_balance.value > old_balance.value\n    \n        # Check logs\n        found_log = False\n        for log in log_list:\n             if log.get('operation') == 'apply_referral_reward':\n                 if log.get('input', {}).get('wallet') == referrer_wallet:\n                     found_log = True\n                     break\n    \n        # Verify that we found the log entry\n>       assert found_log, \"Referral reward application was not logged\"\nE       AssertionError: Referral reward application was not logged\nE       assert False\n\nv13\\tests\\unit\\test_coherence_referral_integration.py:96: AssertionError"}, "hash": "3c3b8903ab48c83075b1ed068e77bab68eb59670841295da0ac3ddd32aef8a76411dc354fabc150fb9702bdaf549223060b5edde36d6232489d12f43ba49d29e"}
{"timestamp": "2025-12-15T16:34:27.128126", "session_id": "178bae76e58b427a", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_ast_zerosimchecker_modules.py::test_golden_files", "context": {"env": "test"}, "details": {"duration": 0.0014646999989054166, "error": "def test_golden_files():\n        \"\"\"Test the static golden files for Zero-Sim compliance.\"\"\"\n        checker = AST_ZeroSimChecker()\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n    \n        pass_file = os.path.join(current_dir, \"unit\", \"zero_sim_golden_pass.py\")\n        if not os.path.exists(pass_file):\n             # Try expecting it in the same directory as this test\n             pass_file = os.path.join(current_dir, \"zero_sim_golden_pass.py\")\n             if not os.path.exists(pass_file):\n                 # Fallback to v13/tests/unit\n                 pass_file = os.path.join(current_dir, \"..\", \"unit\", \"zero_sim_golden_pass.py\")\n    \n        # Ensure file exists before testing\n        assert os.path.exists(pass_file), f\"Golden pass file not found at {pass_file}\"\n    \n        violations = checker.scan_file(pass_file)\n        assert len(violations) == 0, f\"Golden pass file has violations: {violations}\"\n    \n        fail_file = os.path.join(current_dir, \"unit\", \"zero_sim_golden_fail.py\")\n        if not os.path.exists(fail_file):\n             fail_file = os.path.join(current_dir, \"zero_sim_golden_fail.py\")\n             if not os.path.exists(fail_file):\n                 fail_file = os.path.join(current_dir, \"..\", \"unit\", \"zero_sim_golden_fail.py\")\n    \n        assert os.path.exists(fail_file), f\"Golden fail file not found at {fail_file}\"\n    \n        violations = checker.scan_file(fail_file)\n        assert len(violations) > 0, \"Golden fail file has no violations\"\n    \n        # Check for specific violations we expect\n        import_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_IMPORT\"]\n        call_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_CALL\"]\n    \n        assert len(import_violations) > 0, \"Golden fail file missing FORBIDDEN_IMPORT violation\"\n>       assert len(call_violations) > 0, \"Golden fail file missing FORBIDDEN_CALL violation\"\nE       AssertionError: Golden fail file missing FORBIDDEN_CALL violation\nE       assert 0 > 0\nE        +  where 0 = len([])\n\nv13\\tests\\test_ast_zerosimchecker_modules.py:182: AssertionError"}, "hash": "1f9ad35c89d51da9e401e8a6487aac9f693471a717318f445d827dd821e73ff365b240fca1adcab95c25a99276f57fb39e713237a309676057798e4caaecb83f"}
{"timestamp": "2025-12-15T16:35:01.911410", "session_id": "241564f7413d3c1c", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_ast_zerosimchecker_modules.py::test_golden_files", "context": {"env": "test"}, "details": {"duration": 0.0013873000025341753, "error": "def test_golden_files():\n        \"\"\"Test the static golden files for Zero-Sim compliance.\"\"\"\n        checker = AST_ZeroSimChecker()\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n    \n        pass_file = os.path.join(current_dir, \"unit\", \"zero_sim_golden_pass.py\")\n        if not os.path.exists(pass_file):\n             # Try expecting it in the same directory as this test\n             pass_file = os.path.join(current_dir, \"zero_sim_golden_pass.py\")\n             if not os.path.exists(pass_file):\n                 # Fallback to v13/tests/unit\n                 pass_file = os.path.join(current_dir, \"..\", \"unit\", \"zero_sim_golden_pass.py\")\n    \n        # Ensure file exists before testing\n        assert os.path.exists(pass_file), f\"Golden pass file not found at {pass_file}\"\n    \n        violations = checker.scan_file(pass_file)\n        assert len(violations) == 0, f\"Golden pass file has violations: {violations}\"\n    \n        fail_file = os.path.join(current_dir, \"unit\", \"zero_sim_golden_fail.py\")\n        if not os.path.exists(fail_file):\n             fail_file = os.path.join(current_dir, \"zero_sim_golden_fail.py\")\n             if not os.path.exists(fail_file):\n                 fail_file = os.path.join(current_dir, \"..\", \"unit\", \"zero_sim_golden_fail.py\")\n    \n        assert os.path.exists(fail_file), f\"Golden fail file not found at {fail_file}\"\n    \n        violations = checker.scan_file(fail_file)\n        assert len(violations) > 0, \"Golden fail file has no violations\"\n    \n        # Check for specific violations we expect\n        import_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_IMPORT\"]\n        call_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_CALL\"]\n    \n        assert len(import_violations) > 0, \"Golden fail file missing FORBIDDEN_IMPORT violation\"\n>       assert len(call_violations) > 0, \"Golden fail file missing FORBIDDEN_CALL violation\"\nE       AssertionError: Golden fail file missing FORBIDDEN_CALL violation\nE       assert 0 > 0\nE        +  where 0 = len([])\n\nv13\\tests\\test_ast_zerosimchecker_modules.py:182: AssertionError"}, "hash": "0493d1a0a9b4768c03548548bbfed0b95e9af91589a77b5560200fdce325d2a833d656233c4785ebe928f4bf2cd6d984ba5347c4a9bbffafb786397314a701dd"}
{"timestamp": "2025-12-15T16:36:17.459824", "session_id": "b38b8e521654a4fd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_ast_zerosimchecker_modules.py::test_golden_files", "context": {"env": "test"}, "details": {"duration": 0.001438600000255974, "error": "def test_golden_files():\n        \"\"\"Test the static golden files for Zero-Sim compliance.\"\"\"\n        checker = AST_ZeroSimChecker()\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n        # Assuming test is in v13/tests/ and compliance is in v13/compliance/\n        # Go up one level from tests/ to v13/\n        project_root = os.path.dirname(current_dir)\n    \n        pass_file = os.path.join(project_root, \"compliance\", \"golden_pass.py\")\n    \n        # Ensure file exists before testing\n        assert os.path.exists(pass_file), f\"Golden pass file not found at {pass_file}\"\n    \n        violations = checker.scan_file(pass_file)\n        assert len(violations) == 0, f\"Golden pass file has violations: {violations}\"\n    \n        fail_file = os.path.join(project_root, \"compliance\", \"golden_fail.py\")\n    \n        assert os.path.exists(fail_file), f\"Golden fail file not found at {fail_file}\"\n    \n        violations = checker.scan_file(fail_file)\n        assert len(violations) > 0, \"Golden fail file has no violations (check if it was excluded?)\"\n    \n        # Check for specific violations we expect\n        import_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_IMPORT\"]\n        call_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_CALL\"]\n    \n        assert len(import_violations) > 0, \"Golden fail file missing FORBIDDEN_IMPORT violation\"\n>       assert len(call_violations) > 0, \"Golden fail file missing FORBIDDEN_CALL violation\"\nE       AssertionError: Golden fail file missing FORBIDDEN_CALL violation\nE       assert 0 > 0\nE        +  where 0 = len([])\n\nv13\\tests\\test_ast_zerosimchecker_modules.py:175: AssertionError"}, "hash": "7166accc6f11a238868d51ed3585a5e6f0993259be3a9ce457b480ee4b6e236bb5d4f527dc73d9f9bdf4d7c8cbc14b1ca5f87e5dc0e0fadd26f11b47db8a04a5"}
{"timestamp": "2025-12-15T16:37:00.894866", "session_id": "3271182855e5e8c0", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_ast_zerosimchecker_modules.py::test_golden_files", "context": {"env": "test"}, "details": {"duration": 0.0016199000019696541, "error": "def test_golden_files():\n        \"\"\"Test the static golden files for Zero-Sim compliance.\"\"\"\n        checker = AST_ZeroSimChecker()\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n        # Assuming test is in v13/tests/ and compliance is in v13/compliance/\n        # Go up one level from tests/ to v13/\n        project_root = os.path.dirname(current_dir)\n    \n        pass_file = os.path.join(project_root, \"compliance\", \"golden_pass.py\")\n    \n        # Ensure file exists before testing\n        assert os.path.exists(pass_file), f\"Golden pass file not found at {pass_file}\"\n    \n        violations = checker.scan_file(pass_file)\n        assert len(violations) == 0, f\"Golden pass file has violations: {violations}\"\n    \n        fail_file = os.path.join(project_root, \"compliance\", \"golden_fail.py\")\n    \n        assert os.path.exists(fail_file), f\"Golden fail file not found at {fail_file}\"\n    \n        violations = checker.scan_file(fail_file)\n        print(f\"DEBUG: Scanned {fail_file}\")\n        print(f\"DEBUG: Found {len(violations)} violations: {violations}\")\n        assert len(violations) > 0, f\"Golden fail file has no violations (check if it was excluded?). Violations: {violations}\"\n    \n        # Check for specific violations we expect\n        import_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_IMPORT\"]\n        call_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_CALL\"]\n    \n        assert len(import_violations) > 0, \"Golden fail file missing FORBIDDEN_IMPORT violation\"\n>       assert len(call_violations) > 0, \"Golden fail file missing FORBIDDEN_CALL violation\"\nE       AssertionError: Golden fail file missing FORBIDDEN_CALL violation\nE       assert 0 > 0\nE        +  where 0 = len([])\n\nv13\\tests\\test_ast_zerosimchecker_modules.py:177: AssertionError"}, "hash": "1bfc36d7a4a3c4a328e2e57f433f4de3efe9fd9dbd3e4f23832062343542177ca271b1f2361f6b986d4278427d4a340ef41680dff6070a321c8f564198b35a2c"}
{"timestamp": "2025-12-15T16:37:45.530766", "session_id": "b6bf5684ac5f3967", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_ast_zerosimchecker_modules.py::test_golden_files", "context": {"env": "test"}, "details": {"duration": 0.0019815999985439703, "error": "def test_golden_files():\n        \"\"\"Test the static golden files for Zero-Sim compliance.\"\"\"\n        checker = AST_ZeroSimChecker()\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n        # Assuming test is in v13/tests/ and compliance is in v13/compliance/\n        # Go up one level from tests/ to v13/\n        project_root = os.path.dirname(current_dir)\n    \n        pass_file = os.path.join(project_root, \"compliance\", \"golden_pass.py\")\n    \n        # Ensure file exists before testing\n        assert os.path.exists(pass_file), f\"Golden pass file not found at {pass_file}\"\n    \n        violations = checker.scan_file(pass_file)\n        assert len(violations) == 0, f\"Golden pass file has violations: {violations}\"\n    \n        fail_file = os.path.join(project_root, \"compliance\", \"golden_fail.py\")\n    \n        assert os.path.exists(fail_file), f\"Golden fail file not found at {fail_file}\"\n    \n        violations = checker.scan_file(fail_file)\n        with open(\"debug_test_log.txt\", \"w\") as f:\n            f.write(f\"DEBUG: Scanned {fail_file}\\n\")\n            f.write(f\"DEBUG: Found {len(violations)} violations\\n\")\n            for v in violations:\n                 f.write(f\" Violation: {v}\\n\")\n    \n        assert len(violations) > 0, f\"Golden fail file has no violations (check if it was excluded?). Violations: {violations}\"\n    \n        # Check for specific violations we expect\n        import_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_IMPORT\"]\n        call_violations = [v for v in violations if v.violation_type == \"FORBIDDEN_CALL\"]\n    \n        assert len(import_violations) > 0, \"Golden fail file missing FORBIDDEN_IMPORT violation\"\n>       assert len(call_violations) > 0, \"Golden fail file missing FORBIDDEN_CALL violation\"\nE       AssertionError: Golden fail file missing FORBIDDEN_CALL violation\nE       assert 0 > 0\nE        +  where 0 = len([])\n\nv13\\tests\\test_ast_zerosimchecker_modules.py:181: AssertionError"}, "hash": "c12a54ef0d4a015e42c36310b4ded58ec7c965f6b616fa33a093744bba346c737862fccee7b58a1dacafc0c23d1222cdd15804cf937c1c706d62d62798ae9a8d"}
{"timestamp": "2025-12-15T16:58:51.263573", "session_id": "f9ecea376fe83453", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_referral_ledger_sync.py::test_referral_ledger_sync_flow", "context": {"env": "test"}, "details": {"duration": 0.004231200000504032, "error": "def test_referral_ledger_sync_flow():\n        # Setup\n        with CertifiedMath.LogContext() as log_list:\n            cm = CertifiedMath()\n    \n        coherence_ledger = CoherenceLedger(cm)\n        referral_ledger = ReferralLedger(coherence_ledger)\n    \n        referrer = \"wallet_referrer_123\"\n        referee = \"wallet_referee_456\"\n        epoch = 101\n    \n        # 1. Create Link (Synchronous)\n        code = referral_ledger.create_link(referrer, epoch, \"test_source\")\n        assert code is not None\n        assert len(coherence_ledger.ledger_entries) == 1\n        assert coherence_ledger.ledger_entries[0].entry_type == \"REFERRAL_CREATED\"\n    \n        # 2. Accept\n        referral_ledger.accept(code, referee, epoch, \"device_hash_abc\")\n        assert len(coherence_ledger.ledger_entries) == 2\n        assert coherence_ledger.ledger_entries[1].entry_type == \"REFERRAL_ACCEPTED\"\n    \n        # 3. Activate & Grant Reward\n        # Mock _count_referrals to make sure we hit a tier (e.g. 0 -> 1st referral)\n        referral_ledger._count_referrals = lambda w: 0\n    \n        referral_ledger.activate(referee, \"PROFILE_COMPLETE\", epoch)\n    \n        # Should have ACTIVATED and REWARDED events\n        assert len(coherence_ledger.ledger_entries) == 4\n        assert coherence_ledger.ledger_entries[2].entry_type == \"REFERRAL_ACTIVATED\"\n        assert coherence_ledger.ledger_entries[3].entry_type == \"REFERRAL_REWARDED\"\n    \n        reward_entry = coherence_ledger.ledger_entries[3]\n        event_data = reward_entry.data[\"event_data\"]\n        assert event_data[\"amount_scaled\"] == 10_000_000_000 # 100 FLX\n>       assert event_data[\"referrer_wallet\"] == referrer\nE       AssertionError: assert 'mock_referrer' == 'wallet_referrer_123'\nE         \nE         \u001b[0m\u001b[91m- wallet_referrer_123\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ mock_referrer\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\unit\\test_referral_ledger_sync.py:45: AssertionError"}, "hash": "20d3f197f654b5e584d452d73f52713a91bba418d9464413b00b6aca223ff325f54efd5119b60671adb4219c9a56c2511b72dbad9e2f58573a7353410ff0a7dc"}
{"timestamp": "2025-12-15T16:59:15.000366", "session_id": "4a3210341daf2cf9", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_referral_ledger_sync.py::test_referral_ledger_sync_flow", "context": {"env": "test"}, "details": {"duration": 0.0011421999988669995, "error": "def test_referral_ledger_sync_flow():\n        # Setup\n        with CertifiedMath.LogContext() as log_list:\n            cm = CertifiedMath()\n    \n        coherence_ledger = CoherenceLedger(cm)\n        referral_ledger = ReferralLedger(coherence_ledger)\n    \n        referrer = \"wallet_referrer_123\"\n        referee = \"wallet_referee_456\"\n        epoch = 101\n    \n        # 1. Create Link (Synchronous)\n        code = referral_ledger.create_link(referrer, epoch, \"test_source\")\n        assert code is not None\n        assert len(coherence_ledger.ledger_entries) == 1\n        assert coherence_ledger.ledger_entries[0].entry_type == \"REFERRAL_CREATED\"\n    \n        # 2. Accept\n        referral_ledger.accept(code, referee, epoch, \"device_hash_abc\")\n        assert len(coherence_ledger.ledger_entries) == 2\n        assert coherence_ledger.ledger_entries[1].entry_type == \"REFERRAL_ACCEPTED\"\n    \n        # 3. Activate & Grant Reward\n        # Mock _count_referrals to make sure we hit a tier (e.g. 0 -> 1st referral)\n        referral_ledger._count_referrals = lambda w: 0\n    \n        referral_ledger.activate(referee, \"PROFILE_COMPLETE\", epoch)\n    \n        # Should have ACTIVATED and REWARDED events\n        assert len(coherence_ledger.ledger_entries) == 4\n        assert coherence_ledger.ledger_entries[2].entry_type == \"REFERRAL_ACTIVATED\"\n        assert coherence_ledger.ledger_entries[3].entry_type == \"REFERRAL_REWARDED\"\n    \n        reward_entry = coherence_ledger.ledger_entries[3]\n        event_data = reward_entry.data[\"event_data\"]\n        assert event_data[\"amount_scaled\"] == 10_000_000_000 # 100 FLX\n>       assert event_data[\"referrer_wallet\"] == referrer\nE       AssertionError: assert 'mock_referrer' == 'wallet_referrer_123'\nE         \nE         \u001b[0m\u001b[91m- wallet_referrer_123\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ mock_referrer\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\unit\\test_referral_ledger_sync.py:45: AssertionError"}, "hash": "8db086ef4efe26d19ad63aff62dab8826075543dcc86f82e2a82885e5b141a446f9a7338fb5079e5b04ab587067a4a5dd892ab83a43bc76f9795e2d30469d9c6"}
{"timestamp": "2025-12-15T17:02:22.834186", "session_id": "5fa70496188e0d5a", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_referral_ledger_sync.py::test_referral_ledger_sync_flow", "context": {"env": "test"}, "details": {"duration": 0.0012002000003121793, "error": "def test_referral_ledger_sync_flow():\n        # Setup\n        with CertifiedMath.LogContext() as log_list:\n            cm = CertifiedMath()\n    \n        coherence_ledger = CoherenceLedger(cm)\n        referral_ledger = ReferralLedger(coherence_ledger)\n    \n        referrer = \"wallet_referrer_123\"\n        referee = \"wallet_referee_456\"\n        epoch = 101\n    \n        # 1. Create Link (Synchronous)\n        code = referral_ledger.create_link(referrer, epoch, \"test_source\")\n        assert code is not None\n        assert len(coherence_ledger.ledger_entries) == 1\n        assert coherence_ledger.ledger_entries[0].entry_type == \"REFERRAL_CREATED\"\n    \n        # 2. Accept\n        referral_ledger.accept(code, referee, epoch, \"device_hash_abc\")\n        assert len(coherence_ledger.ledger_entries) == 2\n        assert coherence_ledger.ledger_entries[1].entry_type == \"REFERRAL_ACCEPTED\"\n    \n        # 3. Activate & Grant Reward\n        # Mock _count_referrals to make sure we hit a tier (e.g. 0 -> 1st referral)\n        referral_ledger._count_referrals = lambda w: 0\n    \n        referral_ledger.activate(referee, \"PROFILE_COMPLETE\", epoch)\n    \n        # Should have ACTIVATED and REWARDED events\n        assert len(coherence_ledger.ledger_entries) == 4\n        assert coherence_ledger.ledger_entries[2].entry_type == \"REFERRAL_ACTIVATED\"\n        assert coherence_ledger.ledger_entries[3].entry_type == \"REFERRAL_REWARDED\"\n    \n        reward_entry = coherence_ledger.ledger_entries[3]\n        event_data = reward_entry.data[\"event_data\"]\n        assert event_data[\"amount_scaled\"] == 10_000_000_000 # 100 FLX\n>       assert event_data[\"referrer_wallet\"] == referrer\nE       AssertionError: assert 'mock_referrer' == 'wallet_referrer_123'\nE         \nE         - wallet_referrer_123\nE         + mock_referrer\n\nv13\\tests\\unit\\test_referral_ledger_sync.py:45: AssertionError"}, "hash": "eb9b1816e680081149d7c95cf87968d477f78dba7ddb7b9aee375fd420a04f74c233127925d483bd927514a1b7d8a7c8112e4d4fabd1c9a17869bc02974d06f2"}
{"timestamp": "2025-12-15T21:12:23.068676", "session_id": "c59ecba2f20b6669", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_phi_series.py::test_phi_series_basic_values", "context": {"env": "test"}, "details": {"duration": 0.00020650000078603625, "error": "def test_phi_series_basic_values():\n        \"\"\"Test phi_series function with basic values\"\"\"\n        with CertifiedMath.LogContext() as log:\n            # Test \u03c6(0) = 0\n            zero = BigNum128(0)\n>           result = CertifiedMath.safe_phi_series(zero, log)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: type object 'CertifiedMath' has no attribute 'safe_phi_series'\n\nv13\\tests\\unit\\test_phi_series.py:15: AttributeError"}, "hash": "bb180c682cab0eb30e83385b3364fc9e97c9b0a175db38844bdbed07ae302483905d644724b43ddcd2c01b7963895830691720f376b52b66c365f40e669e46ce"}
{"timestamp": "2025-12-15T21:12:23.079626", "session_id": "c59ecba2f20b6669", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_phi_series.py::test_phi_series_negative_values", "context": {"env": "test"}, "details": {"duration": 0.00018460000137565657, "error": "def test_phi_series_negative_values():\n        \"\"\"Test phi_series function with negative values\"\"\"\n        with CertifiedMath.LogContext() as log:\n            # Test \u03c6(-1)\n>           neg_one = BigNum128.from_int(-1)\n                      ^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\unit\\test_phi_series.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nv13\\libs\\BigNum128.py:42: in from_int\n    return cls(integer_val * cls.SCALE)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'BigNum128' object has no attribute 'value'\") raised in repr()] BigNum128 object at 0x198583e3bb0>, value = -1000000000000000000\n\n    def __init__(self, value: int):\n        if not isinstance(value, int):\n            raise TypeError(\"BigNum128 only accepts integers\")\n        if value < self.MIN_VALUE or value > self.MAX_VALUE:\n>           raise OverflowError(\n                f\"BigNum128 value {value} out of bounds [{self.MIN_VALUE}, {self.MAX_VALUE}]\"\n            )\nE           OverflowError: BigNum128 value -1000000000000000000 out of bounds [0, 340282366920938463463374607431768211455]\n\nv13\\libs\\BigNum128.py:34: OverflowError"}, "hash": "6727cb447847f1f3ca42e19399ab9e2dd740aa6b1744d295630d3002be15b258d5e3fedd3127bdd9cd2d2c776bc92653a7334947a5cfce896a26469f00727d0b"}
{"timestamp": "2025-12-15T21:12:23.084430", "session_id": "c59ecba2f20b6669", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_phi_series.py::test_phi_series_half_values", "context": {"env": "test"}, "details": {"duration": 0.00017830000433605164, "error": "def test_phi_series_half_values():\n        \"\"\"Test phi_series function with 0.5\"\"\"\n        with CertifiedMath.LogContext() as log:\n            # Test \u03c6(0.5)\n            half = BigNum128(500000000000000000)  # 0.5 * 1e18\n>           result = CertifiedMath.safe_phi_series(half, log, n=20)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: type object 'CertifiedMath' has no attribute 'safe_phi_series'\n\nv13\\tests\\unit\\test_phi_series.py:40: AttributeError"}, "hash": "511fbd80af573c885242d06211de1571a17f38f1b28ef33226a323c9c99a3d4f8e88222309c49aeaf6e99ab8c1e665b1334bcf0ce8053040a2c2e7a10eedbf77"}
{"timestamp": "2025-12-15T21:12:23.089063", "session_id": "c59ecba2f20b6669", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_phi_series.py::test_phi_series_deterministic", "context": {"env": "test"}, "details": {"duration": 0.00017659999866737053, "error": "def test_phi_series_deterministic():\n        \"\"\"Test that phi_series produces deterministic results\"\"\"\n        # Run the same calculation twice and ensure results are identical\n        with CertifiedMath.LogContext() as log1:\n            val = BigNum128.from_int(1)\n>           result1 = CertifiedMath.safe_phi_series(val, log1, n=15)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: type object 'CertifiedMath' has no attribute 'safe_phi_series'\n\nv13\\tests\\unit\\test_phi_series.py:50: AttributeError"}, "hash": "e91ceca9c7f4bcbfac59659e8ca900c2c85ad2470e946252deeb9f5e12b0ad9d67d0b09613138f048ff5bca6315637fafb590f44b702f2be58968d0b22b12212"}
{"timestamp": "2025-12-15T21:12:23.094054", "session_id": "c59ecba2f20b6669", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_phi_series.py::test_phi_series_convergence", "context": {"env": "test"}, "details": {"duration": 0.00019699999393196777, "error": "def test_phi_series_convergence():\n        \"\"\"Test that increasing terms improves convergence\"\"\"\n        with CertifiedMath.LogContext() as log10:\n            val = BigNum128.from_int(1)\n>           result10 = CertifiedMath.safe_phi_series(val, log10, n=10)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: type object 'CertifiedMath' has no attribute 'safe_phi_series'\n\nv13\\tests\\unit\\test_phi_series.py:65: AttributeError"}, "hash": "ece0dd4689e1d498073c5843c86591257c0ae0ab27965181de7a98f7f34ccbe70a6a5c566e386881ebaa7e1bd2bf051c3f0821cadff1fada3284cdb0d29b2caf"}
{"timestamp": "2025-12-15T21:30:43.095837", "session_id": "e1a144d4441bce99", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_openagi_dm_integration.py::test_simulation_role_create_thread", "context": {"env": "test"}, "details": {"duration": 0.00036559999716700986, "error": "def test_simulation_role_create_thread():\n        \"\"\"OPEN-AGI simulation role creates a DM thread.\"\"\"\n        dm_service = DirectMessagingService()\n        adapter = OpenAGIDMAdapter(dm_service, scope=\"SIMULATION\")\n    \n        result = adapter.dm_create_thread(\"sim_user_1\", \"sim_user_2\")\n    \n>       assert \"thread_id\" in result\nE       AssertionError: assert 'thread_id' in {'error': 'RECIPIENT_NOT_FOUND'}\n\nv13\\tests\\unit\\test_openagi_dm_integration.py:18: AssertionError"}, "hash": "abceb3e3b61557432520b9afb28bdf10885f3e927104539e30aa7feff8a75da412852a0f6a75c94dc6b061ff1786995239217e046a97f7a6a3bad933887e2d3d"}
{"timestamp": "2025-12-15T21:30:43.204727", "session_id": "e1a144d4441bce99", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_openagi_dm_integration.py::test_dm_event_determinism", "context": {"env": "test"}, "details": {"duration": 0.00024879999546101317, "error": "def test_dm_event_determinism():\n        \"\"\"Same inputs produce same event structure.\"\"\"\n        dm_service = DirectMessagingService()\n        adapter = OpenAGIDMAdapter(dm_service, scope=\"SIMULATION\")\n    \n        result1 = adapter.dm_create_thread(\"user_a\", \"user_b\")\n        result2 = adapter.dm_create_thread(\"user_a\", \"user_b\")\n    \n        # Thread IDs should be deterministic\n>       assert result1[\"thread_id\"] == result2[\"thread_id\"]\n               ^^^^^^^^^^^^^^^^^^^^\nE       KeyError: 'thread_id'\n\nv13\\tests\\unit\\test_openagi_dm_integration.py:82: KeyError"}, "hash": "3f0ba83b5a45a2c65a294ad018fc94db8ea781ee44072448768000b05cdc3f2a17c7e5a5effbb7b07ce8f908b5e63eec7eea2d9170913df6e9c0532abf9e0188"}
{"timestamp": "2025-12-17T08:50:15.168283", "session_id": "dc36a023c4fd205d", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_audit_integrity.py::test_tamper_detection_chain", "context": {"env": "test"}, "details": {"duration": 0.00029689999064430594, "error": "def test_tamper_detection_chain():\n        \"\"\"Verify chain integrity checks.\"\"\"\n        prev_hash = \"abc12345\"\n    \n        # 1. Valid Record\n        record = {\n            \"prev_hash\": prev_hash,\n            \"action\": \"Legit Action\",\n            \"hash\": \"\" # Placeholder\n        }\n        # Calculate self hash excluding 'hash'\n        import json, hashlib\n        to_hash = {k: v for k, v in record.items() if k != \"hash\"}\n        json_str = json.dumps(to_hash, sort_keys=True, separators=(',', ':'))\n        record[\"hash\"] = hashlib.sha256(json_str.encode('utf-8')).hexdigest()\n    \n>       result = detect_tampering(record, prev_hash)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\test_audit_integrity.py:54: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrecord = {'action': 'Legit Action', 'hash': 'd2eb7db6c6ef8b2493fb5b004c02bd65443276cab0942daedb2b01338fb02c03', 'prev_hash': 'abc12345'}\nprevious_hash = 'abc12345'\n\n    def detect_tampering(record: Dict[str, Any], previous_hash: str) -> Dict[str, Any]:\n        \"\"\"\n        Check a chain entry for tampering.\n    \n        Args:\n            record: The current audit log entry.\n            previous_hash: The hash of the previous entry in the chain.\n    \n        Returns:\n            Dict with 'valid' (bool) and 'error' (str, optional).\n        \"\"\"\n        # Verify strict chaining\n        if record.get(\"prev_hash\") != previous_hash:\n            return {\"valid\": False, \"error\": \"BROKEN_CHAIN_LINK\"}\n    \n        # Recalculate own hash\n        # Exclude 'hash' field from calculation\n            # Deterministic hashing of record fields (excluding hash itself)\n            # Sort items by key\n            sorted_items = sorted(record.items())\n            data_to_hash = {}\n            for i in range(len(sorted_items)):\n                k, v = sorted_items[i]\n                if k != \"hash\":\n                    data_to_hash[k] = v\n>       verified = verify_explanation_integrity(data_to_hash, record.get(\"hash\", \"\"))\n                                                ^^^^^^^^^^^^\nE       UnboundLocalError: cannot access local variable 'data_to_hash' where it is not associated with a value\n\nv13\\core\\audit_integrity.py:69: UnboundLocalError"}, "hash": "8e2f04fc48f6a61fb5fb52a0062f8e6b00074f85ca4ab17b134e1feb415bb127df3ed3e560b028bf367e45051009a447af1316b5ae0682fc7a3b58728cd43d41"}
{"timestamp": "2025-12-17T08:50:44.027908", "session_id": "c3a79579c5c3c65b", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_audit_integrity.py::test_tamper_detection_chain", "context": {"env": "test"}, "details": {"duration": 0.0003313999914098531, "error": "def test_tamper_detection_chain():\n        \"\"\"Verify chain integrity checks.\"\"\"\n        prev_hash = \"abc12345\"\n    \n        # 1. Valid Record\n        record = {\n            \"prev_hash\": prev_hash,\n            \"action\": \"Legit Action\",\n            \"hash\": \"\" # Placeholder\n        }\n        # Calculate self hash excluding 'hash'\n        import json, hashlib\n        to_hash = {k: v for k, v in record.items() if k != \"hash\"}\n        json_str = json.dumps(to_hash, sort_keys=True, separators=(',', ':'))\n        record[\"hash\"] = hashlib.sha256(json_str.encode('utf-8')).hexdigest()\n    \n>       result = detect_tampering(record, prev_hash)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\test_audit_integrity.py:54: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrecord = {'action': 'Legit Action', 'hash': 'd2eb7db6c6ef8b2493fb5b004c02bd65443276cab0942daedb2b01338fb02c03', 'prev_hash': 'abc12345'}\nprevious_hash = 'abc12345'\n\n    def detect_tampering(record: Dict[str, Any], previous_hash: str) -> Dict[str, Any]:\n        \"\"\"\n        Check a chain entry for tampering.\n    \n        Args:\n            record: The current audit log entry.\n            previous_hash: The hash of the previous entry in the chain.\n    \n        Returns:\n            Dict with 'valid' (bool) and 'error' (str, optional).\n        \"\"\"\n        # Verify strict chaining\n        if record.get(\"prev_hash\") != previous_hash:\n            return {\"valid\": False, \"error\": \"BROKEN_CHAIN_LINK\"}\n    \n        # Recalculate own hash\n        # Exclude 'hash' field from calculation\n            # Deterministic hashing of record fields (excluding hash itself)\n            # Sort items by key\n            sorted_items = sorted(record.items())\n            data_to_hash = {}\n            for i in range(len(sorted_items)):\n                k, v = sorted_items[i]\n                if k != \"hash\":\n                    data_to_hash[k] = v\n>       verified = verify_explanation_integrity(data_to_hash, record.get(\"hash\", \"\"))\n                                                ^^^^^^^^^^^^\nE       UnboundLocalError: cannot access local variable 'data_to_hash' where it is not associated with a value\n\nv13\\core\\audit_integrity.py:69: UnboundLocalError"}, "hash": "704b5635869ae8e6b309ed6663b9c19aac08f085a59e5d0bcc02d3da09a00fe6d1abed75fc7d3a41beb7058dad500ef43b1be2d772fb1d10edee49af8b7b3963"}
<<<<<<< HEAD
{"timestamp": "2025-12-17T09:45:31.587612", "session_id": "a280672b2fade2a3", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/governance/test_appeals_deterministic.py::test_scoring_determinism", "context": {"env": "test"}, "details": {"duration": 0.00037360002170316875, "error": "def test_scoring_determinism():\n        \"\"\"Same votes + same evidence must yield same score.\"\"\"\n        evidence = {\"id\": \"ev_001\", \"content\": \"spam\"}\n        votes = [\n            Vote(voter_id=\"alice\", reputation=1000, approve=True),  # +1000\n            Vote(voter_id=\"bob\", reputation=500, approve=False),  # -500\n        ]\n    \n        # Net = 500. Threshold = 400. -> Approved.\n>       res1 = score_appeal(evidence, votes, threshold=400)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\governance\\test_appeals_deterministic.py:21: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nevidence_payload = {'content': 'spam', 'id': 'ev_001'}\nvotes = [Vote(voter_id='alice', reputation=1000, approve=True, weight=100), Vote(voter_id='bob', reputation=500, approve=False, weight=100)], threshold = 400\n\n    def score_appeal(\n        evidence_payload: Dict[str, Any],\n        votes: List[Vote],\n        threshold: int = 5000,  # 50.00 ATR\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate the final score for an appeal.\n    \n        Args:\n            evidence_payload: The raw evidence dictionary.\n            votes: List of cast votes.\n            threshold: Score required for approval (Scale 100).\n    \n        Returns:\n            Dict with 'approved' (bool), 'score' (int), 'hash' (str).\n        \"\"\"\n        # 1. Canonical Hash (The 'Seed')\n        ev_hash = hash_evidence(evidence_payload)\n    \n        # 2. Calculate Tally using CertifiedMath\n        # We use basic integer math here as CertifiedMath wrappers are mainly for\n        # complex funcs (log, exp) or safe division. For additions, standard int matches\n        # Zero-Sim if inputs are integers.\n    \n        score_approve = 0\n        score_reject = 0\n    \n        for v in votes:\n            # Weight = VoteWeight * (Reputation / 100)\n            # Scale: weight(100) * rep(1000) / 100 = 1000.\n            # Use CertifiedMath for division to be safe and consistent.\n    \n            # effective_weight = (v.weight * v.reputation) // 100\n>           effective_weight = CertifiedMath.idiv(v.weight * v.reputation, 100)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\governance\\appeals.py:63: TypeError"}, "hash": "f71bb50338226e17ea57fb1a05b3781e404a842086ef10b74c4fd07123a20d7496a875f711af1298f1dbf273853344769e155526c7a12a28677399513a9a55f1"}
{"timestamp": "2025-12-17T09:45:31.616938", "session_id": "a280672b2fade2a3", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/governance/test_appeals_deterministic.py::test_scoring_threshold_failure", "context": {"env": "test"}, "details": {"duration": 0.00033870001789182425, "error": "def test_scoring_threshold_failure():\n        \"\"\"Net score below threshold -> Rejected.\"\"\"\n        evidence = {\"id\": \"ev_002\"}\n        votes = [\n            Vote(voter_id=\"alice\", reputation=200, approve=True)  # +200\n        ]\n    \n>       res = score_appeal(evidence, votes, threshold=500)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\governance\\test_appeals_deterministic.py:36: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nevidence_payload = {'id': 'ev_002'}, votes = [Vote(voter_id='alice', reputation=200, approve=True, weight=100)], threshold = 500\n\n    def score_appeal(\n        evidence_payload: Dict[str, Any],\n        votes: List[Vote],\n        threshold: int = 5000,  # 50.00 ATR\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate the final score for an appeal.\n    \n        Args:\n            evidence_payload: The raw evidence dictionary.\n            votes: List of cast votes.\n            threshold: Score required for approval (Scale 100).\n    \n        Returns:\n            Dict with 'approved' (bool), 'score' (int), 'hash' (str).\n        \"\"\"\n        # 1. Canonical Hash (The 'Seed')\n        ev_hash = hash_evidence(evidence_payload)\n    \n        # 2. Calculate Tally using CertifiedMath\n        # We use basic integer math here as CertifiedMath wrappers are mainly for\n        # complex funcs (log, exp) or safe division. For additions, standard int matches\n        # Zero-Sim if inputs are integers.\n    \n        score_approve = 0\n        score_reject = 0\n    \n        for v in votes:\n            # Weight = VoteWeight * (Reputation / 100)\n            # Scale: weight(100) * rep(1000) / 100 = 1000.\n            # Use CertifiedMath for division to be safe and consistent.\n    \n            # effective_weight = (v.weight * v.reputation) // 100\n>           effective_weight = CertifiedMath.idiv(v.weight * v.reputation, 100)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\governance\\appeals.py:63: TypeError"}, "hash": "70bffdafe147a0490fef7d021879ac07f7bceaa7ff0139ad2b0c98d2fd2abecdd88e315cbbd8e73290a000ea645f8027037c37c3576b5833b40535326e91c51d"}
{"timestamp": "2025-12-17T09:45:31.683443", "session_id": "a280672b2fade2a3", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/governance/test_appeals_deterministic.py::test_rounding_safety", "context": {"env": "test"}, "details": {"duration": 0.0003039000148419291, "error": "def test_rounding_safety():\n        \"\"\"Verify integer division behavior via CertifiedMath.\"\"\"\n        # Weight 100 * Rep 55 // 100 = 55\n        votes = [Vote(voter_id=\"v\", reputation=55, approve=True)]\n>       res = score_appeal({}, votes, threshold=0)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\governance\\test_appeals_deterministic.py:45: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nevidence_payload = {}, votes = [Vote(voter_id='v', reputation=55, approve=True, weight=100)], threshold = 0\n\n    def score_appeal(\n        evidence_payload: Dict[str, Any],\n        votes: List[Vote],\n        threshold: int = 5000,  # 50.00 ATR\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate the final score for an appeal.\n    \n        Args:\n            evidence_payload: The raw evidence dictionary.\n            votes: List of cast votes.\n            threshold: Score required for approval (Scale 100).\n    \n        Returns:\n            Dict with 'approved' (bool), 'score' (int), 'hash' (str).\n        \"\"\"\n        # 1. Canonical Hash (The 'Seed')\n        ev_hash = hash_evidence(evidence_payload)\n    \n        # 2. Calculate Tally using CertifiedMath\n        # We use basic integer math here as CertifiedMath wrappers are mainly for\n        # complex funcs (log, exp) or safe division. For additions, standard int matches\n        # Zero-Sim if inputs are integers.\n    \n        score_approve = 0\n        score_reject = 0\n    \n        for v in votes:\n            # Weight = VoteWeight * (Reputation / 100)\n            # Scale: weight(100) * rep(1000) / 100 = 1000.\n            # Use CertifiedMath for division to be safe and consistent.\n    \n            # effective_weight = (v.weight * v.reputation) // 100\n>           effective_weight = CertifiedMath.idiv(v.weight * v.reputation, 100)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\governance\\appeals.py:63: TypeError"}, "hash": "b2d0467644e27e13d5fb3817639c5939e3706752cf30669b2b4489c820d2fe439ca616fe606337aa24d13a8d0a69a529de3739db51172e800b5b9ec9c9a7e074"}
{"timestamp": "2025-12-17T09:45:54.131718", "session_id": "dc5b1602591e8c18", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/governance/test_appeals_deterministic.py::test_scoring_determinism", "context": {"env": "test"}, "details": {"duration": 0.000282000022707507, "error": "def test_scoring_determinism():\n        \"\"\"Same votes + same evidence must yield same score.\"\"\"\n        evidence = {\"id\": \"ev_001\", \"content\": \"spam\"}\n        votes = [\n            Vote(voter_id=\"alice\", reputation=1000, approve=True),  # +1000\n            Vote(voter_id=\"bob\", reputation=500, approve=False),  # -500\n        ]\n    \n        # Net = 500. Threshold = 400. -> Approved.\n>       res1 = score_appeal(evidence, votes, threshold=400)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\governance\\test_appeals_deterministic.py:21: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nevidence_payload = {'content': 'spam', 'id': 'ev_001'}\nvotes = [Vote(voter_id='alice', reputation=1000, approve=True, weight=100), Vote(voter_id='bob', reputation=500, approve=False, weight=100)], threshold = 400\n\n    def score_appeal(\n        evidence_payload: Dict[str, Any],\n        votes: List[Vote],\n        threshold: int = 5000,  # 50.00 ATR\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate the final score for an appeal.\n    \n        Args:\n            evidence_payload: The raw evidence dictionary.\n            votes: List of cast votes.\n            threshold: Score required for approval (Scale 100).\n    \n        Returns:\n            Dict with 'approved' (bool), 'score' (int), 'hash' (str).\n        \"\"\"\n        # 1. Canonical Hash (The 'Seed')\n        ev_hash = hash_evidence(evidence_payload)\n    \n        # 2. Calculate Tally using CertifiedMath\n        # We use basic integer math here as CertifiedMath wrappers are mainly for\n        # complex funcs (log, exp) or safe division. For additions, standard int matches\n        # Zero-Sim if inputs are integers.\n    \n        score_approve = 0\n        score_reject = 0\n    \n        for v in votes:\n            # Weight = VoteWeight * (Reputation / 100)\n            # Scale: weight(100) * rep(1000) / 100 = 1000.\n            # Use CertifiedMath for division to be safe and consistent.\n    \n            # effective_weight = (v.weight * v.reputation) // 100\n>           effective_weight = CertifiedMath.idiv(v.weight * v.reputation, 100)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\governance\\appeals.py:63: TypeError"}, "hash": "bfebb7e27658bc70637815c733df04f755389740b60e695a0a8eaa85d319f2a1a9ce750f9aff83406f8e775638a97658e1ac771fce265737275416bec842477c"}
{"timestamp": "2025-12-17T09:45:54.140551", "session_id": "dc5b1602591e8c18", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/governance/test_appeals_deterministic.py::test_scoring_threshold_failure", "context": {"env": "test"}, "details": {"duration": 0.00025770001229830086, "error": "def test_scoring_threshold_failure():\n        \"\"\"Net score below threshold -> Rejected.\"\"\"\n        evidence = {\"id\": \"ev_002\"}\n        votes = [\n            Vote(voter_id=\"alice\", reputation=200, approve=True)  # +200\n        ]\n    \n>       res = score_appeal(evidence, votes, threshold=500)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\governance\\test_appeals_deterministic.py:36: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nevidence_payload = {'id': 'ev_002'}, votes = [Vote(voter_id='alice', reputation=200, approve=True, weight=100)], threshold = 500\n\n    def score_appeal(\n        evidence_payload: Dict[str, Any],\n        votes: List[Vote],\n        threshold: int = 5000,  # 50.00 ATR\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate the final score for an appeal.\n    \n        Args:\n            evidence_payload: The raw evidence dictionary.\n            votes: List of cast votes.\n            threshold: Score required for approval (Scale 100).\n    \n        Returns:\n            Dict with 'approved' (bool), 'score' (int), 'hash' (str).\n        \"\"\"\n        # 1. Canonical Hash (The 'Seed')\n        ev_hash = hash_evidence(evidence_payload)\n    \n        # 2. Calculate Tally using CertifiedMath\n        # We use basic integer math here as CertifiedMath wrappers are mainly for\n        # complex funcs (log, exp) or safe division. For additions, standard int matches\n        # Zero-Sim if inputs are integers.\n    \n        score_approve = 0\n        score_reject = 0\n    \n        for v in votes:\n            # Weight = VoteWeight * (Reputation / 100)\n            # Scale: weight(100) * rep(1000) / 100 = 1000.\n            # Use CertifiedMath for division to be safe and consistent.\n    \n            # effective_weight = (v.weight * v.reputation) // 100\n>           effective_weight = CertifiedMath.idiv(v.weight * v.reputation, 100)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\governance\\appeals.py:63: TypeError"}, "hash": "75005db28e126d384a9e0a3eba8e6beab959402094011c82a075e78ffe560c6bad22593c8e85feb887f4bf52db77373b4ad9cf39455ce7c2847714a200a097c5"}
{"timestamp": "2025-12-17T09:45:54.148415", "session_id": "dc5b1602591e8c18", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/governance/test_appeals_deterministic.py::test_rounding_safety", "context": {"env": "test"}, "details": {"duration": 0.00023029997828416526, "error": "def test_rounding_safety():\n        \"\"\"Verify integer division behavior via CertifiedMath.\"\"\"\n        # Weight 100 * Rep 55 // 100 = 55\n        votes = [Vote(voter_id=\"v\", reputation=55, approve=True)]\n>       res = score_appeal({}, votes, threshold=0)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\governance\\test_appeals_deterministic.py:45: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nevidence_payload = {}, votes = [Vote(voter_id='v', reputation=55, approve=True, weight=100)], threshold = 0\n\n    def score_appeal(\n        evidence_payload: Dict[str, Any],\n        votes: List[Vote],\n        threshold: int = 5000,  # 50.00 ATR\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate the final score for an appeal.\n    \n        Args:\n            evidence_payload: The raw evidence dictionary.\n            votes: List of cast votes.\n            threshold: Score required for approval (Scale 100).\n    \n        Returns:\n            Dict with 'approved' (bool), 'score' (int), 'hash' (str).\n        \"\"\"\n        # 1. Canonical Hash (The 'Seed')\n        ev_hash = hash_evidence(evidence_payload)\n    \n        # 2. Calculate Tally using CertifiedMath\n        # We use basic integer math here as CertifiedMath wrappers are mainly for\n        # complex funcs (log, exp) or safe division. For additions, standard int matches\n        # Zero-Sim if inputs are integers.\n    \n        score_approve = 0\n        score_reject = 0\n    \n        for v in votes:\n            # Weight = VoteWeight * (Reputation / 100)\n            # Scale: weight(100) * rep(1000) / 100 = 1000.\n            # Use CertifiedMath for division to be safe and consistent.\n    \n            # effective_weight = (v.weight * v.reputation) // 100\n>           effective_weight = CertifiedMath.idiv(v.weight * v.reputation, 100)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\governance\\appeals.py:63: TypeError"}, "hash": "6453aa781c8199aafba0905324b6f8eca7f5679f12f869b052e4b2934bca95ae75683241b5c17b7d1bb80acadfa890f7be6a26d13ef35525b3b284f4b48fbf64"}
{"timestamp": "2025-12-17T09:47:07.085291", "session_id": "c5ed0a32e27a13b0", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/governance/test_appeals_deterministic.py::test_scoring_determinism", "context": {"env": "test"}, "details": {"duration": 0.0002838000073097646, "error": "def test_scoring_determinism():\n        \"\"\"Same votes + same evidence must yield same score.\"\"\"\n        evidence = {\"id\": \"ev_001\", \"content\": \"spam\"}\n        votes = [\n            Vote(voter_id=\"alice\", reputation=1000, approve=True),  # +1000\n            Vote(voter_id=\"bob\", reputation=500, approve=False),  # -500\n        ]\n    \n        # Net = 500. Threshold = 400. -> Approved.\n>       res1 = score_appeal(evidence, votes, threshold=400)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\governance\\test_appeals_deterministic.py:21: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nevidence_payload = {'content': 'spam', 'id': 'ev_001'}\nvotes = [Vote(voter_id='alice', reputation=1000, approve=True, weight=100), Vote(voter_id='bob', reputation=500, approve=False, weight=100)], threshold = 400\n\n    def score_appeal(\n        evidence_payload: Dict[str, Any],\n        votes: List[Vote],\n        threshold: int = 5000,  # 50.00 ATR\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate the final score for an appeal.\n    \n        Args:\n            evidence_payload: The raw evidence dictionary.\n            votes: List of cast votes.\n            threshold: Score required for approval (Scale 100).\n    \n        Returns:\n            Dict with 'approved' (bool), 'score' (int), 'hash' (str).\n        \"\"\"\n        # 1. Canonical Hash (The 'Seed')\n        ev_hash = hash_evidence(evidence_payload)\n    \n        # 2. Calculate Tally using CertifiedMath\n        # We use basic integer math here as CertifiedMath wrappers are mainly for\n        # complex funcs (log, exp) or safe division. For additions, standard int matches\n        # Zero-Sim if inputs are integers.\n    \n        score_approve = 0\n        score_reject = 0\n    \n        for v in votes:\n            # Weight = VoteWeight * (Reputation / 100)\n            # Scale: weight(100) * rep(1000) / 100 = 1000.\n            # Use CertifiedMath for division to be safe and consistent.\n    \n            # effective_weight = (v.weight * v.reputation) // 100\n>           effective_weight = CertifiedMath.idiv(v.weight * v.reputation, 100)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\governance\\appeals.py:63: TypeError"}, "hash": "6c5c76017adc2b8d3a2132a16fe8d1f5792d4f4dda101c3d5e35d9a2295e2af87121cfa7018f63ea2fcef7bdec517021532e1bf6d3424e1e4a8ea3e8214d0dd5"}
{"timestamp": "2025-12-17T09:47:07.091677", "session_id": "c5ed0a32e27a13b0", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/governance/test_appeals_deterministic.py::test_scoring_threshold_failure", "context": {"env": "test"}, "details": {"duration": 0.00024679998750798404, "error": "def test_scoring_threshold_failure():\n        \"\"\"Net score below threshold -> Rejected.\"\"\"\n        evidence = {\"id\": \"ev_002\"}\n        votes = [\n            Vote(voter_id=\"alice\", reputation=200, approve=True)  # +200\n        ]\n    \n>       res = score_appeal(evidence, votes, threshold=500)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\governance\\test_appeals_deterministic.py:36: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nevidence_payload = {'id': 'ev_002'}, votes = [Vote(voter_id='alice', reputation=200, approve=True, weight=100)], threshold = 500\n\n    def score_appeal(\n        evidence_payload: Dict[str, Any],\n        votes: List[Vote],\n        threshold: int = 5000,  # 50.00 ATR\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate the final score for an appeal.\n    \n        Args:\n            evidence_payload: The raw evidence dictionary.\n            votes: List of cast votes.\n            threshold: Score required for approval (Scale 100).\n    \n        Returns:\n            Dict with 'approved' (bool), 'score' (int), 'hash' (str).\n        \"\"\"\n        # 1. Canonical Hash (The 'Seed')\n        ev_hash = hash_evidence(evidence_payload)\n    \n        # 2. Calculate Tally using CertifiedMath\n        # We use basic integer math here as CertifiedMath wrappers are mainly for\n        # complex funcs (log, exp) or safe division. For additions, standard int matches\n        # Zero-Sim if inputs are integers.\n    \n        score_approve = 0\n        score_reject = 0\n    \n        for v in votes:\n            # Weight = VoteWeight * (Reputation / 100)\n            # Scale: weight(100) * rep(1000) / 100 = 1000.\n            # Use CertifiedMath for division to be safe and consistent.\n    \n            # effective_weight = (v.weight * v.reputation) // 100\n>           effective_weight = CertifiedMath.idiv(v.weight * v.reputation, 100)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\governance\\appeals.py:63: TypeError"}, "hash": "7c3525099bd896be56cc24cfb09cd92dc4d554623b36f6951f6f95afe83e1b17fe48447b54d54c6afa542c4444c662209ac452ffd8f61fd803ead959cab8a814"}
{"timestamp": "2025-12-17T09:47:07.097413", "session_id": "c5ed0a32e27a13b0", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/governance/test_appeals_deterministic.py::test_rounding_safety", "context": {"env": "test"}, "details": {"duration": 0.00020939999376423657, "error": "def test_rounding_safety():\n        \"\"\"Verify integer division behavior via CertifiedMath.\"\"\"\n        # Weight 100 * Rep 55 // 100 = 55\n        votes = [Vote(voter_id=\"v\", reputation=55, approve=True)]\n>       res = score_appeal({}, votes, threshold=0)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\governance\\test_appeals_deterministic.py:45: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nevidence_payload = {}, votes = [Vote(voter_id='v', reputation=55, approve=True, weight=100)], threshold = 0\n\n    def score_appeal(\n        evidence_payload: Dict[str, Any],\n        votes: List[Vote],\n        threshold: int = 5000,  # 50.00 ATR\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate the final score for an appeal.\n    \n        Args:\n            evidence_payload: The raw evidence dictionary.\n            votes: List of cast votes.\n            threshold: Score required for approval (Scale 100).\n    \n        Returns:\n            Dict with 'approved' (bool), 'score' (int), 'hash' (str).\n        \"\"\"\n        # 1. Canonical Hash (The 'Seed')\n        ev_hash = hash_evidence(evidence_payload)\n    \n        # 2. Calculate Tally using CertifiedMath\n        # We use basic integer math here as CertifiedMath wrappers are mainly for\n        # complex funcs (log, exp) or safe division. For additions, standard int matches\n        # Zero-Sim if inputs are integers.\n    \n        score_approve = 0\n        score_reject = 0\n    \n        for v in votes:\n            # Weight = VoteWeight * (Reputation / 100)\n            # Scale: weight(100) * rep(1000) / 100 = 1000.\n            # Use CertifiedMath for division to be safe and consistent.\n    \n            # effective_weight = (v.weight * v.reputation) // 100\n>           effective_weight = CertifiedMath.idiv(v.weight * v.reputation, 100)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\governance\\appeals.py:63: TypeError"}, "hash": "65715ca95eafd045e9734c77c04a50b499c23855a681c5b7330d35924403fa28c2aac18a56e9d4547167998b37211d9a7fbebf2868127aee6262589e6876979c"}
{"timestamp": "2025-12-17T10:01:48.478062", "session_id": "095391b92398d917", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/observability/test_trace_propagation.py::test_trace_propagation_end_to_end", "context": {"env": "test"}, "details": {"duration": 0.04574899998260662, "error": "client = <starlette.testclient.TestClient object at 0x00000168EE86BA10>, capsys = <_pytest.capture.CaptureFixture object at 0x00000168EFA60590>\n\n    def test_trace_propagation_end_to_end(client, capsys):\n        \"\"\"\n        Verify that X-Trace-Id header propagates to CertifiedMath logs.\n        \"\"\"\n        trace_id = \"test-trace-12345\"\n    \n        # Make request\n        response = client.get(\n            \"/explain/reward/test_wallet?epoch=1\", headers={\"x-trace-id\": trace_id}\n        )\n    \n>       assert response.status_code == 200\nE       assert 500 == 200\nE        +  where 500 = <Response [500 Internal Server Error]>.status_code\n\nv13\\tests\\observability\\test_trace_propagation.py:62: AssertionError"}, "hash": "2b774a94b531616eb62264a97f10fa033afb845c3ac06b47a56edaa6d516f8fcffadb3fa5bdd45e9bf6cf923cb068df04ff56c3ef5d48019f099d5e099a771df"}
{"timestamp": "2025-12-17T10:01:48.490565", "session_id": "095391b92398d917", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/observability/test_trace_propagation.py::test_trace_propagation_no_header", "context": {"env": "test"}, "details": {"duration": 0.004688399989390746, "error": "client = <starlette.testclient.TestClient object at 0x00000168EFA66490>, capsys = <_pytest.capture.CaptureFixture object at 0x00000168EFA65BD0>\n\n    def test_trace_propagation_no_header(client, capsys):\n        \"\"\"\n        Verify that a new trace ID is generated if header is missing.\n        \"\"\"\n        response = client.get(\"/explain/reward/test_wallet?epoch=1\")\n>       assert response.status_code == 200\nE       assert 500 == 200\nE        +  where 500 = <Response [500 Internal Server Error]>.status_code\n\nv13\\tests\\observability\\test_trace_propagation.py:100: AssertionError"}, "hash": "9bd63c850f61edca03f0288b40a486a314c4802ef68ab138c4392ad75477490b3d29d5b1cc6c40ac7fddbb47ac049d28ee89ae682b1a84c23d5be790dbfe9493"}
{"timestamp": "2025-12-17T10:08:15.910800", "session_id": "8993fd712f5cb026", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider.py::test_mock_provider_signing_roundtrip", "context": {"env": "test"}, "details": {"duration": 0.00024009999469853938, "error": "def test_mock_provider_signing_roundtrip():\n        \"\"\"Verify sign/verify mechanics for MockProvider.\"\"\"\n        provider = get_pqc_provider()\n        seed = b\"test_seed_signing_123456789032\"\n>       pk, sk = provider.generate_keypair(seed)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\unit\\test_pqc_provider.py:31: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <v13.libs.pqc_provider.DeterministicMockProvider object at 0x000002C777127ED0>, seed = b'test_seed_signing_123456789032'\n\n    def generate_keypair(self, seed: bytes) -> Tuple[bytes, bytes]:\n        if not isinstance(seed, bytes) or len(seed) < 32:\n>           raise ValueError(\"Seed must be at least 32 bytes\")\nE           ValueError: Seed must be at least 32 bytes\n\nv13\\libs\\pqc_provider.py:77: ValueError"}, "hash": "bb43cbb9d02b11f3ddf450385e14d0e800934bfa1fec65a20f2cc8fd4726d02ab8d0b3c4358c3603aa34687ac1d41f6ae69cdd456f1d0bf2096c2c829d95ed09"}
{"timestamp": "2025-12-17T10:08:37.061226", "session_id": "da382666d63188f8", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider.py::test_mock_provider_signing_roundtrip", "context": {"env": "test"}, "details": {"duration": 0.00020779998158104718, "error": "def test_mock_provider_signing_roundtrip():\n        \"\"\"Verify sign/verify mechanics for MockProvider.\"\"\"\n        provider = get_pqc_provider()\n        seed = b\"test_seed_signing_123456789032\"\n>       pk, sk = provider.generate_keypair(seed)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\unit\\test_pqc_provider.py:31: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <v13.libs.pqc_provider.DeterministicMockProvider object at 0x0000027FADBEBED0>, seed = b'test_seed_signing_123456789032'\n\n    def generate_keypair(self, seed: bytes) -> Tuple[bytes, bytes]:\n        if not isinstance(seed, bytes) or len(seed) < 32:\n>           raise ValueError(\"Seed must be at least 32 bytes\")\nE           ValueError: Seed must be at least 32 bytes\n\nv13\\libs\\pqc_provider.py:77: ValueError"}, "hash": "5e81c079a5e3a896ceb7c3d0c6d9027b48393f8fa093eab71e1081f419232167ff7d0b4ca571712705d0c9ed7367ac88cb97dac96b0275794147fa3e8ea71995"}
{"timestamp": "2025-12-17T10:11:07.586030", "session_id": "a510f9d569b78944", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_system_creator_wallet.py::test_derive_creator_keypair_dev", "context": {"env": "test"}, "details": {"duration": 0.0022037000162526965, "error": "def test_derive_creator_keypair_dev():\n        priv, addr = derive_creator_keypair(\"DEV\")\n>       assert addr == EXPECTED_ADDRESS_DEV\nE       AssertionError: assert '0x86d65da5b0...edcaa7143b4fc' == '0x40d1b50e2b...10e9995d72dc9'\nE         \nE         \u001b[0m\u001b[91m- 0x40d1b50e2b950b1e933b286108335ce73553af2a16b338d408210e9995d72dc9\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ 0x86d65da5b0edd2528e3c6de5506cb0b89ee7b51459d4e4c8768edcaa7143b4fc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\unit\\test_system_creator_wallet.py:22: AssertionError"}, "hash": "ab7bfcfffc95662a72621a8f830f03330e694b49330a54b4d963673497f25e20d111aa09a0f70ea8a3a625efead0cf03a7cea5f0ca2f89f9fcedeef9745ad4e9"}
{"timestamp": "2025-12-17T10:24:36.154897", "session_id": "facfa44f5cb04f03", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_hd_derivation.py::test_vector_1_hardened_child", "context": {"env": "test"}, "details": {"duration": 0.006907900009537116, "error": "def test_vector_1_hardened_child():\n        seed = bytes.fromhex(SEED_HEX)\n        master = HDKey.from_seed(seed)\n    \n        # Derive m/0' (Index 0 + 0x80000000)\n        child = master.derive(0 + 0x80000000)\n    \n        assert child.key.hex() == M_0H_PRIV_HEX\n>       assert child.chain_code.hex() == M_0H_CHAIN_HEX\nE       AssertionError: assert '47fdacbd0f10...82c7ae6236141' == '47fdacbd3f10...09e92979bff1b'\nE         \nE         \u001b[0m\u001b[91m- 47fdacbd3f106a2e04705146450d163e3fb231d55e9621e25cc09e92979bff1b\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ 47fdacbd0f1097043b78c63c20c34ef4ed9a111d980047ad16282c7ae6236141\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\unit\\test_hd_derivation.py:35: AssertionError"}, "hash": "5b2bc9d3a3d19c8809aa87601078268c41786119936f29d8a7494b003e452b83b5d97e7a9ca116176110fd6f50f4acb17af34a2fe63e11d590830901f81e5638"}
{"timestamp": "2025-12-17T10:25:01.802429", "session_id": "113495d4ca1abed9", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_hd_derivation.py::test_vector_1_hardened_child", "context": {"env": "test"}, "details": {"duration": 0.001363499992294237, "error": "def test_vector_1_hardened_child():\n        seed = bytes.fromhex(SEED_HEX)\n        master = HDKey.from_seed(seed)\n    \n        # Derive m/0' (Index 0 + 0x80000000)\n        child = master.derive(0 + 0x80000000)\n    \n        assert child.key.hex() == M_0H_PRIV_HEX\n>       assert child.chain_code.hex() == M_0H_CHAIN_HEX\nE       AssertionError: assert '47fdacbd0f10...82c7ae6236141' == '47fdacbd3f10...09e92979bff1b'\nE         \nE         \u001b[0m\u001b[91m- 47fdacbd3f106a2e04705146450d163e3fb231d55e9621e25cc09e92979bff1b\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ 47fdacbd0f1097043b78c63c20c34ef4ed9a111d980047ad16282c7ae6236141\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\unit\\test_hd_derivation.py:35: AssertionError"}, "hash": "ebfd21780f36f208ed10ad3837d31e3a2c71cd601c58f49320ac573971bcff71ba5137631e4c735f00cbd0dca37a0d4b49528d3390e76edd68cbc1b60513c8f3"}
{"timestamp": "2025-12-17T10:26:53.685851", "session_id": "bc5d883a8e641b29", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_hd_derivation.py::test_vector_1_hardened_child", "context": {"env": "test"}, "details": {"duration": 0.0012244000099599361, "error": "def test_vector_1_hardened_child():\n        seed = bytes.fromhex(SEED_HEX)\n        master = HDKey.from_seed(seed)\n    \n        # Derive m/0' (Index 0 + 0x80000000)\n        child = master.derive(0 + 0x80000000)\n    \n        assert child.key.hex() == M_0H_PRIV_HEX\n>       assert child.chain_code.hex() == M_0H_CHAIN_HEX\nE       AssertionError: assert '47fdacbd0f10...82c7ae6236141' == '47fdacbd0f10...09e92979bff1b'\nE         \nE         \u001b[0m\u001b[91m- 47fdacbd0f106a2e04705146450d163e3fb231d55e9621e25cc09e92979bff1b\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ 47fdacbd0f1097043b78c63c20c34ef4ed9a111d980047ad16282c7ae6236141\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\unit\\test_hd_derivation.py:35: AssertionError"}, "hash": "77e9d271045f307405ba82cf8a5bfa1a46c517058a9691090e8751e0fa397ef417b8f71ec65ceacc423cdade0d3d524c95c7ccae18a4ebd9a7eb90346084a034"}
{"timestamp": "2025-12-17T10:27:18.581937", "session_id": "e38a99b4484c81ca", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_hd_derivation.py::test_vector_1_hardened_child", "context": {"env": "test"}, "details": {"duration": 0.0012920000008307397, "error": "def test_vector_1_hardened_child():\n        seed = bytes.fromhex(SEED_HEX)\n        master = HDKey.from_seed(seed)\n    \n        # Derive m/0' (Index 0 + 0x80000000)\n        child = master.derive(0 + 0x80000000)\n    \n        assert child.key.hex() == M_0H_PRIV_HEX\n>       assert child.chain_code.hex() == M_0H_CHAIN_HEX\nE       AssertionError: assert '47fdacbd0f10...82c7ae6236141' == '47fdacbd0f10...09e92979bff1b'\nE         \nE         \u001b[0m\u001b[91m- 47fdacbd0f106a2e04705146450d163e3fb231d55e9621e25cc09e92979bff1b\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ 47fdacbd0f1097043b78c63c20c34ef4ed9a111d980047ad16282c7ae6236141\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\unit\\test_hd_derivation.py:35: AssertionError"}, "hash": "dab4202e1567cdc14c6058357838a5e998b29fee3e6c04acbfda339e7f19e83a83e880a7c5eb6c2b28303aa08836793efb5df8285d64a2a06e3fd47c44a4bcf5"}
{"timestamp": "2025-12-17T10:28:05.097077", "session_id": "2b7563079999bee5", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_system_creator_wallet.py::test_derive_creator_keypair_dev", "context": {"env": "test"}, "details": {"duration": 0.09286699999938719, "error": "def test_derive_creator_keypair_dev():\n        priv, addr = derive_creator_keypair(\"DEV\")\n>       assert addr == EXPECTED_ADDRESS_DEV\nE       AssertionError: assert '0x7f63e288dd...ee812b00e3d7f' == '0x86d65da5b0...edcaa7143b4fc'\nE         \nE         \u001b[0m\u001b[91m- 0x86d65da5b0edd2528e3c6de5506cb0b89ee7b51459d4e4c8768edcaa7143b4fc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ 0x7f63e288dd4775ca540298e7e6de6169b2eec1f281c6949a1c2ee812b00e3d7f\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\unit\\test_system_creator_wallet.py:26: AssertionError"}, "hash": "e40a071883adf32fa1c1c6fe40e68673f05aa21748953730abd55fd0149ba999c2f51855dd156ebe82d7e272a300927e162de8875b47007af33c57f596a7f0db"}
{"timestamp": "2025-12-17T10:28:23.186712", "session_id": "b5a89918e9b71376", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_system_creator_wallet.py::test_derive_creator_keypair_dev", "context": {"env": "test"}, "details": {"duration": 0.09323890000814572, "error": "def test_derive_creator_keypair_dev():\n        priv, addr = derive_creator_keypair(\"DEV\")\n>       assert addr == EXPECTED_ADDRESS_DEV\nE       AssertionError: assert '0x7f63e288dd...ee812b00e3d7f' == '0x86d65da5b0...edcaa7143b4fc'\nE         \nE         \u001b[0m\u001b[91m- 0x86d65da5b0edd2528e3c6de5506cb0b89ee7b51459d4e4c8768edcaa7143b4fc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ 0x7f63e288dd4775ca540298e7e6de6169b2eec1f281c6949a1c2ee812b00e3d7f\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\unit\\test_system_creator_wallet.py:26: AssertionError"}, "hash": "026c816d379232dc38d2e956bb9299ee227969f1a09ab814b215909701ada9161c65432595a086af70b7b44c2cb371ba9ce35a30545f80ff0d9d00d989c78be7"}
{"timestamp": "2025-12-17T10:29:22.633304", "session_id": "b748b454a030cd27", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_system_creator_wallet.py::test_derive_creator_keypair_testnet", "context": {"env": "test"}, "details": {"duration": 0.09478710000985302, "error": "def test_derive_creator_keypair_testnet():\n        priv, addr = derive_creator_keypair(\"TESTNET\")\n>       assert addr != EXPECTED_ADDRESS_DEV\nE       AssertionError: assert '0x7f63e288dd4775ca540298e7e6de6169b2eec1f281c6949a1c2ee812b00e3d7f' != '0x7f63e288dd4775ca540298e7e6de6169b2eec1f281c6949a1c2ee812b00e3d7f'\n\nv13\\tests\\unit\\test_system_creator_wallet.py:32: AssertionError"}, "hash": "456fb46440f189537d84b9d694a21e9049440756be14c003fc58cc324696ef009f29083bb45d6d6d88e4253c7ef846e5eb3be4d39406886fcb427760db47d3f5"}
{"timestamp": "2025-12-17T11:28:44.919297", "session_id": "cbc73ea1f559fe4d", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/sessions/test_session_cutover_boundary.py::test_session_replay_with_multiple_operations", "context": {"env": "test"}, "details": {"duration": 0.0009089999948628247, "error": "def test_session_replay_with_multiple_operations():\n        \"\"\"Test session replay with multiple operations including rotation and revocation.\"\"\"\n        # Create fake ledger\n        ledger = FakeLedger()\n    \n        # Create session manager\n        session_manager = SessionManager(ledger)\n    \n        # Test data\n        wallet_id = \"wallet_123\"\n        device_id = \"device_456\"\n        scope = [\"read\", \"write\"]\n    \n        # Create initial session at block 100\n        token1 = session_manager.create_session(\n            wallet_id=wallet_id,\n            device_id=device_id,\n            scope=scope,\n            current_block=100,\n            ttl_blocks=1000\n        )\n    \n        # Rotate session at block 150\n        token2 = session_manager.rotate_session(token1, 150)\n    \n        # Rotate again at block 200\n        token3 = session_manager.rotate_session(token2, 200)\n    \n        # Revoke at block 250\n        session_manager.revoke_session(token3, \"timeout\", 250)\n    \n        # Verify we have all events\n>       assert len(ledger.events) == 4  # SESSION_STARTED + 2 SESSION_ROTATED + SESSION_REVOKED\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AssertionError: assert 6 == 4\nE        +  where 6 = len([{'data': {'device_id': 'device_456', 'issued_at_block': 100, 'scope': ['read', 'write'], 'session_id': 'ccc9a4437566ae2daaf9f45e9761e5d2a2ea7a2d871e540e7a479be47ae0eb92', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'device_id': 'device_456', 'issued_at_block': 150, 'scope': ['read', 'write'], 'session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'block': 150, 'new_session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d', 'old_session_id': 'ccc9a4437566ae2daaf9f45e9761e5d2a2ea7a2d871e540e7a479be47ae0eb92'}, 'event_type': 'SESSION_ROTATED'}, {'data': {'device_id': 'device_456', 'issued_at_block': 200, 'scope': ['read', 'write'], 'session_id': '0f8102bcdaeea4b6c0c106612133a9ea0480c6f87b26bd7644b088b8c4bf91f8', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'block': 200, 'new_session_id': '0f8102bcdaeea4b6c0c106612133a9ea0480c6f87b26bd7644b088b8c4bf91f8', 'old_session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d'}, 'event_type': 'SESSION_ROTATED'}, {'data': {'block': 250, 'reason': 'timeout', 'session_id': '0f8102bcdaeea4b6c0c106612133a9ea0480c6f87b26bd7644b088b8c4bf91f8'}, 'event_type': 'SESSION_REVOKED'}])\nE        +    where [{'data': {'device_id': 'device_456', 'issued_at_block': 100, 'scope': ['read', 'write'], 'session_id': 'ccc9a4437566ae2daaf9f45e9761e5d2a2ea7a2d871e540e7a479be47ae0eb92', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'device_id': 'device_456', 'issued_at_block': 150, 'scope': ['read', 'write'], 'session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'block': 150, 'new_session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d', 'old_session_id': 'ccc9a4437566ae2daaf9f45e9761e5d2a2ea7a2d871e540e7a479be47ae0eb92'}, 'event_type': 'SESSION_ROTATED'}, {'data': {'device_id': 'device_456', 'issued_at_block': 200, 'scope': ['read', 'write'], 'session_id': '0f8102bcdaeea4b6c0c106612133a9ea0480c6f87b26bd7644b088b8c4bf91f8', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'block': 200, 'new_session_id': '0f8102bcdaeea4b6c0c106612133a9ea0480c6f87b26bd7644b088b8c4bf91f8', 'old_session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d'}, 'event_type': 'SESSION_ROTATED'}, {'data': {'block': 250, 'reason': 'timeout', 'session_id': '0f8102bcdaeea4b6c0c106612133a9ea0480c6f87b26bd7644b088b8c4bf91f8'}, 'event_type': 'SESSION_REVOKED'}] = <test_session_cutover_boundary.FakeLedger object at 0x0000025A15A95550>.events\n\nv13\\tests\\sessions\\test_session_cutover_boundary.py:54: AssertionError"}, "hash": "6556dc444bc07424ed3317d09fa530ef3eeafb9dd309bbcc7848573980db908b6ef8cf04e0853293345da15dc8af26d9a60e51d79b1a0c78a3bb8dc239ea0250"}
{"timestamp": "2025-12-17T11:28:44.931647", "session_id": "cbc73ea1f559fe4d", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/sessions/test_session_explainability_mixed_eras.py::test_session_explainability_with_rotation", "context": {"env": "test"}, "details": {"duration": 0.0009330000029876828, "error": "def test_session_explainability_with_rotation():\n        \"\"\"Test session explainability with session rotation events.\"\"\"\n        # Create an action event\n        action_event = {\n            \"event_id\": \"action_789\",\n            \"event_type\": \"REFERRAL_USED\",\n            \"block_number\": 2000,\n            \"creator_id\": \"wallet_123\",\n            \"data\": {\n                \"wallet_id\": \"wallet_123\",\n                \"device_id\": \"device_789\",\n                \"referral_code\": \"REF123\"\n            }\n        }\n    \n        # Create session events including rotation\n        session_events = [\n            {\n                \"event_type\": \"SESSION_STARTED\",\n                \"data\": {\n                    \"session_id\": \"session_old\",\n                    \"wallet_id\": \"wallet_123\",\n                    \"device_id\": \"device_789\",\n                    \"issued_at_block\": 1500,\n                    \"ttl_blocks\": 1000,\n                    \"scope\": [\"basic\"]\n                }\n            },\n            {\n                \"event_type\": \"SESSION_ROTATED\",\n                \"data\": {\n                    \"old_session_id\": \"session_old\",\n                    \"new_session_id\": \"session_new\",\n                    \"block\": 1800\n                }\n            }\n        ]\n    \n        # Build proof\n        proof = build_session_proof(action_event, session_events, era_cutoff_block=1000)\n    \n        # Verify proof identifies the rotated session\n        assert proof[\"wallet_id\"] == \"wallet_123\"\n        assert proof[\"device_id\"] == \"device_789\"\n>       assert proof[\"session_id\"] == \"session_new\"  # Should identify the new session\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AssertionError: assert 'session_old' == 'session_new'\nE         \nE         \u001b[0m\u001b[91m- session_new\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ session_old\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\sessions\\test_session_explainability_mixed_eras.py:153: AssertionError"}, "hash": "1f6bdfc96c6473f123f124c3b3e3f38fa35f076e5e2229e6f63941d40a0140828715eb29a6567ee744b101a4f8b287bbe412ad926a6c4f1d3299b60553da2a76"}
{"timestamp": "2025-12-17T11:28:44.942981", "session_id": "cbc73ea1f559fe4d", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/sessions/test_session_lifecycle_replay.py::test_session_lifecycle_replay", "context": {"env": "test"}, "details": {"duration": 0.0004564999835565686, "error": "def test_session_lifecycle_replay():\n        \"\"\"Test session lifecycle with replay functionality.\"\"\"\n        # Create fake ledger\n        ledger = FakeLedger()\n    \n        # Create session manager\n        session_manager = SessionManager(ledger)\n    \n        # Test data\n        wallet_id = \"wallet_123\"\n        device_id = \"device_456\"\n        scope = [\"read\", \"write\"]\n        current_block = 100\n        ttl_blocks = 1000\n    \n        # Create session\n        token = session_manager.create_session(\n            wallet_id=wallet_id,\n            device_id=device_id,\n            scope=scope,\n            current_block=current_block,\n            ttl_blocks=ttl_blocks\n        )\n    \n        # Verify session token\n        assert token.wallet_id == wallet_id\n        assert token.device_id == device_id\n        assert token.scope == scope\n        assert token.issued_at_block == current_block\n        assert token.ttl_blocks == ttl_blocks\n    \n        # Verify event was emitted\n        assert len(ledger.events) == 1\n        event = ledger.events[0]\n        assert event[\"event_type\"] == \"SESSION_STARTED\"\n        assert event[\"data\"][\"session_id\"] == token.session_id\n        assert event[\"data\"][\"wallet_id\"] == wallet_id\n        assert event[\"data\"][\"device_id\"] == device_id\n    \n        # Rotate session\n        current_block = 150\n        new_token = session_manager.rotate_session(token, current_block)\n    \n        # Verify new token\n        assert new_token.wallet_id == wallet_id\n        assert new_token.device_id == device_id\n        assert new_token.session_id != token.session_id  # Should be different\n        assert new_token.issued_at_block == current_block\n    \n        # Verify events were emitted\n>       assert len(ledger.events) == 2\nE       AssertionError: assert 3 == 2\nE        +  where 3 = len([{'data': {'device_id': 'device_456', 'issued_at_block': 100, 'scope': ['read', 'write'], 'session_id': 'ccc9a4437566ae2daaf9f45e9761e5d2a2ea7a2d871e540e7a479be47ae0eb92', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'device_id': 'device_456', 'issued_at_block': 150, 'scope': ['read', 'write'], 'session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'block': 150, 'new_session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d', 'old_session_id': 'ccc9a4437566ae2daaf9f45e9761e5d2a2ea7a2d871e540e7a479be47ae0eb92'}, 'event_type': 'SESSION_ROTATED'}])\nE        +    where [{'data': {'device_id': 'device_456', 'issued_at_block': 100, 'scope': ['read', 'write'], 'session_id': 'ccc9a4437566ae2daaf9f45e9761e5d2a2ea7a2d871e540e7a479be47ae0eb92', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'device_id': 'device_456', 'issued_at_block': 150, 'scope': ['read', 'write'], 'session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'block': 150, 'new_session_id': '4da5be2b47b65fdc5e6bac6bce4d0e26401ef322e4309d7dee04b051de40754d', 'old_session_id': 'ccc9a4437566ae2daaf9f45e9761e5d2a2ea7a2d871e540e7a479be47ae0eb92'}, 'event_type': 'SESSION_ROTATED'}] = <test_session_lifecycle_replay.FakeLedger object at 0x0000025A15A96270>.events\n\nv13\\tests\\sessions\\test_session_lifecycle_replay.py:72: AssertionError"}, "hash": "081fcd703470c599f45530d23b6b090e0e3a1568d2da550beb33297546ec95317fbb0fc6f21af2e1b76e675d578329647fb195402a22d45a912276eb7f2bc014"}
{"timestamp": "2025-12-17T11:28:44.955835", "session_id": "cbc73ea1f559fe4d", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/sessions/test_session_rotation_ordering.py::test_session_rotation_emits_correct_event", "context": {"env": "test"}, "details": {"duration": 0.0003657999914139509, "error": "def test_session_rotation_emits_correct_event():\n        \"\"\"Test that session rotation emits the correct ledger event.\"\"\"\n        # Create fake ledger\n        ledger = FakeLedger()\n    \n        # Create session manager\n        session_manager = SessionManager(ledger)\n    \n        # Create initial session\n        wallet_id = \"wallet_123\"\n        device_id = \"device_456\"\n        scope = [\"basic\"]\n        initial_block = 100\n        ttl_blocks = 1000\n    \n        initial_token = session_manager.create_session(\n            wallet_id=wallet_id,\n            device_id=device_id,\n            scope=scope,\n            current_block=initial_block,\n            ttl_blocks=ttl_blocks\n        )\n    \n        # Clear events to focus on rotation event\n        ledger.events.clear()\n    \n        # Rotate session\n        rotation_block = 150\n        rotated_token = session_manager.rotate_session(initial_token, rotation_block)\n    \n        # Verify exactly one event was emitted\n>       assert len(ledger.events) == 1\nE       AssertionError: assert 2 == 1\nE        +  where 2 = len([{'data': {'device_id': 'device_456', 'issued_at_block': 150, 'scope': ['basic'], 'session_id': 'f5aa2578dd37dbde70bf27379d0893955f2e0f5b5da3044595dd0405809f78af', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'block': 150, 'new_session_id': 'f5aa2578dd37dbde70bf27379d0893955f2e0f5b5da3044595dd0405809f78af', 'old_session_id': '894344490922576df3d933ccd3886ee22826f8870f10475bfb6ca995a9e1001b'}, 'event_type': 'SESSION_ROTATED'}])\nE        +    where [{'data': {'device_id': 'device_456', 'issued_at_block': 150, 'scope': ['basic'], 'session_id': 'f5aa2578dd37dbde70bf27379d0893955f2e0f5b5da3044595dd0405809f78af', ...}, 'event_type': 'SESSION_STARTED'}, {'data': {'block': 150, 'new_session_id': 'f5aa2578dd37dbde70bf27379d0893955f2e0f5b5da3044595dd0405809f78af', 'old_session_id': '894344490922576df3d933ccd3886ee22826f8870f10475bfb6ca995a9e1001b'}, 'event_type': 'SESSION_ROTATED'}] = <test_session_rotation_ordering.FakeLedger object at 0x0000025A15BD47D0>.events\n\nv13\\tests\\sessions\\test_session_rotation_ordering.py:132: AssertionError"}, "hash": "02ce50ab697d63e55314b41933924b88bc6859c4b6075cd18e67fb52c42676a42426a509aca1b709e553c58a683b4bb171ed677675b83fa6ae86830061b7a170"}
{"timestamp": "2025-12-17T11:29:52.399332", "session_id": "0b8ab43b1bf74ecd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/sessions/test_session_cutover_boundary.py::test_session_replay_with_multiple_operations", "context": {"env": "test"}, "details": {"duration": 0.00042940001003444195, "error": "def test_session_replay_with_multiple_operations():\n        \"\"\"Test session replay with multiple operations including rotation and revocation.\"\"\"\n        # Create fake ledger\n        ledger = FakeLedger()\n    \n        # Create session manager\n        session_manager = SessionManager(ledger)\n    \n        # Test data\n        wallet_id = \"wallet_123\"\n        device_id = \"device_456\"\n        scope = [\"read\", \"write\"]\n    \n        # Create initial session at block 100\n        token1 = session_manager.create_session(\n            wallet_id=wallet_id,\n            device_id=device_id,\n            scope=scope,\n            current_block=100,\n            ttl_blocks=1000\n        )\n    \n        # Rotate session at block 150\n        token2 = session_manager.rotate_session(token1, 150)\n    \n        # Rotate again at block 200\n        token3 = session_manager.rotate_session(token2, 200)\n    \n        # Revoke at block 250\n        session_manager.revoke_session(token3, \"timeout\", 250)\n    \n        # Verify we have all events\n        assert len(ledger.events) == 4  # SESSION_STARTED + 2 SESSION_ROTATED + SESSION_REVOKED\n    \n        # Test replay functionality\n        session_states = replay_sessions(ledger.events)\n    \n        # After revoke, no sessions should exist\n        assert len(session_states) == 0\n    \n        # Test replay at intermediate points\n        # Replay only first event (session created)\n        session_states_1 = replay_sessions(ledger.events[:1])\n        assert len(session_states_1) == 1\n        assert token1.session_id in session_states_1\n    \n        # Replay first two events (session created + first rotation)\n        session_states_2 = replay_sessions(ledger.events[:2])\n>       assert len(session_states_2) == 1  # Only the new session should exist\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       assert 0 == 1\nE        +  where 0 = len({})\n\nv13\\tests\\sessions\\test_session_cutover_boundary.py:70: AssertionError"}, "hash": "91a77a38fdc0dbe891b0c4f2ba6485665908ec6c8e75c702a32c8c2a661ada36c468858c9c3c9cce082c6b10cac4478a9cf3cb15654d79576cda72b29792cab1"}
{"timestamp": "2025-12-17T11:30:35.605169", "session_id": "c044b76e7a8208af", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/sessions/test_session_explainability_mixed_eras.py::test_session_explainability_with_rotation", "context": {"env": "test"}, "details": {"duration": 0.0009725999843794852, "error": "def test_session_explainability_with_rotation():\n        \"\"\"Test session explainability with session rotation events.\"\"\"\n        # Create an action event\n        action_event = {\n            \"event_id\": \"action_789\",\n            \"event_type\": \"REFERRAL_USED\",\n            \"block_number\": 2000,\n            \"creator_id\": \"wallet_123\",\n            \"data\": {\n                \"wallet_id\": \"wallet_123\",\n                \"device_id\": \"device_789\",\n                \"referral_code\": \"REF123\"\n            }\n        }\n    \n        # Create session events including rotation\n        session_events = [\n            {\n                \"event_type\": \"SESSION_STARTED\",\n                \"data\": {\n                    \"session_id\": \"session_old\",\n                    \"wallet_id\": \"wallet_123\",\n                    \"device_id\": \"device_789\",\n                    \"issued_at_block\": 1500,\n                    \"ttl_blocks\": 1000,\n                    \"scope\": [\"basic\"]\n                }\n            },\n            {\n                \"event_type\": \"SESSION_ROTATED\",\n                \"data\": {\n                    \"old_session_id\": \"session_old\",\n                    \"new_session_id\": \"session_new\",\n                    \"block\": 1800\n                }\n            }\n        ]\n    \n        # Build proof\n        proof = build_session_proof(action_event, session_events, era_cutoff_block=1000)\n    \n        # Verify proof identifies the rotated session\n        assert proof[\"wallet_id\"] == \"wallet_123\"\n        assert proof[\"device_id\"] == \"device_789\"\n>       assert proof[\"session_id\"] == \"session_new\"  # Should identify the new session\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AssertionError: assert 'session_old' == 'session_new'\nE         \nE         \u001b[0m\u001b[91m- session_new\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\nE         \u001b[92m+ session_old\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n\nv13\\tests\\sessions\\test_session_explainability_mixed_eras.py:153: AssertionError"}, "hash": "55bc0b183f58b7bc3c1bf2b4e56d8dc72c20ceb074db4bc18d8f4e5b2b7716b0aa4effce8d6ea2835a6776df64b1a3c84f836a620c7da02362257ebd6de8c31c"}
=======
{"timestamp": "2025-12-17T12:17:08.535037", "session_id": "e5716fb8538b8fbb", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider_consistency_shim.py::TestPQCProviderConsistencyShim::test_backend_info_consistency", "context": {"env": "test"}, "details": {"duration": 0.005436199979158118, "error": "self = <v13.tests.unit.test_pqc_provider_consistency_shim.TestPQCProviderConsistencyShim testMethod=test_backend_info_consistency>\n\n    def test_backend_info_consistency(self):\n        \"\"\"Test that backend info is consistently provided\"\"\"\n        mock_info = self.mock_provider.get_backend_info()\n>       concrete_info = self.concrete_provider.get_backend_info()\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\unit\\test_pqc_provider_consistency_shim.py:260: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <v13.libs.pqc.ConcretePQCProvider.ConcretePQCProvider object at 0x0000021BCC5E8C20>\n\n    def get_backend_info(self) -> Dict[str, Any]:\n        \"\"\"\n        Get information about the currently active PQC backend.\n    \n        Returns:\n            Dictionary with backend information\n        \"\"\"\n        # Get backend info from legacy implementation\n>       legacy_info = LegacyPQC.get_backend_info()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PQC' has no attribute 'get_backend_info'\n\nv13\\libs\\pqc\\ConcretePQCProvider.py:203: AttributeError"}, "hash": "ae119efdf80dfba813e328231cb758b1c1366db835bfddbaaf876b3beaae67787c9b3cd6c9e239f93d32e92205e94a374aa4155e8d7a728122b6e4f409ea7397"}
{"timestamp": "2025-12-17T12:17:08.570567", "session_id": "e5716fb8538b8fbb", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider_consistency_shim.py::TestPQCProviderConsistencyShim::test_signature_structure_compatibility", "context": {"env": "test"}, "details": {"duration": 0.00038629997288808227, "error": "log_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_signature_structure', 'timestamp': 0}, ...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5'\nparameters = {}, pqc_cid = 'test_signature_structure'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n>               private_key, public_key = Dilithium5Impl.keygen(seed)\n                                          ^^^^^^^^^^^^^^^^^^^^^\nE               AttributeError: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:657: AttributeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <v13.tests.unit.test_pqc_provider_consistency_shim.TestPQCProviderConsistencyShim testMethod=test_signature_structure_compatibility>\n\n    def test_signature_structure_compatibility(self):\n        \"\"\"Test that signatures from both providers have compatible structures\"\"\"\n        # Generate key pairs\n        mock_keypair = self.mock_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_signature_structure\"\n        )\n    \n>       concrete_keypair = self.concrete_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_signature_structure\"\n        )\n\nv13\\tests\\unit\\test_pqc_provider_consistency_shim.py:75: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nv13\\libs\\pqc\\ConcretePQCProvider.py:76: in generate_keypair\n    legacy_keypair = LegacyPQC.generate_keypair(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlog_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_signature_structure', 'timestamp': 0}, ...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5'\nparameters = {}, pqc_cid = 'test_signature_structure'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n                private_key, public_key = Dilithium5Impl.keygen(seed)\n            else:\n                raise PQCError(f\"Unsupported algorithm: {algorithm}\")\n    \n            # Convert private key to mutable bytearray for secure handling\n            private_key_array = bytearray(private_key)\n    \n            result_keypair = KeyPair(\n                private_key=private_key_array,\n                public_key=public_key,\n                algorithm=algorithm,\n                parameters=parameters\n            )\n    \n            # Log the successful operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"public_key_size\": len(public_key),\n                    \"seed_provided\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp\n            )\n    \n            return result_keypair\n    \n        except Exception as e:\n            # Log the failed operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"error_occurred\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp,\n                error=e\n            )\n>           raise PQCError(f\"Failed to generate keypair: {str(e)}\") from e\nE           v13.libs.PQC.PQCError: Failed to generate keypair: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:703: PQCError"}, "hash": "6d89def2a224cbe22c68990d34c0664afeebac172a2d4e2e33641463ad047f3b9ec26f7eb1cdba16715081ccf934a75499ced575c45abfab2f7d7e976e671f31"}
{"timestamp": "2025-12-17T12:17:08.595006", "session_id": "e5716fb8538b8fbb", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider_consistency_shim.py::TestPQCProviderConsistencyShim::test_signature_verification_compatibility", "context": {"env": "test"}, "details": {"duration": 0.00034699999378062785, "error": "log_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_verification_compatibility', 'timestamp...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5'\nparameters = {}, pqc_cid = 'test_verification_compatibility'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n>               private_key, public_key = Dilithium5Impl.keygen(seed)\n                                          ^^^^^^^^^^^^^^^^^^^^^\nE               AttributeError: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:657: AttributeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <v13.tests.unit.test_pqc_provider_consistency_shim.TestPQCProviderConsistencyShim testMethod=test_signature_verification_compatibility>\n\n    def test_signature_verification_compatibility(self):\n        \"\"\"Test that signatures from one provider can be verified by the other\"\"\"\n        # Generate key pairs\n        mock_keypair = self.mock_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_verification_compatibility\"\n        )\n    \n>       concrete_keypair = self.concrete_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_verification_compatibility\"\n        )\n\nv13\\tests\\unit\\test_pqc_provider_consistency_shim.py:113: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nv13\\libs\\pqc\\ConcretePQCProvider.py:76: in generate_keypair\n    legacy_keypair = LegacyPQC.generate_keypair(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlog_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_verification_compatibility', 'timestamp...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5'\nparameters = {}, pqc_cid = 'test_verification_compatibility'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n                private_key, public_key = Dilithium5Impl.keygen(seed)\n            else:\n                raise PQCError(f\"Unsupported algorithm: {algorithm}\")\n    \n            # Convert private key to mutable bytearray for secure handling\n            private_key_array = bytearray(private_key)\n    \n            result_keypair = KeyPair(\n                private_key=private_key_array,\n                public_key=public_key,\n                algorithm=algorithm,\n                parameters=parameters\n            )\n    \n            # Log the successful operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"public_key_size\": len(public_key),\n                    \"seed_provided\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp\n            )\n    \n            return result_keypair\n    \n        except Exception as e:\n            # Log the failed operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"error_occurred\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp,\n                error=e\n            )\n>           raise PQCError(f\"Failed to generate keypair: {str(e)}\") from e\nE           v13.libs.PQC.PQCError: Failed to generate keypair: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:703: PQCError"}, "hash": "d3bfc54945d8809a19ef08433e1f1bee9a6384ac690d9e78ef73ec058b577e0f354ebf7cc2a2adc0f534fd25cf57cceb2c9c1faaf5a7d1ab56bd0b05902ecd2d"}
{"timestamp": "2025-12-17T12:17:08.622504", "session_id": "e5716fb8538b8fbb", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider_consistency_shim.py::TestPQCProviderConsistencyShim::test_structural_compatibility_of_keypairs", "context": {"env": "test"}, "details": {"duration": 0.0003810000198427588, "error": "log_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_structural_compatibility', 'timestamp':...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5'\nparameters = {}, pqc_cid = 'test_structural_compatibility'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n>               private_key, public_key = Dilithium5Impl.keygen(seed)\n                                          ^^^^^^^^^^^^^^^^^^^^^\nE               AttributeError: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:657: AttributeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <v13.tests.unit.test_pqc_provider_consistency_shim.TestPQCProviderConsistencyShim testMethod=test_structural_compatibility_of_keypairs>\n\n    def test_structural_compatibility_of_keypairs(self):\n        \"\"\"Test that mock and concrete providers produce structurally compatible key pairs\"\"\"\n        # Generate key pairs from both providers\n        mock_keypair = self.mock_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_structural_compatibility\"\n        )\n    \n>       concrete_keypair = self.concrete_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_structural_compatibility\"\n        )\n\nv13\\tests\\unit\\test_pqc_provider_consistency_shim.py:35: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nv13\\libs\\pqc\\ConcretePQCProvider.py:76: in generate_keypair\n    legacy_keypair = LegacyPQC.generate_keypair(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlog_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_structural_compatibility', 'timestamp':...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5'\nparameters = {}, pqc_cid = 'test_structural_compatibility'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n                private_key, public_key = Dilithium5Impl.keygen(seed)\n            else:\n                raise PQCError(f\"Unsupported algorithm: {algorithm}\")\n    \n            # Convert private key to mutable bytearray for secure handling\n            private_key_array = bytearray(private_key)\n    \n            result_keypair = KeyPair(\n                private_key=private_key_array,\n                public_key=public_key,\n                algorithm=algorithm,\n                parameters=parameters\n            )\n    \n            # Log the successful operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"public_key_size\": len(public_key),\n                    \"seed_provided\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp\n            )\n    \n            return result_keypair\n    \n        except Exception as e:\n            # Log the failed operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"error_occurred\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp,\n                error=e\n            )\n>           raise PQCError(f\"Failed to generate keypair: {str(e)}\") from e\nE           v13.libs.PQC.PQCError: Failed to generate keypair: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:703: PQCError"}, "hash": "c5d3e84fe54d24cae1e507546dc02cda6a041442ba3d16f29fbc9d3b43912cb5a2df15fe18a0a4961c1da3793bc56159fd69d2757a83de44eef9526b695ce429"}
{"timestamp": "2025-12-17T12:17:13.091881", "session_id": "9ccc1fbb6332fa39", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider_consistency_shim.py::TestPQCProviderConsistencyShim::test_backend_info_consistency", "context": {"env": "test"}, "details": {"duration": 0.00033549999352544546, "error": "self = <v13.tests.unit.test_pqc_provider_consistency_shim.TestPQCProviderConsistencyShim testMethod=test_backend_info_consistency>\n\n    def test_backend_info_consistency(self):\n        \"\"\"Test that backend info is consistently provided\"\"\"\n        mock_info = self.mock_provider.get_backend_info()\n>       concrete_info = self.concrete_provider.get_backend_info()\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\unit\\test_pqc_provider_consistency_shim.py:260: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <v13.libs.pqc.ConcretePQCProvider.ConcretePQCProvider object at 0x0000022EE6FBCC20>\n\n    def get_backend_info(self) -> Dict[str, Any]:\n        \"\"\"\n        Get information about the currently active PQC backend.\n    \n        Returns:\n            Dictionary with backend information\n        \"\"\"\n        # Get backend info from legacy implementation\n>       legacy_info = LegacyPQC.get_backend_info()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PQC' has no attribute 'get_backend_info'\n\nv13\\libs\\pqc\\ConcretePQCProvider.py:203: AttributeError"}, "hash": "ca443f870bec19336b92329dd9d975d91a7c2611cb5ea8ff7018946c28ff19e113311f54d050129f24cb77fa9569ba17689ae2a848b3a7ca014f3170311307b8"}
{"timestamp": "2025-12-17T12:17:13.116313", "session_id": "9ccc1fbb6332fa39", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider_consistency_shim.py::TestPQCProviderConsistencyShim::test_signature_structure_compatibility", "context": {"env": "test"}, "details": {"duration": 0.00026229998911730945, "error": "log_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_signature_structure', 'timestamp': 0}, ...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5', parameters = {}, pqc_cid = 'test_signature_structure'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n>               private_key, public_key = Dilithium5Impl.keygen(seed)\n                                          ^^^^^^^^^^^^^^^^^^^^^\nE               AttributeError: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:657: AttributeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <v13.tests.unit.test_pqc_provider_consistency_shim.TestPQCProviderConsistencyShim testMethod=test_signature_structure_compatibility>\n\n    def test_signature_structure_compatibility(self):\n        \"\"\"Test that signatures from both providers have compatible structures\"\"\"\n        # Generate key pairs\n        mock_keypair = self.mock_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_signature_structure\"\n        )\n    \n>       concrete_keypair = self.concrete_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_signature_structure\"\n        )\n\nv13\\tests\\unit\\test_pqc_provider_consistency_shim.py:75: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nv13\\libs\\pqc\\ConcretePQCProvider.py:76: in generate_keypair\n    legacy_keypair = LegacyPQC.generate_keypair(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlog_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_signature_structure', 'timestamp': 0}, ...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5', parameters = {}, pqc_cid = 'test_signature_structure'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n                private_key, public_key = Dilithium5Impl.keygen(seed)\n            else:\n                raise PQCError(f\"Unsupported algorithm: {algorithm}\")\n    \n            # Convert private key to mutable bytearray for secure handling\n            private_key_array = bytearray(private_key)\n    \n            result_keypair = KeyPair(\n                private_key=private_key_array,\n                public_key=public_key,\n                algorithm=algorithm,\n                parameters=parameters\n            )\n    \n            # Log the successful operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"public_key_size\": len(public_key),\n                    \"seed_provided\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp\n            )\n    \n            return result_keypair\n    \n        except Exception as e:\n            # Log the failed operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"error_occurred\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp,\n                error=e\n            )\n>           raise PQCError(f\"Failed to generate keypair: {str(e)}\") from e\nE           v13.libs.PQC.PQCError: Failed to generate keypair: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:703: PQCError"}, "hash": "c8032354da575616bc41224e3a1091bee872cba958d7751695b496d34fd08f7e659eb00734e859d08e04ab8d727f3e7981b818377fe5b522ad18affa5c6693fd"}
{"timestamp": "2025-12-17T12:17:13.138004", "session_id": "9ccc1fbb6332fa39", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider_consistency_shim.py::TestPQCProviderConsistencyShim::test_signature_verification_compatibility", "context": {"env": "test"}, "details": {"duration": 0.0002837000065483153, "error": "log_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_verification_compatibility', 'timestamp...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5', parameters = {}, pqc_cid = 'test_verification_compatibility'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n>               private_key, public_key = Dilithium5Impl.keygen(seed)\n                                          ^^^^^^^^^^^^^^^^^^^^^\nE               AttributeError: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:657: AttributeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <v13.tests.unit.test_pqc_provider_consistency_shim.TestPQCProviderConsistencyShim testMethod=test_signature_verification_compatibility>\n\n    def test_signature_verification_compatibility(self):\n        \"\"\"Test that signatures from one provider can be verified by the other\"\"\"\n        # Generate key pairs\n        mock_keypair = self.mock_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_verification_compatibility\"\n        )\n    \n>       concrete_keypair = self.concrete_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_verification_compatibility\"\n        )\n\nv13\\tests\\unit\\test_pqc_provider_consistency_shim.py:113: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nv13\\libs\\pqc\\ConcretePQCProvider.py:76: in generate_keypair\n    legacy_keypair = LegacyPQC.generate_keypair(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlog_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_verification_compatibility', 'timestamp...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5', parameters = {}, pqc_cid = 'test_verification_compatibility'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n                private_key, public_key = Dilithium5Impl.keygen(seed)\n            else:\n                raise PQCError(f\"Unsupported algorithm: {algorithm}\")\n    \n            # Convert private key to mutable bytearray for secure handling\n            private_key_array = bytearray(private_key)\n    \n            result_keypair = KeyPair(\n                private_key=private_key_array,\n                public_key=public_key,\n                algorithm=algorithm,\n                parameters=parameters\n            )\n    \n            # Log the successful operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"public_key_size\": len(public_key),\n                    \"seed_provided\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp\n            )\n    \n            return result_keypair\n    \n        except Exception as e:\n            # Log the failed operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"error_occurred\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp,\n                error=e\n            )\n>           raise PQCError(f\"Failed to generate keypair: {str(e)}\") from e\nE           v13.libs.PQC.PQCError: Failed to generate keypair: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:703: PQCError"}, "hash": "c0239aa2623722cf6d33a684644b89a7296a0d64605ddac4718d1324fef95ff4d0affbd595c6e9c7dbaf05ec5ee3f7b688cb41dd12f63f6e027fd126cf0a3cc7"}
{"timestamp": "2025-12-17T12:17:13.158990", "session_id": "9ccc1fbb6332fa39", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider_consistency_shim.py::TestPQCProviderConsistencyShim::test_structural_compatibility_of_keypairs", "context": {"env": "test"}, "details": {"duration": 0.0002666999935172498, "error": "log_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_structural_compatibility', 'timestamp':...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5', parameters = {}, pqc_cid = 'test_structural_compatibility'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n>               private_key, public_key = Dilithium5Impl.keygen(seed)\n                                          ^^^^^^^^^^^^^^^^^^^^^\nE               AttributeError: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:657: AttributeError\n\nThe above exception was the direct cause of the following exception:\n\nself = <v13.tests.unit.test_pqc_provider_consistency_shim.TestPQCProviderConsistencyShim testMethod=test_structural_compatibility_of_keypairs>\n\n    def test_structural_compatibility_of_keypairs(self):\n        \"\"\"Test that mock and concrete providers produce structurally compatible key pairs\"\"\"\n        # Generate key pairs from both providers\n        mock_keypair = self.mock_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_structural_compatibility\"\n        )\n    \n>       concrete_keypair = self.concrete_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_structural_compatibility\"\n        )\n\nv13\\tests\\unit\\test_pqc_provider_consistency_shim.py:35: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nv13\\libs\\pqc\\ConcretePQCProvider.py:76: in generate_keypair\n    legacy_keypair = LegacyPQC.generate_keypair(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlog_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_structural_compatibility', 'timestamp':...', 'error': {'message': \"'NoneType' object has no attribute 'keygen'\", 'type': 'AttributeError'}, 'log_index': 1, ...}]\nseed = b'test_seed_for_deterministic_generation', algorithm = 'Dilithium5', parameters = {}, pqc_cid = 'test_structural_compatibility'\nquantum_metadata = {'seed_hash': '5a841be4b9fb1a1fbe747bcc39f26469ef94fd3d4f9bc0132bf2522ff6983201d7b16c3aad51e719d9efa4a62b3c19fda9440aa0196823474e60c8146f76bbdf'}\ndeterministic_timestamp = 0\n\n    @staticmethod\n    def generate_keypair(\n        log_list: List[Dict[str, Any]],\n        seed: bytes,\n        algorithm: str = DILITHIUM5,\n        parameters: Optional[Dict[str, Any]] = None,\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> KeyPair:\n        \"\"\"\n        Generates a deterministic PQC keypair using the specified algorithm.\n        Production PQC.py must call real functions (Section 2.1)\n        \"\"\"\n        if log_list is None:\n            raise ValueError(\"log_list is required for generate_keypair\")\n    \n        if parameters is None:\n            parameters = {}\n    \n        # Validate seed is provided (Section 4.1)\n        if not seed:\n            raise ValueError(\"seed is required for deterministic key generation\")\n    \n        # Log the seed (Section 2.3)\n        seed_hash = hashlib.sha3_512(seed).hexdigest()\n        if quantum_metadata is None:\n            quantum_metadata = {}\n        quantum_metadata[\"seed_hash\"] = seed_hash\n    \n        try:\n            # Generate keypair using the real PQC library (Section 2.1)\n            if algorithm == PQC.DILITHIUM5:\n                # Use seed deterministically\n                private_key, public_key = Dilithium5Impl.keygen(seed)\n            else:\n                raise PQCError(f\"Unsupported algorithm: {algorithm}\")\n    \n            # Convert private key to mutable bytearray for secure handling\n            private_key_array = bytearray(private_key)\n    \n            result_keypair = KeyPair(\n                private_key=private_key_array,\n                public_key=public_key,\n                algorithm=algorithm,\n                parameters=parameters\n            )\n    \n            # Log the successful operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"public_key_size\": len(public_key),\n                    \"seed_provided\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp\n            )\n    \n            return result_keypair\n    \n        except Exception as e:\n            # Log the failed operation\n            PQC._log_pqc_operation(\n                operation=\"generate_keypair\",\n                details={\n                    \"algorithm\": algorithm,\n                    \"parameters\": parameters,\n                    \"error_occurred\": True\n                },\n                log_list=log_list,\n                pqc_cid=pqc_cid,\n                quantum_metadata=quantum_metadata,\n                deterministic_timestamp=deterministic_timestamp,\n                error=e\n            )\n>           raise PQCError(f\"Failed to generate keypair: {str(e)}\") from e\nE           v13.libs.PQC.PQCError: Failed to generate keypair: 'NoneType' object has no attribute 'keygen'\n\nv13\\libs\\PQC.py:703: PQCError"}, "hash": "057f67c97221d5a7d5e24bb26482c6881249ea9815f59bb521259be59d46f6166d396e6dd677a737af1fac78e419fc7e084158df2d22c76bb987bba29b4f5d53"}
{"timestamp": "2025-12-17T12:18:49.812314", "session_id": "c6c127593cf34601", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_pqc_provider_consistency_shim.py::TestPQCProviderConsistencyShim::test_signature_verification_compatibility", "context": {"env": "test"}, "details": {"duration": 0.00030410001636482775, "error": "self = <v13.tests.unit.test_pqc_provider_consistency_shim.TestPQCProviderConsistencyShim testMethod=test_signature_verification_compatibility>\n\n    def test_signature_verification_compatibility(self):\n        \"\"\"Test that signatures from one provider can be verified by the other\"\"\"\n        # Generate key pairs\n        mock_keypair = self.mock_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_verification_compatibility\"\n        )\n    \n        concrete_keypair = self.concrete_provider.generate_keypair(\n            log_list=self.log_list,\n            seed=self.test_seed,\n            pqc_cid=\"test_verification_compatibility\"\n        )\n    \n        # Generate signatures\n        mock_signature = self.mock_provider.sign_data(\n            private_key_handle=mock_keypair.private_key_handle,\n            data=self.test_data,\n            log_list=self.log_list,\n            pqc_cid=\"test_verification_compatibility\"\n        )\n    \n        concrete_signature = self.concrete_provider.sign_data(\n            private_key_handle=concrete_keypair.private_key_handle,\n            data=self.test_data,\n            log_list=self.log_list,\n            pqc_cid=\"test_verification_compatibility\"\n        )\n    \n        # Verify mock signature with concrete provider\n>       mock_sig_validation = self.concrete_provider.verify_signature(\n            public_key=mock_keypair.public_key,\n            data=self.test_data,\n            signature=mock_signature,\n            log_list=self.log_list,\n            pqc_cid=\"test_verification_compatibility\"\n        )\n\nv13\\tests\\unit\\test_pqc_provider_consistency_shim.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <v13.libs.pqc.ConcretePQCProvider.ConcretePQCProvider object at 0x000002D67F84D940>\npublic_key = b')\\xdc\\x0fU\\xbde\\x93\\xb8\\xb6\\x0b\\xfbn\\xf3\\xa1\\xf0\\xfbW\\xb5\\x87\\x93\\xa8o\\xf65\\xeb`\\x0e\\x16\\xcd\\x02\\xae\\x91'\ndata = {'message': 'test_data_for_signing', 'value': 42}\nsignature = b'r\\x97\\xb3\\xb8~28\\xc87H\\x82\\xfc\\xf8\\xd1.\\xe5\\r\\xab\\xaesF\\xb9\\xc7C\\xd0\\x0b\\xca\\xad\\xf1\\xee\\xf9\\xeb'\nlog_list = [{'algorithm': 'Dilithium5', 'operation': 'generate_keypair', 'pqc_cid': 'test_verification_compatibility', 'timestamp...}, {'algorithm': 'Dilithium5', 'operation': 'sign_data', 'pqc_cid': 'test_verification_compatibility', 'timestamp': 0}]\npqc_cid = 'test_verification_compatibility', quantum_metadata = None, deterministic_timestamp = 0\n\n    def verify_signature(\n        self,\n        public_key: bytes,\n        data: Any,\n        signature: bytes,\n        log_list: List[Dict[str, Any]],\n        pqc_cid: Optional[str] = None,\n        quantum_metadata: Optional[Dict[str, Any]] = None,\n        deterministic_timestamp: int = 0,\n    ) -> ValidationResult:\n        \"\"\"\n        Verifies a signature against data using the provided public key.\n    \n        Args:\n            public_key: Public key bytes\n            data: Data that was signed (will be canonically serialized)\n            signature: Signature to verify\n            log_list: List to append audit log entries\n            pqc_cid: Correlation ID for tracing\n            quantum_metadata: Additional quantum-related metadata\n            deterministic_timestamp: Timestamp for deterministic operations\n    \n        Returns:\n            ValidationResult with verification outcome\n        \"\"\"\n        if self._use_mock:\n            # Use mock implementation when real backend is not available\n>           private_key = private_key_handle.metadata[\"legacy_private_key\"]\n                          ^^^^^^^^^^^^^^^^^^\nE           NameError: name 'private_key_handle' is not defined\n\nv13\\libs\\pqc\\ConcretePQCProvider.py:238: NameError"}, "hash": "1c4b3dcf0644baa7e77dcc632aa1da798cb077878a5a5b6c495208f4d3d09a96f9f3a9d41d2592698d3dbd90bc0453b2b0263d4feaf42e8206fdc3a7c5606394"}
{"timestamp": "2025-12-17T13:23:35.049994", "session_id": "a5c12ff42f438b6a", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_explain_this_system.py::test_reward_explanation", "context": {"env": "test"}, "details": {"duration": 0.04058130001067184, "error": "def test_reward_explanation():\n        engine = ExplainerEngine(policy_version=\"v13.8\")\n    \n        # Mock ledger events\n        ledger_events = [\n            {\"id\": \"reward_123\", \"type\": \"REWARD\", \"amount\": 100, \"user_id\": \"0xUser\"}\n        ]\n    \n>       explanation = engine.explain(\"reward\", \"reward_123\", ledger_events)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\unit\\test_explain_this_system.py:19: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\services\\explainer\\engine.py:51: in explain\n    explanation_data = resolver.resolve(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <v13.services.explainer.resolvers.RewardResolver object at 0x000001D3A714D160>, entity_id = 'reward_123'\nledger_events = [{'amount': 100, 'id': 'reward_123', 'type': 'REWARD', 'user_id': '0xUser'}], policy_version = 'v13.8'\n\n    def resolve(\n        self, entity_id: str, ledger_events: List[Dict[str, Any]], policy_version: str\n    ) -> Dict[str, Any]:\n        # Find the reward event\n        reward_event = None\n        for event in sorted(ledger_events, key=lambda x: str(x.get('id', '')) + str(x.get('type', ''))):\n            if event.get(\"id\") == entity_id and event.get(\"type\") == \"REWARD\":\n                reward_event = event\n                break\n    \n        if not reward_event:\n            return {\"inputs\": [], \"computation\": {}}\n    \n        # Mock computation - use integers for Zero-Sim compliance\n        base_reward = reward_event.get(\"amount\", 100)\n        coherence_multiplier_scaled = 120  # 1.2 * 100 (scaled by 100)\n    \n        return {\n            \"inputs\": [\n                {\n                    \"event_id\": \"content_posted\",\n                    \"weight\": 60,  # 0.6 * 100 (percentage as integer)\n                    \"description\": \"Content contribution\",\n                },\n                {\n                    \"event_id\": \"coherence_score\",\n                    \"weight\": 40,  # 0.4 * 100 (percentage as integer)\n                    \"description\": \"User reputation\",\n                },\n            ],\n            \"computation\": {\n                \"base_reward\": base_reward,\n                \"coherence_multiplier_scaled\": coherence_multiplier_scaled,\n>               \"final_reward\": CertifiedMath.idiv(\n                    base_reward * coherence_multiplier_scaled, 100\n                ),\n            },\n        }\nE       TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\explainer\\resolvers.py:54: TypeError"}, "hash": "9b1da3562ab1fcc6b0192ae0808ab13260cdef399826fa2f35b427f1132f16fa350bb7af83713525102c5ccd6f16c7c7ec3956b5637b41e2c58b4cdb1c5402f4"}
{"timestamp": "2025-12-17T13:23:35.062659", "session_id": "a5c12ff42f438b6a", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_explain_this_system.py::test_proof_hash_determinism", "context": {"env": "test"}, "details": {"duration": 0.00023450001026503742, "error": "def test_proof_hash_determinism():\n        \"\"\"Verify that proof hash is deterministic.\"\"\"\n        engine = ExplainerEngine(policy_version=\"v13.8\")\n    \n        ledger_events = [{\"id\": \"e1\", \"type\": \"REWARD\", \"amount\": 50}]\n    \n>       exp1 = engine.explain(\"reward\", \"e1\", ledger_events)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\unit\\test_explain_this_system.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\services\\explainer\\engine.py:51: in explain\n    explanation_data = resolver.resolve(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <v13.services.explainer.resolvers.RewardResolver object at 0x000001D3A7072FD0>, entity_id = 'e1'\nledger_events = [{'amount': 50, 'id': 'e1', 'type': 'REWARD'}], policy_version = 'v13.8'\n\n    def resolve(\n        self, entity_id: str, ledger_events: List[Dict[str, Any]], policy_version: str\n    ) -> Dict[str, Any]:\n        # Find the reward event\n        reward_event = None\n        for event in sorted(ledger_events, key=lambda x: str(x.get('id', '')) + str(x.get('type', ''))):\n            if event.get(\"id\") == entity_id and event.get(\"type\") == \"REWARD\":\n                reward_event = event\n                break\n    \n        if not reward_event:\n            return {\"inputs\": [], \"computation\": {}}\n    \n        # Mock computation - use integers for Zero-Sim compliance\n        base_reward = reward_event.get(\"amount\", 100)\n        coherence_multiplier_scaled = 120  # 1.2 * 100 (scaled by 100)\n    \n        return {\n            \"inputs\": [\n                {\n                    \"event_id\": \"content_posted\",\n                    \"weight\": 60,  # 0.6 * 100 (percentage as integer)\n                    \"description\": \"Content contribution\",\n                },\n                {\n                    \"event_id\": \"coherence_score\",\n                    \"weight\": 40,  # 0.4 * 100 (percentage as integer)\n                    \"description\": \"User reputation\",\n                },\n            ],\n            \"computation\": {\n                \"base_reward\": base_reward,\n                \"coherence_multiplier_scaled\": coherence_multiplier_scaled,\n>               \"final_reward\": CertifiedMath.idiv(\n                    base_reward * coherence_multiplier_scaled, 100\n                ),\n            },\n        }\nE       TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\explainer\\resolvers.py:54: TypeError"}, "hash": "109be1a2e9508a37bfb0b9ac789a6b66f6b0ddc85296d80ec7c053451ead177c621f4e88665581ce9216195b6f75a8ad739cbb59dd0ba120f77cfa6433f54ef1"}
{"timestamp": "2025-12-17T13:23:35.073281", "session_id": "a5c12ff42f438b6a", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_explain_this_system.py::test_explanation_structure", "context": {"env": "test"}, "details": {"duration": 0.00019580000662244856, "error": "def test_explanation_structure():\n        \"\"\"Verify all required fields are present.\"\"\"\n        engine = ExplainerEngine()\n    \n>       explanation = engine.explain(\n            \"reward\", \"r1\", [{\"id\": \"r1\", \"type\": \"REWARD\", \"amount\": 100}]\n        )\n\nv13\\tests\\unit\\test_explain_this_system.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\services\\explainer\\engine.py:51: in explain\n    explanation_data = resolver.resolve(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <v13.services.explainer.resolvers.RewardResolver object at 0x000001D3A71E32F0>, entity_id = 'r1'\nledger_events = [{'amount': 100, 'id': 'r1', 'type': 'REWARD'}], policy_version = 'v13.8'\n\n    def resolve(\n        self, entity_id: str, ledger_events: List[Dict[str, Any]], policy_version: str\n    ) -> Dict[str, Any]:\n        # Find the reward event\n        reward_event = None\n        for event in sorted(ledger_events, key=lambda x: str(x.get('id', '')) + str(x.get('type', ''))):\n            if event.get(\"id\") == entity_id and event.get(\"type\") == \"REWARD\":\n                reward_event = event\n                break\n    \n        if not reward_event:\n            return {\"inputs\": [], \"computation\": {}}\n    \n        # Mock computation - use integers for Zero-Sim compliance\n        base_reward = reward_event.get(\"amount\", 100)\n        coherence_multiplier_scaled = 120  # 1.2 * 100 (scaled by 100)\n    \n        return {\n            \"inputs\": [\n                {\n                    \"event_id\": \"content_posted\",\n                    \"weight\": 60,  # 0.6 * 100 (percentage as integer)\n                    \"description\": \"Content contribution\",\n                },\n                {\n                    \"event_id\": \"coherence_score\",\n                    \"weight\": 40,  # 0.4 * 100 (percentage as integer)\n                    \"description\": \"User reputation\",\n                },\n            ],\n            \"computation\": {\n                \"base_reward\": base_reward,\n                \"coherence_multiplier_scaled\": coherence_multiplier_scaled,\n>               \"final_reward\": CertifiedMath.idiv(\n                    base_reward * coherence_multiplier_scaled, 100\n                ),\n            },\n        }\nE       TypeError: CertifiedMath.idiv() missing 1 required positional argument: 'b_int'\n\nv13\\services\\explainer\\resolvers.py:54: TypeError"}, "hash": "e870efe8f5a245a92b72a2facccd29e357adc5d4e37a714b71e18981c7133932ecebc4a4353f7c7d0f9587c94bb07a9f8074fb8b86546dc56d0fc1dc96b56942"}
{"timestamp": "2025-12-17T13:24:08.639558", "session_id": "939517fe057f0bba", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_explain_this_system.py::test_reward_explanation", "context": {"env": "test"}, "details": {"duration": 0.002279500011354685, "error": "def test_reward_explanation():\n        engine = ExplainerEngine(policy_version=\"v13.8\")\n    \n        # Mock ledger events\n        ledger_events = [\n            {\"id\": \"reward_123\", \"type\": \"REWARD\", \"amount\": 100, \"user_id\": \"0xUser\"}\n        ]\n    \n>       explanation = engine.explain(\"reward\", \"reward_123\", ledger_events)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\unit\\test_explain_this_system.py:19: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\services\\explainer\\engine.py:51: in explain\n    explanation_data = resolver.resolve(\nv13\\services\\explainer\\resolvers.py:60: in resolve\n    base_reward * coherence_multiplier_scaled, 100\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nv13\\libs\\BigNum128.py:212: in __mul__\n    return self.mul(other)\n           ^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BigNum128(raw=100000000000000000000, fp='100.0'), other = 120\n\n    def mul(self, other: 'BigNum128') -> 'BigNum128':\n        \"\"\"Multiplies two BigNum128 values.\"\"\"\n        from .CertifiedMath import CertifiedMath\n        cm = CertifiedMath()\n        # Perform multiplication with proper scaling\n>       result = cm.mul(self.value, other.value)\n                                    ^^^^^^^^^^^\nE       AttributeError: 'int' object has no attribute 'value'\n\nv13\\libs\\BigNum128.py:269: AttributeError"}, "hash": "fab74b4277c4bb99b2d9402f7e8de84a09fa69d8419444f35c5d2f50b12fcab343de19d804c8d3324323d06a412eef33776d40cea38bfb705eb88903cf1f215d"}
{"timestamp": "2025-12-17T13:24:29.116084", "session_id": "5f1b8272cb292806", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/unit/test_explain_this_system.py::test_reward_explanation", "context": {"env": "test"}, "details": {"duration": 0.0026578999822959304, "error": "def test_reward_explanation():\n        engine = ExplainerEngine(policy_version=\"v13.8\")\n    \n        # Mock ledger events\n        ledger_events = [\n            {\"id\": \"reward_123\", \"type\": \"REWARD\", \"amount\": 100, \"user_id\": \"0xUser\"}\n        ]\n    \n>       explanation = engine.explain(\"reward\", \"reward_123\", ledger_events)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\unit\\test_explain_this_system.py:19: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\services\\explainer\\engine.py:56: in explain\n    proof_input = json.dumps(\nC:\\Python313\\Lib\\json\\__init__.py:238: in dumps\n    **kw).encode(obj)\n          ^^^^^^^^^^^\nC:\\Python313\\Lib\\json\\encoder.py:200: in encode\n    chunks = self.iterencode(o, _one_shot=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Python313\\Lib\\json\\encoder.py:261: in iterencode\n    return _iterencode(o, 0)\n           ^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <json.encoder.JSONEncoder object at 0x0000018E1A996EA0>, o = BigNum128(raw=100000000000000000000, fp='100.0')\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return super().default(o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type BigNum128 is not JSON serializable\n\nC:\\Python313\\Lib\\json\\encoder.py:180: TypeError"}, "hash": "e99a87994aa7132f9792e82c58bbcd88258d79a5090b551186ebb503082dd52961222ac393c002b11ac35e49f3f47aa50f7f1772cb19093ef85dc7ee1faa1161"}
{"timestamp": "2025-12-17T13:31:58.594350", "session_id": "8d60c39290a775db", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0003892999957315624, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n>       genesis_state = boot_from_genesis(cm)\n                        ^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\test_phase3_integration.py:46: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncertified_math = <v13.libs.CertifiedMath.CertifiedMath object at 0x0000014687FDDFD0>, pqc = None\n\n    def boot_from_genesis(certified_math=None, pqc=None) -> dict:\n        \"\"\"Safe boot with comprehensive validation and proof generation.\"\"\"\n        validation_result = validate_genesis_constraints(certified_math, pqc)\n    \n        if not validation_result[\"valid\"]:\n>           raise SystemError(f\"Genesis boot failed: {validation_result['violations']}\")\nE           SystemError: Genesis boot failed: [\"Validation error: 'CertifiedMath' object has no attribute 'verify_genesis_state'\"]\n\nv13\\libs\\economics\\GenesisHarmonicState.py:311: SystemError"}, "hash": "2270ce4c167f3aba4e224f787545ff5ca3dd0761f653de9106a653b157c79632e8388bf9a2e9c46a30646bdd590aa532e46c8c83aa17a2b7ddf474882acbc38c"}
{"timestamp": "2025-12-17T13:39:03.837813", "session_id": "aeac1ad24e767651", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0009057999996002764, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n        genesis_state = boot_from_genesis(cm)\n        print(\"\u2713 Genesis state created\")\n    \n        # Create PsiFieldEngine\n        psi_field = DiscretePsiField(genesis_topology, cm)\n        print(\"\u2713 PsiFieldEngine created\")\n    \n        # Create HarmonicEconomics\n        economics = HarmonicEconomics(psi_field, cm)\n        print(\"\u2713 HarmonicEconomics created\")\n    \n        # Create PsiSyncProtocol\n        psisync = PsiSyncProtocol(cm)\n        print(\"\u2713 PsiSyncProtocol created\")\n    \n        # Create Mock PQC instance\n        pqc = MockPQC()\n    \n        # Create TreasuryDistributionEngine\n        treasury = TreasuryDistributionEngine(cm, pqc, None, psi_field, psisync)\n        print(\"\u2713 TreasuryDistributionEngine created\")\n    \n        # Create HoloRewardEngine\n        holo_reward = HoloRewardEngine(cm, None, psi_field)\n        print(\"\u2713 HoloRewardEngine created\")\n    \n        # Create CoherenceLedger\n        ledger = CoherenceLedger(cm)\n        print(\"\u2713 CoherenceLedger created\")\n    \n        # Create SystemRecoveryProtocol\n        founding_nodes = GENESIS_STATE[\"governance\"][\"founding_nodes\"]\n        recovery_threshold = GENESIS_STATE[\"governance\"][\"recovery_threshold\"]\n        recovery = SystemRecoveryProtocol(cm, pqc, founding_nodes, recovery_threshold)\n        print(\"\u2713 SystemRecoveryProtocol created\")\n    \n        # Integrate recovery protocol with components\n        recovery.integrate_with_phase3_components(\n            psi_field_engine=psi_field,\n            harmonic_economics=economics,\n            treasury_engine=treasury,\n            psisync_protocol=psisync\n        )\n        print(\"\u2713 Recovery protocol integrated with Phase 3 components\")\n    \n        # Create EconomicAdversarySuite\n        adversary_suite = EconomicAdversarySuite(\n            cm, psi_field, economics, treasury, psisync, ledger, recovery, genesis_state\n        )\n        print(\"\u2713 EconomicAdversarySuite created\")\n    \n        # Test basic functionality\n        # Create a token state bundle from genesis state\n        chr_state = {\n            \"shards\": genesis_state[\"token_allocations\"][\"shards\"]\n        }\n    \n>       token_bundle = create_token_state_bundle(\n            chr_state=chr_state,\n            flx_state={},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            lambda1=BigNum128(1618033988749894848),\n            lambda2=BigNum128(618033988749894848),\n            c_crit=BigNum128(1000000000000000000),\n            pqc_cid=\"TEST_PHASE3_INTEGRATION\",\n            timestamp=1234567890,\n            parameters={\n                \"\u03b4_curl\": BigNum128(10),\n                \"MAX_CHR_SUPPLY\": BigNum128(10000000000),\n                \"\u03b4_max\": BigNum128(5),\n                \"\u03b5_sync\": BigNum128(2)\n            }\n        )\nE       TypeError: create_token_state_bundle() missing 1 required positional argument: 'nod_state'\n\nv13\\tests\\test_phase3_integration.py:103: TypeError"}, "hash": "5e1f82cd70efa5e5664368fc62f0c329b1fa24116a2ff4a35323a08965970f30d3ae9265a626728de2da12ef5a346c1abfda5b9db4c9cde10b4626313417ee0d"}
{"timestamp": "2025-12-17T13:39:28.303105", "session_id": "f553f2e0e69888ea", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0010245000012218952, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n        genesis_state = boot_from_genesis(cm)\n        print(\"\u2713 Genesis state created\")\n    \n        # Create PsiFieldEngine\n        psi_field = DiscretePsiField(genesis_topology, cm)\n        print(\"\u2713 PsiFieldEngine created\")\n    \n        # Create HarmonicEconomics\n        economics = HarmonicEconomics(psi_field, cm)\n        print(\"\u2713 HarmonicEconomics created\")\n    \n        # Create PsiSyncProtocol\n        psisync = PsiSyncProtocol(cm)\n        print(\"\u2713 PsiSyncProtocol created\")\n    \n        # Create Mock PQC instance\n        pqc = MockPQC()\n    \n        # Create TreasuryDistributionEngine\n        treasury = TreasuryDistributionEngine(cm, pqc, None, psi_field, psisync)\n        print(\"\u2713 TreasuryDistributionEngine created\")\n    \n        # Create HoloRewardEngine\n        holo_reward = HoloRewardEngine(cm, None, psi_field)\n        print(\"\u2713 HoloRewardEngine created\")\n    \n        # Create CoherenceLedger\n        ledger = CoherenceLedger(cm)\n        print(\"\u2713 CoherenceLedger created\")\n    \n        # Create SystemRecoveryProtocol\n        founding_nodes = GENESIS_STATE[\"governance\"][\"founding_nodes\"]\n        recovery_threshold = GENESIS_STATE[\"governance\"][\"recovery_threshold\"]\n        recovery = SystemRecoveryProtocol(cm, pqc, founding_nodes, recovery_threshold)\n        print(\"\u2713 SystemRecoveryProtocol created\")\n    \n        # Integrate recovery protocol with components\n        recovery.integrate_with_phase3_components(\n            psi_field_engine=psi_field,\n            harmonic_economics=economics,\n            treasury_engine=treasury,\n            psisync_protocol=psisync\n        )\n        print(\"\u2713 Recovery protocol integrated with Phase 3 components\")\n    \n        # Create EconomicAdversarySuite\n        adversary_suite = EconomicAdversarySuite(\n            cm, psi_field, economics, treasury, psisync, ledger, recovery, genesis_state\n        )\n        print(\"\u2713 EconomicAdversarySuite created\")\n    \n        # Test basic functionality\n        # Create a token state bundle from genesis state\n        chr_state = {\n            \"shards\": genesis_state[\"token_allocations\"][\"shards\"]\n        }\n    \n        token_bundle = create_token_state_bundle(\n            chr_state=chr_state,\n            flx_state={},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128(1618033988749894848),\n            lambda2=BigNum128(618033988749894848),\n            c_crit=BigNum128(1000000000000000000),\n            pqc_cid=\"TEST_PHASE3_INTEGRATION\",\n            timestamp=1234567890,\n            parameters={\n                \"\u03b4_curl\": BigNum128(10),\n                \"MAX_CHR_SUPPLY\": BigNum128(10000000000),\n                \"\u03b4_max\": BigNum128(5),\n                \"\u03b5_sync\": BigNum128(2)\n            }\n        )\n        print(\"\u2713 TokenStateBundle created\")\n    \n        # Test PsiFieldEngine functionality\n>       density_0 = psi_field.psi_density(\"shard_0\", token_bundle)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nv13\\tests\\test_phase3_integration.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <v13.libs.economics.PsiFieldEngine.DiscretePsiField object at 0x000001D29A11EBA0>, shard_id = 'shard_0'\nharmonic_state = TokenStateBundle(chr_state={'shards': {'shard_0': {'CHR': 3000000000, 'FLX': 1854101966, 'ATR': 50000, 'RES': 0, '\u03a8Syn...000001'), '\u03b4_max': BigNum128(raw=5, fp='0.000000000000000005'), '\u03b5_sync': BigNum128(raw=2, fp='0.000000000000000002')})\n\n    def psi_density(self, shard_id: str, harmonic_state: 'TokenStateBundle') -> int:\n        \"\"\"\n        HARDENED \u03c8-density computation with bounds checking.\n        \u03c8 = (CHR \u00d7 ATR) / (1 + DISSONANCE)\n        \"\"\"\n        # Access shard data from TokenStateBundle\n        shards = harmonic_state.chr_state.get(\"shards\", {})\n        if shard_id not in shards:\n            evidence = {\"shard_id\": shard_id, \"available_shards\": list(shards.keys())}\n            raise SecurityError(\n                f\"MISSING_SHARD: Shard {shard_id} not in harmonic state\",\n                violation_type=\"MISSING_SHARD\",\n                evidence=evidence,\n                cir_code=\"CIR-412\"\n            )\n    \n        shard = shards[shard_id]\n    \n        # Validate token values are within reasonable bounds\n>       chr_val = self.certified_math.clamp(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n            shard[\"CHR\"],\n            0,\n            SecurityThresholds.MAX_CHR_VALUE\n        )  # 1 trillion max\nE       AttributeError: 'CertifiedMath' object has no attribute 'clamp'\n\nv13\\libs\\economics\\PsiFieldEngine.py:312: AttributeError"}, "hash": "923a8030218134a430121b666af2d3477c5f28b0171a402057db74cb26f45eaec980390f9161d73e44ed7b188e250051ec5e95dbb5fdd90fd58160995e7065fb"}
{"timestamp": "2025-12-17T13:41:23.523444", "session_id": "c04e83808ed383e8", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0017133999790530652, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n        genesis_state = boot_from_genesis(cm)\n        print(\"\u2713 Genesis state created\")\n    \n        # Create PsiFieldEngine\n        psi_field = DiscretePsiField(genesis_topology, cm)\n        print(\"\u2713 PsiFieldEngine created\")\n    \n        # Create HarmonicEconomics\n        economics = HarmonicEconomics(psi_field, cm)\n        print(\"\u2713 HarmonicEconomics created\")\n    \n        # Create PsiSyncProtocol\n        psisync = PsiSyncProtocol(cm)\n        print(\"\u2713 PsiSyncProtocol created\")\n    \n        # Create Mock PQC instance\n        pqc = MockPQC()\n    \n        # Create TreasuryDistributionEngine\n        treasury = TreasuryDistributionEngine(cm, pqc, None, psi_field, psisync)\n        print(\"\u2713 TreasuryDistributionEngine created\")\n    \n        # Create HoloRewardEngine\n        holo_reward = HoloRewardEngine(cm, None, psi_field)\n        print(\"\u2713 HoloRewardEngine created\")\n    \n        # Create CoherenceLedger\n        ledger = CoherenceLedger(cm)\n        print(\"\u2713 CoherenceLedger created\")\n    \n        # Create SystemRecoveryProtocol\n        founding_nodes = GENESIS_STATE[\"governance\"][\"founding_nodes\"]\n        recovery_threshold = GENESIS_STATE[\"governance\"][\"recovery_threshold\"]\n        recovery = SystemRecoveryProtocol(cm, pqc, founding_nodes, recovery_threshold)\n        print(\"\u2713 SystemRecoveryProtocol created\")\n    \n        # Integrate recovery protocol with components\n        recovery.integrate_with_phase3_components(\n            psi_field_engine=psi_field,\n            harmonic_economics=economics,\n            treasury_engine=treasury,\n            psisync_protocol=psisync\n        )\n        print(\"\u2713 Recovery protocol integrated with Phase 3 components\")\n    \n        # Create EconomicAdversarySuite\n        adversary_suite = EconomicAdversarySuite(\n            cm, psi_field, economics, treasury, psisync, ledger, recovery, genesis_state\n        )\n        print(\"\u2713 EconomicAdversarySuite created\")\n    \n        # Test basic functionality\n        # Create a token state bundle from genesis state\n        chr_state = {\n            \"shards\": genesis_state[\"token_allocations\"][\"shards\"]\n        }\n    \n        token_bundle = create_token_state_bundle(\n            chr_state=chr_state,\n            flx_state={},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128(1618033988749894848),\n            lambda2=BigNum128(618033988749894848),\n            c_crit=BigNum128(1000000000000000000),\n            pqc_cid=\"TEST_PHASE3_INTEGRATION\",\n            timestamp=1234567890,\n            parameters={\n                \"\u03b4_curl\": BigNum128(10),\n                \"MAX_CHR_SUPPLY\": BigNum128(10000000000),\n                \"\u03b4_max\": BigNum128(5),\n                \"\u03b5_sync\": BigNum128(2)\n            }\n        )\n        print(\"\u2713 TokenStateBundle created\")\n    \n        # Test PsiFieldEngine functionality\n        density_0 = psi_field.psi_density(\"shard_0\", token_bundle)\n        print(f\"\u2713 Psi density for shard_0: {density_0}\")\n    \n        # Test HarmonicEconomics functionality\n        try:\n            new_state = economics.compute_harmonic_state(token_bundle)\n            print(\"\u2713 HarmonicEconomics compute_harmonic_state executed successfully\")\n        except Exception as e:\n            print(f\"\u26a0 HarmonicEconomics compute_harmonic_state raised exception: {e}\")\n    \n        # Test PsiSyncProtocol functionality\n        shard_psisync_values = {\n            \"shard_0\": 100,\n            \"shard_1\": 105,\n            \"shard_2\": 95,\n            \"shard_3\": 102,\n            \"shard_4\": 98\n        }\n>       consensus_result = psisync.compute_global_psisync(\n            shard_psisync_values,\n            epsilon_sync=10,\n            genesis_shard_count=5,\n            genesis_shard_ids=[\"shard_0\", \"shard_1\", \"shard_2\", \"shard_3\", \"shard_4\"]\n        )\nE       TypeError: PsiSyncProtocol.compute_global_psisync() got an unexpected keyword argument 'genesis_shard_count'\n\nv13\\tests\\test_phase3_integration.py:143: TypeError"}, "hash": "12d64f1a884610f5bd67b6fcccdf073ea4b577f5a2e86fcb93dff8920b49205c62e65f636b7dc6d7dc7164910b6e9a6b4aeafb34ebaa1391dd5cd3fe1bc4ef91"}
{"timestamp": "2025-12-17T13:42:02.903522", "session_id": "edb64830de6f3b47", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0016864999779500067, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n        genesis_state = boot_from_genesis(cm)\n        print(\"\u2713 Genesis state created\")\n    \n        # Create PsiFieldEngine\n        psi_field = DiscretePsiField(genesis_topology, cm)\n        print(\"\u2713 PsiFieldEngine created\")\n    \n        # Create HarmonicEconomics\n        economics = HarmonicEconomics(psi_field, cm)\n        print(\"\u2713 HarmonicEconomics created\")\n    \n        # Create PsiSyncProtocol\n        psisync = PsiSyncProtocol(cm)\n        print(\"\u2713 PsiSyncProtocol created\")\n    \n        # Create Mock PQC instance\n        pqc = MockPQC()\n    \n        # Create TreasuryDistributionEngine\n        treasury = TreasuryDistributionEngine(cm, pqc, None, psi_field, psisync)\n        print(\"\u2713 TreasuryDistributionEngine created\")\n    \n        # Create HoloRewardEngine\n        holo_reward = HoloRewardEngine(cm, None, psi_field)\n        print(\"\u2713 HoloRewardEngine created\")\n    \n        # Create CoherenceLedger\n        ledger = CoherenceLedger(cm)\n        print(\"\u2713 CoherenceLedger created\")\n    \n        # Create SystemRecoveryProtocol\n        founding_nodes = GENESIS_STATE[\"governance\"][\"founding_nodes\"]\n        recovery_threshold = GENESIS_STATE[\"governance\"][\"recovery_threshold\"]\n        recovery = SystemRecoveryProtocol(cm, pqc, founding_nodes, recovery_threshold)\n        print(\"\u2713 SystemRecoveryProtocol created\")\n    \n        # Integrate recovery protocol with components\n        recovery.integrate_with_phase3_components(\n            psi_field_engine=psi_field,\n            harmonic_economics=economics,\n            treasury_engine=treasury,\n            psisync_protocol=psisync\n        )\n        print(\"\u2713 Recovery protocol integrated with Phase 3 components\")\n    \n        # Create EconomicAdversarySuite\n        adversary_suite = EconomicAdversarySuite(\n            cm, psi_field, economics, treasury, psisync, ledger, recovery, genesis_state\n        )\n        print(\"\u2713 EconomicAdversarySuite created\")\n    \n        # Test basic functionality\n        # Create a token state bundle from genesis state\n        chr_state = {\n            \"shards\": genesis_state[\"token_allocations\"][\"shards\"]\n        }\n    \n        token_bundle = create_token_state_bundle(\n            chr_state=chr_state,\n            flx_state={},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128(1618033988749894848),\n            lambda2=BigNum128(618033988749894848),\n            c_crit=BigNum128(1000000000000000000),\n            pqc_cid=\"TEST_PHASE3_INTEGRATION\",\n            timestamp=1234567890,\n            parameters={\n                \"\u03b4_curl\": BigNum128(10),\n                \"MAX_CHR_SUPPLY\": BigNum128(10000000000),\n                \"\u03b4_max\": BigNum128(5),\n                \"\u03b5_sync\": BigNum128(2)\n            }\n        )\n        print(\"\u2713 TokenStateBundle created\")\n    \n        # Test PsiFieldEngine functionality\n        density_0 = psi_field.psi_density(\"shard_0\", token_bundle)\n        print(f\"\u2713 Psi density for shard_0: {density_0}\")\n    \n        # Test HarmonicEconomics functionality\n        try:\n            new_state = economics.compute_harmonic_state(token_bundle)\n            print(\"\u2713 HarmonicEconomics compute_harmonic_state executed successfully\")\n        except Exception as e:\n            print(f\"\u26a0 HarmonicEconomics compute_harmonic_state raised exception: {e}\")\n    \n        # Test PsiSyncProtocol functionality\n        shard_psisync_values = {\n            \"shard_0\": 100,\n            \"shard_1\": 105,\n            \"shard_2\": 95,\n            \"shard_3\": 102,\n            \"shard_4\": 98\n        }\n>       consensus_result = psisync.compute_global_psisync(\n            shard_psisync_values,\n            epsilon_sync=10,\n            deterministic_timestamp=1234567890,\n            drv_packet_seq=\"test_packet_1\"\n        )\n\nv13\\tests\\test_phase3_integration.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\libs\\economics\\PsiSyncProtocol.py:47: in compute_global_psisync\n    DeterministicTime.verify_drv_packet(drv_packet_seq, deterministic_timestamp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\npacket = 'test_packet_1', timestamp = 1234567890\n\n    @staticmethod\n    def verify_drv_packet(packet: Any, timestamp: int) -> None:\n        \"\"\"\n        Verifies that the provided timestamp matches the DRV packet's timestamp.\n        This ensures traceability of time to a signed source.\n    \n        Args:\n            packet: The DRV_Packet object (or compatible structure with ttsTimestamp).\n            timestamp: The deterministic timestamp to verify.\n    \n        Raises:\n            ValueError: If the timestamps do not match or packet is invalid.\n        \"\"\"\n        # Handle both DRV_Packet objects and dict representations\n        if hasattr(packet, 'ttsTimestamp'):\n            packet_ts = packet.ttsTimestamp\n        elif isinstance(packet, dict) and 'ttsTimestamp' in packet:\n            packet_ts = packet['ttsTimestamp']\n        else:\n>           raise ValueError(\"Invalid DRV packet: missing ttsTimestamp\")\nE           ValueError: Invalid DRV packet: missing ttsTimestamp\n\nv13\\libs\\DeterministicTime.py:147: ValueError"}, "hash": "3c4aafd2d59152c9bca5685e5a0cb2199246b18d9b42a3f26b9e2204554a980ee2f4f954b18426a8a16284bbed988fc65f01c85fbd9e42068343a9d66a70d4e3"}
{"timestamp": "2025-12-17T13:42:25.555550", "session_id": "630f8437659aaf92", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0018247999832965434, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n        genesis_state = boot_from_genesis(cm)\n        print(\"\u2713 Genesis state created\")\n    \n        # Create PsiFieldEngine\n        psi_field = DiscretePsiField(genesis_topology, cm)\n        print(\"\u2713 PsiFieldEngine created\")\n    \n        # Create HarmonicEconomics\n        economics = HarmonicEconomics(psi_field, cm)\n        print(\"\u2713 HarmonicEconomics created\")\n    \n        # Create PsiSyncProtocol\n        psisync = PsiSyncProtocol(cm)\n        print(\"\u2713 PsiSyncProtocol created\")\n    \n        # Create Mock PQC instance\n        pqc = MockPQC()\n    \n        # Create TreasuryDistributionEngine\n        treasury = TreasuryDistributionEngine(cm, pqc, None, psi_field, psisync)\n        print(\"\u2713 TreasuryDistributionEngine created\")\n    \n        # Create HoloRewardEngine\n        holo_reward = HoloRewardEngine(cm, None, psi_field)\n        print(\"\u2713 HoloRewardEngine created\")\n    \n        # Create CoherenceLedger\n        ledger = CoherenceLedger(cm)\n        print(\"\u2713 CoherenceLedger created\")\n    \n        # Create SystemRecoveryProtocol\n        founding_nodes = GENESIS_STATE[\"governance\"][\"founding_nodes\"]\n        recovery_threshold = GENESIS_STATE[\"governance\"][\"recovery_threshold\"]\n        recovery = SystemRecoveryProtocol(cm, pqc, founding_nodes, recovery_threshold)\n        print(\"\u2713 SystemRecoveryProtocol created\")\n    \n        # Integrate recovery protocol with components\n        recovery.integrate_with_phase3_components(\n            psi_field_engine=psi_field,\n            harmonic_economics=economics,\n            treasury_engine=treasury,\n            psisync_protocol=psisync\n        )\n        print(\"\u2713 Recovery protocol integrated with Phase 3 components\")\n    \n        # Create EconomicAdversarySuite\n        adversary_suite = EconomicAdversarySuite(\n            cm, psi_field, economics, treasury, psisync, ledger, recovery, genesis_state\n        )\n        print(\"\u2713 EconomicAdversarySuite created\")\n    \n        # Test basic functionality\n        # Create a token state bundle from genesis state\n        chr_state = {\n            \"shards\": genesis_state[\"token_allocations\"][\"shards\"]\n        }\n    \n        token_bundle = create_token_state_bundle(\n            chr_state=chr_state,\n            flx_state={},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128(1618033988749894848),\n            lambda2=BigNum128(618033988749894848),\n            c_crit=BigNum128(1000000000000000000),\n            pqc_cid=\"TEST_PHASE3_INTEGRATION\",\n            timestamp=1234567890,\n            parameters={\n                \"\u03b4_curl\": BigNum128(10),\n                \"MAX_CHR_SUPPLY\": BigNum128(10000000000),\n                \"\u03b4_max\": BigNum128(5),\n                \"\u03b5_sync\": BigNum128(2)\n            }\n        )\n        print(\"\u2713 TokenStateBundle created\")\n    \n        # Test PsiFieldEngine functionality\n        density_0 = psi_field.psi_density(\"shard_0\", token_bundle)\n        print(f\"\u2713 Psi density for shard_0: {density_0}\")\n    \n        # Test HarmonicEconomics functionality\n        try:\n            new_state = economics.compute_harmonic_state(token_bundle)\n            print(\"\u2713 HarmonicEconomics compute_harmonic_state executed successfully\")\n        except Exception as e:\n            print(f\"\u26a0 HarmonicEconomics compute_harmonic_state raised exception: {e}\")\n    \n        # Test PsiSyncProtocol functionality\n        shard_psisync_values = {\n            \"shard_0\": 100,\n            \"shard_1\": 105,\n            \"shard_2\": 95,\n            \"shard_3\": 102,\n            \"shard_4\": 98\n        }\n    \n        # Create a mock DRV packet\n        drv_packet = type('DRV_Packet', (), {\n            'ttsTimestamp': 1234567890,\n            'sequence': 1,\n            'previous_hash': '0' * 64\n        })()\n    \n>       consensus_result = psisync.compute_global_psisync(\n            shard_psisync_values,\n            epsilon_sync=10,\n            deterministic_timestamp=1234567890,\n            drv_packet_seq=drv_packet\n        )\n\nv13\\tests\\test_phase3_integration.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\libs\\economics\\PsiSyncProtocol.py:71: in compute_global_psisync\n    metrics = self._compute_consensus_metrics(cleaned_values, consensus_val, epsilon_sync)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nv13\\libs\\economics\\PsiSyncProtocol.py:193: in _compute_consensus_metrics\n    deviation = self.math.abs(self.math.sub(val, global_psisync))\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nv13\\libs\\CertifiedMath.py:100: in sub\n    return CertifiedMath._safe_sub(a, b, log_list or self.log_list, pqc_cid, quantum_metadata)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\na = BigNum128(raw=95, fp='0.000000000000000095'), b = BigNum128(raw=100, fp='0.0000000000000001')\nlog_list = [{'inputs': {'a': '0.0', 'b': '0.0'}, 'log_index': 0, 'op_name': 'sub', 'pqc_cid': None, ...}, {'inputs': {'a': '0.0'}...': 'sub', 'pqc_cid': None, ...}, {'inputs': {'a': '0.0'}, 'log_index': 5, 'op_name': 'abs', 'pqc_cid': None, ...}, ...]\npqc_cid = None, quantum_metadata = None\n\n    @staticmethod\n    def _safe_sub(a: BigNum128, b: BigNum128, log_list: List[Dict[str, Any]],\n                  pqc_cid: Optional[str] = None, quantum_metadata: Optional[Dict[str, Any]] = None) -> BigNum128:\n        # Ensure both a and b are BigNum128 objects\n        if not isinstance(a, BigNum128):\n            a = BigNum128(a)\n        if not isinstance(b, BigNum128):\n            b = BigNum128(b)\n    \n        result_value = a.value - b.value\n        if result_value < BigNum128.MIN_VALUE:\n>           raise OverflowError(\"CertifiedMath sub underflow\")\nE           OverflowError: CertifiedMath sub underflow\n\nv13\\libs\\CertifiedMath.py:521: OverflowError"}, "hash": "fb42e29a6620dd9c5b6e32de2e0e938826b7b9dff08332dc4b126fc29d1765a18531f999afea92a486ad324e14971c58872dcacc62447bb62ef0d4572ecf91ea"}
{"timestamp": "2025-12-17T13:42:43.394553", "session_id": "c2037702b14fcb15", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0018709000141825527, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n        genesis_state = boot_from_genesis(cm)\n        print(\"\u2713 Genesis state created\")\n    \n        # Create PsiFieldEngine\n        psi_field = DiscretePsiField(genesis_topology, cm)\n        print(\"\u2713 PsiFieldEngine created\")\n    \n        # Create HarmonicEconomics\n        economics = HarmonicEconomics(psi_field, cm)\n        print(\"\u2713 HarmonicEconomics created\")\n    \n        # Create PsiSyncProtocol\n        psisync = PsiSyncProtocol(cm)\n        print(\"\u2713 PsiSyncProtocol created\")\n    \n        # Create Mock PQC instance\n        pqc = MockPQC()\n    \n        # Create TreasuryDistributionEngine\n        treasury = TreasuryDistributionEngine(cm, pqc, None, psi_field, psisync)\n        print(\"\u2713 TreasuryDistributionEngine created\")\n    \n        # Create HoloRewardEngine\n        holo_reward = HoloRewardEngine(cm, None, psi_field)\n        print(\"\u2713 HoloRewardEngine created\")\n    \n        # Create CoherenceLedger\n        ledger = CoherenceLedger(cm)\n        print(\"\u2713 CoherenceLedger created\")\n    \n        # Create SystemRecoveryProtocol\n        founding_nodes = GENESIS_STATE[\"governance\"][\"founding_nodes\"]\n        recovery_threshold = GENESIS_STATE[\"governance\"][\"recovery_threshold\"]\n        recovery = SystemRecoveryProtocol(cm, pqc, founding_nodes, recovery_threshold)\n        print(\"\u2713 SystemRecoveryProtocol created\")\n    \n        # Integrate recovery protocol with components\n        recovery.integrate_with_phase3_components(\n            psi_field_engine=psi_field,\n            harmonic_economics=economics,\n            treasury_engine=treasury,\n            psisync_protocol=psisync\n        )\n        print(\"\u2713 Recovery protocol integrated with Phase 3 components\")\n    \n        # Create EconomicAdversarySuite\n        adversary_suite = EconomicAdversarySuite(\n            cm, psi_field, economics, treasury, psisync, ledger, recovery, genesis_state\n        )\n        print(\"\u2713 EconomicAdversarySuite created\")\n    \n        # Test basic functionality\n        # Create a token state bundle from genesis state\n        chr_state = {\n            \"shards\": genesis_state[\"token_allocations\"][\"shards\"]\n        }\n    \n        token_bundle = create_token_state_bundle(\n            chr_state=chr_state,\n            flx_state={},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128(1618033988749894848),\n            lambda2=BigNum128(618033988749894848),\n            c_crit=BigNum128(1000000000000000000),\n            pqc_cid=\"TEST_PHASE3_INTEGRATION\",\n            timestamp=1234567890,\n            parameters={\n                \"\u03b4_curl\": BigNum128(10),\n                \"MAX_CHR_SUPPLY\": BigNum128(10000000000),\n                \"\u03b4_max\": BigNum128(5),\n                \"\u03b5_sync\": BigNum128(2)\n            }\n        )\n        print(\"\u2713 TokenStateBundle created\")\n    \n        # Test PsiFieldEngine functionality\n        density_0 = psi_field.psi_density(\"shard_0\", token_bundle)\n        print(f\"\u2713 Psi density for shard_0: {density_0}\")\n    \n        # Test HarmonicEconomics functionality\n        try:\n            new_state = economics.compute_harmonic_state(token_bundle)\n            print(\"\u2713 HarmonicEconomics compute_harmonic_state executed successfully\")\n        except Exception as e:\n            print(f\"\u26a0 HarmonicEconomics compute_harmonic_state raised exception: {e}\")\n    \n        # Test PsiSyncProtocol functionality\n        shard_psisync_values = {\n            \"shard_0\": 100,\n            \"shard_1\": 105,\n            \"shard_2\": 95,\n            \"shard_3\": 102,\n            \"shard_4\": 98\n        }\n    \n        # Create a mock DRV packet\n        drv_packet = type('DRV_Packet', (), {\n            'ttsTimestamp': 1234567890,\n            'sequence': 1,\n            'previous_hash': '0' * 64\n        })()\n    \n>       consensus_result = psisync.compute_global_psisync(\n            shard_psisync_values,\n            epsilon_sync=10,\n            deterministic_timestamp=1234567890,\n            drv_packet_seq=drv_packet\n        )\n\nv13\\tests\\test_phase3_integration.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\libs\\economics\\PsiSyncProtocol.py:71: in compute_global_psisync\n    metrics = self._compute_consensus_metrics(cleaned_values, consensus_val, epsilon_sync)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <v13.libs.economics.PsiSyncProtocol.PsiSyncProtocol object at 0x00000210209A2F90>, values = [95, 98, 100, 102, 105], global_psisync = 100\nepsilon_sync = 10\n\n    def _compute_consensus_metrics(\n        self,\n        values: List[int],\n        global_psisync: int,\n        epsilon_sync: int\n    ) -> Dict[str, Any]:\n        \"\"\"Compute comprehensive consensus metrics with DIVISION SAFETY and quality metrics.\"\"\"\n        if not values:\n            return {\n                \"max_deviation\": 0,\n                \"average_deviation\": 0,\n                \"consensus_achieved\": False,\n                \"consensus_quality\": {\n                    \"shard_agreement_ratio\": 0.0,\n                    \"consensus_stability\": 0,\n                    \"byzantine_resistance_score\": 0\n                }\n            }\n    \n        deviations = []\n        total_deviation = 0\n    \n        for val in values:\n            deviation = self.math.abs(self.math.sub(val, global_psisync))\n            deviations.append(deviation)\n            total_deviation = self.math.add(total_deviation, deviation)\n    \n        # \ud83d\udd34 CRITICAL FIX: Division safety\n>       max_deviation = self._max_list(deviations)\n                        ^^^^^^^^^^^^^^\nE       AttributeError: 'PsiSyncProtocol' object has no attribute '_max_list'. Did you mean: '_min_list'?\n\nv13\\libs\\economics\\PsiSyncProtocol.py:198: AttributeError"}, "hash": "d4b854b6fb3bef5e91a909d4271ac3f2eff69f7cd26f31774fd8b448e5fa11cc1b4791cb801ba211e25ce1281a0d0a61abcd2a842666c8ebeb5322e803950128"}
{"timestamp": "2025-12-17T13:43:16.972675", "session_id": "f7e8ec8b7bbff13a", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0019167000136803836, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n        genesis_state = boot_from_genesis(cm)\n        print(\"\u2713 Genesis state created\")\n    \n        # Create PsiFieldEngine\n        psi_field = DiscretePsiField(genesis_topology, cm)\n        print(\"\u2713 PsiFieldEngine created\")\n    \n        # Create HarmonicEconomics\n        economics = HarmonicEconomics(psi_field, cm)\n        print(\"\u2713 HarmonicEconomics created\")\n    \n        # Create PsiSyncProtocol\n        psisync = PsiSyncProtocol(cm)\n        print(\"\u2713 PsiSyncProtocol created\")\n    \n        # Create Mock PQC instance\n        pqc = MockPQC()\n    \n        # Create TreasuryDistributionEngine\n        treasury = TreasuryDistributionEngine(cm, pqc, None, psi_field, psisync)\n        print(\"\u2713 TreasuryDistributionEngine created\")\n    \n        # Create HoloRewardEngine\n        holo_reward = HoloRewardEngine(cm, None, psi_field)\n        print(\"\u2713 HoloRewardEngine created\")\n    \n        # Create CoherenceLedger\n        ledger = CoherenceLedger(cm)\n        print(\"\u2713 CoherenceLedger created\")\n    \n        # Create SystemRecoveryProtocol\n        founding_nodes = GENESIS_STATE[\"governance\"][\"founding_nodes\"]\n        recovery_threshold = GENESIS_STATE[\"governance\"][\"recovery_threshold\"]\n        recovery = SystemRecoveryProtocol(cm, pqc, founding_nodes, recovery_threshold)\n        print(\"\u2713 SystemRecoveryProtocol created\")\n    \n        # Integrate recovery protocol with components\n        recovery.integrate_with_phase3_components(\n            psi_field_engine=psi_field,\n            harmonic_economics=economics,\n            treasury_engine=treasury,\n            psisync_protocol=psisync\n        )\n        print(\"\u2713 Recovery protocol integrated with Phase 3 components\")\n    \n        # Create EconomicAdversarySuite\n        adversary_suite = EconomicAdversarySuite(\n            cm, psi_field, economics, treasury, psisync, ledger, recovery, genesis_state\n        )\n        print(\"\u2713 EconomicAdversarySuite created\")\n    \n        # Test basic functionality\n        # Create a token state bundle from genesis state\n        chr_state = {\n            \"shards\": genesis_state[\"token_allocations\"][\"shards\"]\n        }\n    \n        token_bundle = create_token_state_bundle(\n            chr_state=chr_state,\n            flx_state={},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128(1618033988749894848),\n            lambda2=BigNum128(618033988749894848),\n            c_crit=BigNum128(1000000000000000000),\n            pqc_cid=\"TEST_PHASE3_INTEGRATION\",\n            timestamp=1234567890,\n            parameters={\n                \"\u03b4_curl\": BigNum128(10),\n                \"MAX_CHR_SUPPLY\": BigNum128(10000000000),\n                \"\u03b4_max\": BigNum128(5),\n                \"\u03b5_sync\": BigNum128(2)\n            }\n        )\n        print(\"\u2713 TokenStateBundle created\")\n    \n        # Test PsiFieldEngine functionality\n        density_0 = psi_field.psi_density(\"shard_0\", token_bundle)\n        print(f\"\u2713 Psi density for shard_0: {density_0}\")\n    \n        # Test HarmonicEconomics functionality\n        try:\n            new_state = economics.compute_harmonic_state(token_bundle)\n            print(\"\u2713 HarmonicEconomics compute_harmonic_state executed successfully\")\n        except Exception as e:\n            print(f\"\u26a0 HarmonicEconomics compute_harmonic_state raised exception: {e}\")\n    \n        # Test PsiSyncProtocol functionality\n        shard_psisync_values = {\n            \"shard_0\": 100,\n            \"shard_1\": 105,\n            \"shard_2\": 95,\n            \"shard_3\": 102,\n            \"shard_4\": 98\n        }\n    \n        # Create a mock DRV packet\n        drv_packet = type('DRV_Packet', (), {\n            'ttsTimestamp': 1234567890,\n            'sequence': 1,\n            'previous_hash': '0' * 64\n        })()\n    \n>       consensus_result = psisync.compute_global_psisync(\n            shard_psisync_values,\n            epsilon_sync=10,\n            deterministic_timestamp=1234567890,\n            drv_packet_seq=drv_packet\n        )\n\nv13\\tests\\test_phase3_integration.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\libs\\economics\\PsiSyncProtocol.py:71: in compute_global_psisync\n    metrics = self._compute_consensus_metrics(cleaned_values, consensus_val, epsilon_sync)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nv13\\libs\\economics\\PsiSyncProtocol.py:208: in _compute_consensus_metrics\n    consensus_stability = self._compute_consensus_stability(values)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <v13.libs.economics.PsiSyncProtocol.PsiSyncProtocol object at 0x0000018714CB2F90>, values = [95, 98, 100, 102, 105]\n\n    def _compute_consensus_stability(self, values: List[int]) -> int:\n        \"\"\"Compute consensus stability score.\"\"\"\n        if len(values) <= 1:\n            return 1000  # Maximum stability\n    \n        # Lower variance = higher stability\n        mean_val = self.math.div_floor(sum(values), len(values))\n>       variance = sum(self.math.mul(self.math.sub(v, mean_val), self.math.sub(v, mean_val)) for v in values)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       TypeError: unsupported operand type(s) for +: 'int' and 'BigNum128'\n\nv13\\libs\\economics\\PsiSyncProtocol.py:234: TypeError"}, "hash": "9b8e45d75784555e00302e0c621a4f77fd9b63eb49458b840e897cc73df00dfa6511e1dfd801a47d5b6eec9708df6e79cc585a4558f3bc4919a6bc0dd25caa03"}
{"timestamp": "2025-12-17T13:43:51.228044", "session_id": "63c72200d45c1a35", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0019500000053085387, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n        genesis_state = boot_from_genesis(cm)\n        print(\"\u2713 Genesis state created\")\n    \n        # Create PsiFieldEngine\n        psi_field = DiscretePsiField(genesis_topology, cm)\n        print(\"\u2713 PsiFieldEngine created\")\n    \n        # Create HarmonicEconomics\n        economics = HarmonicEconomics(psi_field, cm)\n        print(\"\u2713 HarmonicEconomics created\")\n    \n        # Create PsiSyncProtocol\n        psisync = PsiSyncProtocol(cm)\n        print(\"\u2713 PsiSyncProtocol created\")\n    \n        # Create Mock PQC instance\n        pqc = MockPQC()\n    \n        # Create TreasuryDistributionEngine\n        treasury = TreasuryDistributionEngine(cm, pqc, None, psi_field, psisync)\n        print(\"\u2713 TreasuryDistributionEngine created\")\n    \n        # Create HoloRewardEngine\n        holo_reward = HoloRewardEngine(cm, None, psi_field)\n        print(\"\u2713 HoloRewardEngine created\")\n    \n        # Create CoherenceLedger\n        ledger = CoherenceLedger(cm)\n        print(\"\u2713 CoherenceLedger created\")\n    \n        # Create SystemRecoveryProtocol\n        founding_nodes = GENESIS_STATE[\"governance\"][\"founding_nodes\"]\n        recovery_threshold = GENESIS_STATE[\"governance\"][\"recovery_threshold\"]\n        recovery = SystemRecoveryProtocol(cm, pqc, founding_nodes, recovery_threshold)\n        print(\"\u2713 SystemRecoveryProtocol created\")\n    \n        # Integrate recovery protocol with components\n        recovery.integrate_with_phase3_components(\n            psi_field_engine=psi_field,\n            harmonic_economics=economics,\n            treasury_engine=treasury,\n            psisync_protocol=psisync\n        )\n        print(\"\u2713 Recovery protocol integrated with Phase 3 components\")\n    \n        # Create EconomicAdversarySuite\n        adversary_suite = EconomicAdversarySuite(\n            cm, psi_field, economics, treasury, psisync, ledger, recovery, genesis_state\n        )\n        print(\"\u2713 EconomicAdversarySuite created\")\n    \n        # Test basic functionality\n        # Create a token state bundle from genesis state\n        chr_state = {\n            \"shards\": genesis_state[\"token_allocations\"][\"shards\"]\n        }\n    \n        token_bundle = create_token_state_bundle(\n            chr_state=chr_state,\n            flx_state={},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128(1618033988749894848),\n            lambda2=BigNum128(618033988749894848),\n            c_crit=BigNum128(1000000000000000000),\n            pqc_cid=\"TEST_PHASE3_INTEGRATION\",\n            timestamp=1234567890,\n            parameters={\n                \"\u03b4_curl\": BigNum128(10),\n                \"MAX_CHR_SUPPLY\": BigNum128(10000000000),\n                \"\u03b4_max\": BigNum128(5),\n                \"\u03b5_sync\": BigNum128(2)\n            }\n        )\n        print(\"\u2713 TokenStateBundle created\")\n    \n        # Test PsiFieldEngine functionality\n        density_0 = psi_field.psi_density(\"shard_0\", token_bundle)\n        print(f\"\u2713 Psi density for shard_0: {density_0}\")\n    \n        # Test HarmonicEconomics functionality\n        try:\n            new_state = economics.compute_harmonic_state(token_bundle)\n            print(\"\u2713 HarmonicEconomics compute_harmonic_state executed successfully\")\n        except Exception as e:\n            print(f\"\u26a0 HarmonicEconomics compute_harmonic_state raised exception: {e}\")\n    \n        # Test PsiSyncProtocol functionality\n        shard_psisync_values = {\n            \"shard_0\": 100,\n            \"shard_1\": 105,\n            \"shard_2\": 95,\n            \"shard_3\": 102,\n            \"shard_4\": 98\n        }\n    \n        # Create a mock DRV packet\n        drv_packet = type('DRV_Packet', (), {\n            'ttsTimestamp': 1234567890,\n            'sequence': 1,\n            'previous_hash': '0' * 64\n        })()\n    \n>       consensus_result = psisync.compute_global_psisync(\n            shard_psisync_values,\n            epsilon_sync=10,\n            deterministic_timestamp=1234567890,\n            drv_packet_seq=drv_packet\n        )\n\nv13\\tests\\test_phase3_integration.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\libs\\economics\\PsiSyncProtocol.py:71: in compute_global_psisync\n    metrics = self._compute_consensus_metrics(cleaned_values, consensus_val, epsilon_sync)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nv13\\libs\\economics\\PsiSyncProtocol.py:208: in _compute_consensus_metrics\n    consensus_stability = self._compute_consensus_stability(values)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <v13.libs.economics.PsiSyncProtocol.PsiSyncProtocol object at 0x0000020B50D02F90>, values = [95, 98, 100, 102, 105]\n\n    def _compute_consensus_stability(self, values: List[int]) -> int:\n        \"\"\"Compute consensus stability score.\"\"\"\n        if len(values) <= 1:\n            return 1000  # Maximum stability\n    \n        # Lower variance = higher stability\n        # Convert values to BigNum128 for consistent arithmetic\n>       bn_values = [BigNum128(v) for v in values]\n                     ^^^^^^^^^\nE       NameError: name 'BigNum128' is not defined\n\nv13\\libs\\economics\\PsiSyncProtocol.py:234: NameError"}, "hash": "2024fb20656082310e06e94efcc3e64814db322d1f32898aa858be6bd674053896360f578aaa0a9b029f643e74cdc16e77f8d4a41acc4e5fcc72a92ee2764a63"}
{"timestamp": "2025-12-17T13:44:14.304811", "session_id": "d09157643cb4cd6e", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_phase3_integration.py::test_phase3_integration", "context": {"env": "test"}, "details": {"duration": 0.0023308999952860177, "error": "def test_phase3_integration():\n        \"\"\"Test that all Phase 3 components integrate correctly\"\"\"\n        print(\"Testing Phase 3 Integration...\")\n    \n        # Initialize CertifiedMath\n        cm = CertifiedMath()\n    \n        # Create genesis state\n        genesis_topology = GENESIS_STATE[\"topology\"]\n        genesis_state = boot_from_genesis(cm)\n        print(\"\u2713 Genesis state created\")\n    \n        # Create PsiFieldEngine\n        psi_field = DiscretePsiField(genesis_topology, cm)\n        print(\"\u2713 PsiFieldEngine created\")\n    \n        # Create HarmonicEconomics\n        economics = HarmonicEconomics(psi_field, cm)\n        print(\"\u2713 HarmonicEconomics created\")\n    \n        # Create PsiSyncProtocol\n        psisync = PsiSyncProtocol(cm)\n        print(\"\u2713 PsiSyncProtocol created\")\n    \n        # Create Mock PQC instance\n        pqc = MockPQC()\n    \n        # Create TreasuryDistributionEngine\n        treasury = TreasuryDistributionEngine(cm, pqc, None, psi_field, psisync)\n        print(\"\u2713 TreasuryDistributionEngine created\")\n    \n        # Create HoloRewardEngine\n        holo_reward = HoloRewardEngine(cm, None, psi_field)\n        print(\"\u2713 HoloRewardEngine created\")\n    \n        # Create CoherenceLedger\n        ledger = CoherenceLedger(cm)\n        print(\"\u2713 CoherenceLedger created\")\n    \n        # Create SystemRecoveryProtocol\n        founding_nodes = GENESIS_STATE[\"governance\"][\"founding_nodes\"]\n        recovery_threshold = GENESIS_STATE[\"governance\"][\"recovery_threshold\"]\n        recovery = SystemRecoveryProtocol(cm, pqc, founding_nodes, recovery_threshold)\n        print(\"\u2713 SystemRecoveryProtocol created\")\n    \n        # Integrate recovery protocol with components\n        recovery.integrate_with_phase3_components(\n            psi_field_engine=psi_field,\n            harmonic_economics=economics,\n            treasury_engine=treasury,\n            psisync_protocol=psisync\n        )\n        print(\"\u2713 Recovery protocol integrated with Phase 3 components\")\n    \n        # Create EconomicAdversarySuite\n        adversary_suite = EconomicAdversarySuite(\n            cm, psi_field, economics, treasury, psisync, ledger, recovery, genesis_state\n        )\n        print(\"\u2713 EconomicAdversarySuite created\")\n    \n        # Test basic functionality\n        # Create a token state bundle from genesis state\n        chr_state = {\n            \"shards\": genesis_state[\"token_allocations\"][\"shards\"]\n        }\n    \n        token_bundle = create_token_state_bundle(\n            chr_state=chr_state,\n            flx_state={},\n            psi_sync_state={},\n            atr_state={},\n            res_state={},\n            nod_state={},\n            lambda1=BigNum128(1618033988749894848),\n            lambda2=BigNum128(618033988749894848),\n            c_crit=BigNum128(1000000000000000000),\n            pqc_cid=\"TEST_PHASE3_INTEGRATION\",\n            timestamp=1234567890,\n            parameters={\n                \"\u03b4_curl\": BigNum128(10),\n                \"MAX_CHR_SUPPLY\": BigNum128(10000000000),\n                \"\u03b4_max\": BigNum128(5),\n                \"\u03b5_sync\": BigNum128(2)\n            }\n        )\n        print(\"\u2713 TokenStateBundle created\")\n    \n        # Test PsiFieldEngine functionality\n        density_0 = psi_field.psi_density(\"shard_0\", token_bundle)\n        print(f\"\u2713 Psi density for shard_0: {density_0}\")\n    \n        # Test HarmonicEconomics functionality\n        try:\n            new_state = economics.compute_harmonic_state(token_bundle)\n            print(\"\u2713 HarmonicEconomics compute_harmonic_state executed successfully\")\n        except Exception as e:\n            print(f\"\u26a0 HarmonicEconomics compute_harmonic_state raised exception: {e}\")\n    \n        # Test PsiSyncProtocol functionality\n        shard_psisync_values = {\n            \"shard_0\": 100,\n            \"shard_1\": 105,\n            \"shard_2\": 95,\n            \"shard_3\": 102,\n            \"shard_4\": 98\n        }\n    \n        # Create a mock DRV packet\n        drv_packet = type('DRV_Packet', (), {\n            'ttsTimestamp': 1234567890,\n            'sequence': 1,\n            'previous_hash': '0' * 64\n        })()\n    \n        consensus_result = psisync.compute_global_psisync(\n            shard_psisync_values,\n            epsilon_sync=10,\n            deterministic_timestamp=1234567890,\n            drv_packet_seq=drv_packet\n        )\n        print(f\"\u2713 PsiSyncProtocol compute_global_psisync executed successfully\")\n        print(f\"  Global \u03a8Sync: {consensus_result['global_psisync']}\")\n    \n        # Test TreasuryDistributionEngine functionality\n        try:\n            treasury_result = treasury.compute_system_treasury_distribution(\n                token_bundle,\n                treasury_balance=1000000,\n                epoch_id=\"test_epoch_1\",\n                genesis_shard_ids=[\"shard_0\", \"shard_1\", \"shard_2\", \"shard_3\", \"shard_4\"],\n                global_psisync=consensus_result['global_psisync']\n            )\n            print(\"\u2713 TreasuryDistributionEngine compute_system_treasury_distribution executed successfully\")\n        except Exception as e:\n            print(f\"\u26a0 TreasuryDistributionEngine compute_system_treasury_distribution raised exception: {e}\")\n    \n        # Test HoloRewardEngine functionality\n        try:\n            reward_result = holo_reward.compute_holofield_reward_package(\n                token_bundle,\n                treasury_state=type('obj', (object,), {'total_distributed': 1000000})(),\n                epoch_id=\"reward_epoch_1\"\n            )\n            print(\"\u2713 HoloRewardEngine compute_holofield_reward_package executed successfully\")\n            print(f\"  Reward multiplier: {reward_result['reward_multiplier']}\")\n        except Exception as e:\n            print(f\"\u26a0 HoloRewardEngine compute_holofield_reward_package raised exception: {e}\")\n    \n        # Test CoherenceLedger functionality\n        ledger_entry = ledger.log_state(token_bundle)\n        print(f\"\u2713 CoherenceLedger log_state executed successfully\")\n        print(f\"  Entry ID: {ledger_entry.entry_id[:16]}...\")\n    \n        # Test SystemRecoveryProtocol functionality\n>       recovery_status = recovery.get_recovery_status()\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       TypeError: SystemRecoveryProtocol.get_recovery_status() missing 2 required positional arguments: 'deterministic_timestamp' and 'drv_packet_seq'\n\nv13\\tests\\test_phase3_integration.py:191: TypeError"}, "hash": "c70ab11f12215dce9802715115d38d9ea1c7d23c19f4b86c1907d6b9b237d2a331eb9cb5c138e8f1770d67d5a3e2a605e4e8bde63cd9943df56b15f8b3f239d6"}
{"timestamp": "2025-12-17T13:51:20.217703", "session_id": "a4e0ff7a0a2c45dd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_bignum128_phase3_audit.py::TestBigNum128Phase3Audit::test_integer_fractional_overflow", "context": {"env": "test"}, "details": {"duration": 0.0003312000189907849, "error": "self = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB3521250>\n\n    def test_integer_fractional_overflow(self):\n        \"\"\"Test overflow detection in integer and fractional parts\"\"\"\n        # Test integer part overflow\n        with pytest.raises(OverflowError, match=\"Integer part too large for BigNum128\"):\n>           BigNum128.from_string(f\"{self.MAX_INT_PART + 1}.0\")\n\nv13\\tests\\test_bignum128_phase3_audit.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <class 'v13.libs.BigNum128.BigNum128'>, s = '340282366920938463464.0'\n\n    @classmethod\n    def from_string(cls, s: str):\n        \"\"\"Converts a string representation to BigNum128.\"\"\"\n        if not isinstance(s, str):\n            raise TypeError('Input must be a string')\n        s = s.strip()\n        if s.startswith('-'):\n            raise BigNum128Error('BigNum128 is unsigned; negative values not allowed')\n        if '.' in s:\n            parts = s.split('.')\n            if len(parts) > 2:\n                raise ValueError('Input string must contain at most one decimal point')\n            integer_part = parts[0] or '0'\n            decimal_part = parts[1] or '0'\n            if integer_part == '' and decimal_part == '':\n                integer_part = '0'\n                decimal_part = '0'\n            elif integer_part == '':\n                integer_part = '0'\n            elif decimal_part == '':\n                decimal_part = '0'\n            if not integer_part.isdigit() or not decimal_part.isdigit():\n                raise ValueError('Input string parts must contain only digits')\n            from .CertifiedMath import CertifiedMath\n            cm = CertifiedMath()\n            if int(integer_part) > cm.idiv(cls.MAX_VALUE, cls.SCALE):\n                raise OverflowError('Integer part too large for BigNum128')\n            if len(decimal_part) > cls.SCALE_DIGITS:\n                extra_digits = decimal_part[cls.SCALE_DIGITS:].rstrip('0')\n                if extra_digits:\n                    raise BigNum128Error('Input value too small for BigNum128 (underflow)')\n                round_digit = int(decimal_part[cls.SCALE_DIGITS]) if len(decimal_part) > cls.SCALE_DIGITS else 0\n                decimal_part_scaled = decimal_part[:cls.SCALE_DIGITS]\n                if round_digit >= 5:\n                    decimal_value = cm.add(int(decimal_part_scaled), 1)\n                    if decimal_value >= cm.pow(10, cls.SCALE_DIGITS):\n                        integer_part = str(cm.add(int(integer_part), 1))\n                        if int(integer_part) > cm.idiv(cls.MAX_VALUE, cls.SCALE):\n                            raise OverflowError('Integer part overflow after rounding')\n                        decimal_part_scaled = '0' * cls.SCALE_DIGITS\n                    else:\n                        decimal_part_scaled = str(decimal_value).zfill(cls.SCALE_DIGITS)\n                else:\n                    decimal_part_scaled = decimal_part_scaled.ljust(cls.SCALE_DIGITS, '0')\n            else:\n                decimal_part_scaled = decimal_part.ljust(cls.SCALE_DIGITS, '0')\n            value = int(integer_part) * cls.SCALE + int(decimal_part_scaled)\n        else:\n            if not s.isdigit():\n                raise ValueError('Input string must contain only digits')\n            from .CertifiedMath import CertifiedMath\n            cm = CertifiedMath()\n            if int(s) > cm.idiv(cls.MAX_VALUE, cls.SCALE):\n                raise OverflowError('Integer value too large for BigNum128')\n            value = int(s) * cls.SCALE\n        if value > cls.MAX_VALUE:\n>           raise OverflowError('Scaled value exceeds BigNum128 capacity')\nE           OverflowError: Scaled value exceeds BigNum128 capacity\n\nv13\\libs\\BigNum128.py:101: OverflowError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB3521250>\n\n    def test_integer_fractional_overflow(self):\n        \"\"\"Test overflow detection in integer and fractional parts\"\"\"\n        # Test integer part overflow\n>       with pytest.raises(OverflowError, match=\"Integer part too large for BigNum128\"):\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AssertionError: Regex pattern did not match.\nE        Regex: 'Integer part too large for BigNum128'\nE        Input: 'Scaled value exceeds BigNum128 capacity'\n\nv13\\tests\\test_bignum128_phase3_audit.py:126: AssertionError"}, "hash": "3fdd553e7d719399db1b6149e8bd1ba3b4a5c64c0fd52b985da2fd9389d0a9ecb4ccf15ec5a436a6fd75dcd1569e44b87133f122b3665f300d9aaa0629f1ba72"}
{"timestamp": "2025-12-17T13:51:20.261564", "session_id": "a4e0ff7a0a2c45dd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_bignum128_phase3_audit.py::TestBigNum128Phase3Audit::test_arithmetic_overflow_add", "context": {"env": "test"}, "details": {"duration": 0.0003144000074826181, "error": "self = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB3521450>\n\n    def test_arithmetic_overflow_add(self):\n        \"\"\"Test addition overflow detection\"\"\"\n        # Create two values that when added would exceed MAX_VALUE\n        half_max = BigNum128(BigNum128.MAX_VALUE // 2)\n        more_than_half = BigNum128(BigNum128.MAX_VALUE // 2 + 2)\n    \n        # This should overflow\n        with pytest.raises(OverflowError, match=\"BigNum128 addition overflow\"):\n>           half_max.add(more_than_half)\n\nv13\\tests\\test_bignum128_phase3_audit.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\libs\\BigNum128.py:198: in add\n    result = cm.add(self.value, other.value)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nv13\\libs\\CertifiedMath.py:73: in add\n    return CertifiedMath._safe_add(a, b, log_list or self.log_list, pqc_cid, quantum_metadata)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\na = BigNum128(raw=170141183460469231731687303715884105727, fp='170141183460469231731.687303715884105727')\nb = BigNum128(raw=170141183460469231731687303715884105729, fp='170141183460469231731.687303715884105729'), log_list = [], pqc_cid = None\nquantum_metadata = None\n\n    @staticmethod\n    def _safe_add(a: BigNum128, b: BigNum128, log_list: List[Dict[str, Any]], pqc_cid: Optional[str]=None, quantum_metadata: Optional[Dict[str, Any]]=None) -> BigNum128:\n        if not isinstance(a, BigNum128):\n            a = BigNum128(a)\n        if not isinstance(b, BigNum128):\n            b = BigNum128(b)\n        result_value = a.value + b.value\n        if result_value > BigNum128.MAX_VALUE:\n>           raise OverflowError('CertifiedMath add overflow')\nE           OverflowError: CertifiedMath add overflow\n\nv13\\libs\\CertifiedMath.py:391: OverflowError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB3521450>\n\n    def test_arithmetic_overflow_add(self):\n        \"\"\"Test addition overflow detection\"\"\"\n        # Create two values that when added would exceed MAX_VALUE\n        half_max = BigNum128(BigNum128.MAX_VALUE // 2)\n        more_than_half = BigNum128(BigNum128.MAX_VALUE // 2 + 2)\n    \n        # This should overflow\n>       with pytest.raises(OverflowError, match=\"BigNum128 addition overflow\"):\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AssertionError: Regex pattern did not match.\nE        Regex: 'BigNum128 addition overflow'\nE        Input: 'CertifiedMath add overflow'\n\nv13\\tests\\test_bignum128_phase3_audit.py:147: AssertionError"}, "hash": "1945937daea8f1123e1eb7094a052654459d5ccf36a5f1a0246c52e7fbca7db24fd0b328f5cfe80fdb6f8a959b32558368b934740c6a501190a3479484e12525"}
{"timestamp": "2025-12-17T13:51:20.274185", "session_id": "a4e0ff7a0a2c45dd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_bignum128_phase3_audit.py::TestBigNum128Phase3Audit::test_arithmetic_overflow_sub", "context": {"env": "test"}, "details": {"duration": 0.0002921000123023987, "error": "self = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB34FDE50>\n\n    def test_arithmetic_overflow_sub(self):\n        \"\"\"Test subtraction underflow detection\"\"\"\n        # Test subtracting a larger number from a smaller one\n        small = BigNum128(100)\n        large = BigNum128(200)\n    \n        with pytest.raises(BigNum128Error, match=\"BigNum128 subtraction underflow\"):\n>           small.sub(large)\n\nv13\\tests\\test_bignum128_phase3_audit.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BigNum128(raw=100, fp='0.0000000000000001'), other = BigNum128(raw=200, fp='0.0000000000000002')\n\n    def sub(self, other: 'BigNum128') -> 'BigNum128':\n        \"\"\"Subtracts two BigNum128 values.\"\"\"\n        from .CertifiedMath import CertifiedMath\n        cm = CertifiedMath()\n        if self.value < other.value:\n>           raise OverflowError('Subtraction result would be negative (unsigned type)')\nE           OverflowError: Subtraction result would be negative (unsigned type)\n\nv13\\libs\\BigNum128.py:208: OverflowError"}, "hash": "3eeee4c974629f3f63cb3ede1eab51c8156f124478d2ce5241b12d5747055ea76d6aec90bbc5c6d72167dddfcd323444193895649041012a32fbbbb5b5fd44b7"}
{"timestamp": "2025-12-17T13:51:20.292779", "session_id": "a4e0ff7a0a2c45dd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_bignum128_phase3_audit.py::TestBigNum128Phase3Audit::test_division_by_zero", "context": {"env": "test"}, "details": {"duration": 0.00029689999064430594, "error": "self = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB35CA190>\n\n    def test_division_by_zero(self):\n        \"\"\"Test division by zero raises appropriate exception\"\"\"\n        a = BigNum128(100)\n        b = BigNum128(0)\n    \n        with pytest.raises(ZeroDivisionError, match=\"BigNum128 division by zero\"):\n>           a.div(b)\n\nv13\\tests\\test_bignum128_phase3_audit.py:240: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BigNum128(raw=100, fp='0.0000000000000001'), other = BigNum128(raw=0, fp='0.0')\n\n    def div(self, other: 'BigNum128') -> 'BigNum128':\n        \"\"\"Divides two BigNum128 values.\"\"\"\n        if other.value == 0:\n>           raise ZeroDivisionError('Division by zero')\nE           ZeroDivisionError: Division by zero\n\nv13\\libs\\BigNum128.py:225: ZeroDivisionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB35CA190>\n\n    def test_division_by_zero(self):\n        \"\"\"Test division by zero raises appropriate exception\"\"\"\n        a = BigNum128(100)\n        b = BigNum128(0)\n    \n>       with pytest.raises(ZeroDivisionError, match=\"BigNum128 division by zero\"):\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AssertionError: Regex pattern did not match.\nE        Regex: 'BigNum128 division by zero'\nE        Input: 'Division by zero'\n\nv13\\tests\\test_bignum128_phase3_audit.py:239: AssertionError"}, "hash": "03d886bb0caaf96b3c9a4bef795698c1e0b5a4d042fa6c25063f74fac0572479de206ff7263312fc3b6dad718aa1e650cdbbed113edd903a080e39131f3cb57b"}
{"timestamp": "2025-12-17T13:51:20.305472", "session_id": "a4e0ff7a0a2c45dd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_bignum128_phase3_audit.py::TestBigNum128Phase3Audit::test_modulo_operator", "context": {"env": "test"}, "details": {"duration": 0.00023659999715164304, "error": "self = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB34AE4E0>\n\n    def test_modulo_operator(self):\n        \"\"\"Test modulo operator functionality and edge cases\"\"\"\n        a = BigNum128.from_string(\"10.5\")\n        b = BigNum128.from_string(\"3.0\")\n    \n>       result = a % b\n                 ^^^^^\n\nv13\\tests\\test_bignum128_phase3_audit.py:254: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = BigNum128(raw=10500000000000000000, fp='10.5'), other = BigNum128(raw=3000000000000000000, fp='3.0')\n\n    def __mod__(self, other):\n        if not isinstance(other, BigNum128):\n            raise TypeError('mod requires BigNum128')\n        from .CertifiedMath import CertifiedMath\n        cm = CertifiedMath()\n>       return BigNum128(cm.mod(self.value, other.value))\n                         ^^^^^^\nE       AttributeError: 'CertifiedMath' object has no attribute 'mod'\n\nv13\\libs\\BigNum128.py:178: AttributeError"}, "hash": "f67a92cb3943e5fd7a9f3637a42f2455adc91a2825fefaa03ad38959c813c1e883e3e7ed66712aac7ef6f02c903606cb92ee327b04e9b9f80fb6008dad6c1c67"}
{"timestamp": "2025-12-17T13:51:20.314990", "session_id": "a4e0ff7a0a2c45dd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_bignum128_phase3_audit.py::TestBigNum128Phase3Audit::test_serialization_correctness", "context": {"env": "test"}, "details": {"duration": 0.00021169998217374086, "error": "self = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB350C4D0>\n\n    def test_serialization_correctness(self):\n        \"\"\"Test 16-byte big-endian serialization correctness\"\"\"\n        # Test with zero\n        zero = BigNum128.zero()\n>       zero_bytes = zero.serialize_for_sign()\n                     ^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'BigNum128' object has no attribute 'serialize_for_sign'\n\nv13\\tests\\test_bignum128_phase3_audit.py:270: AttributeError"}, "hash": "2d7999ac7ec721433d9fe8bd451d7505c8dcc4a3f70e0faf3ec246664952ff0f1ae9b5f937a8958688116dc32e2ce0edc956956f46c4c991e3032b54201077d2"}
{"timestamp": "2025-12-17T13:51:20.336769", "session_id": "a4e0ff7a0a2c45dd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_bignum128_phase3_audit.py::TestBigNum128Phase3Audit::test_arithmetic_operator_overloads", "context": {"env": "test"}, "details": {"duration": 0.0002440999960526824, "error": "self = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB35C5950>\n\n    def test_arithmetic_operator_overloads(self):\n        \"\"\"Test arithmetic operator overloads\"\"\"\n        a = BigNum128.from_string(\"10.5\")\n        b = BigNum128.from_string(\"2.5\")\n    \n        # Test addition\n>       result_add = a + b\n                     ^^^^^\n\nv13\\tests\\test_bignum128_phase3_audit.py:383: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\libs\\BigNum128.py:159: in __add__\n    return self.add(other)\n           ^^^^^^^^^^^^^^^\nv13\\libs\\BigNum128.py:201: in add\n    return BigNum128(result)\n           ^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <[AttributeError(\"'BigNum128' object has no attribute 'value'\") raised in repr()] BigNum128 object at 0x21fb3631310>\nvalue = BigNum128(raw=13000000000000000000, fp='13.0')\n\n    def __init__(self, value: int):\n        self._ensure_cm_initialized()\n        if not isinstance(value, int):\n>           raise TypeError('BigNum128 only accepts integers')\nE           TypeError: BigNum128 only accepts integers\n\nv13\\libs\\BigNum128.py:26: TypeError"}, "hash": "579fdb5eb207b68223e687a078c7fd6c01f19ad1bfe72c31ea8871a0a14dc99a38541c805127df2eb6ad98a7160e7c89b9816a5e1c667571c4bde31853c522aa"}
{"timestamp": "2025-12-17T13:51:20.351014", "session_id": "a4e0ff7a0a2c45dd", "component": "pytest_session", "level": "ERROR", "category": "testing", "message": "Test Failed: v13/tests/test_bignum128_phase3_audit.py::TestBigNum128Phase3Audit::test_constants", "context": {"env": "test"}, "details": {"duration": 0.0002246999938506633, "error": "self = <v13.tests.test_bignum128_phase3_audit.TestBigNum128Phase3Audit object at 0x0000021FB356F140>\n\n    def test_constants(self):\n        \"\"\"Test zero() and one() constants\"\"\"\n        zero = BigNum128.zero()\n>       one = BigNum128.one()\n              ^^^^^^^^^^^^^^^\n\nv13\\tests\\test_bignum128_phase3_audit.py:411: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nv13\\libs\\BigNum128.py:192: in one\n    return cls(cm.mul(1, cls.SCALE))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <[AttributeError(\"'BigNum128' object has no attribute 'value'\") raised in repr()] BigNum128 object at 0x21fb3632870>\nvalue = BigNum128(raw=1, fp='0.000000000000000001')\n\n    def __init__(self, value: int):\n        self._ensure_cm_initialized()\n        if not isinstance(value, int):\n>           raise TypeError('BigNum128 only accepts integers')\nE           TypeError: BigNum128 only accepts integers\n\nv13\\libs\\BigNum128.py:26: TypeError"}, "hash": "ed893f8eed074a31937c0514958cb284c73d3c18edda3cb447b15a694b424bfbea0bcc45400c0292a4c0234d85f2ff1e311215cb0d8b24c44b70b624b24d8df1"}
>>>>>>> b27f784 (fix(ci/structure): structural cleanup and genesis_ledger AST fixes)
